1、HDFS支持数据的擦除编码，这使得HDFS在不降低可靠性的前提下，节省一半存储空间。（https://issues.apache.org/jira/browse/HDFS-7285）
  --确定? 不降低可靠性
  RS(k，m)最多可容忍m个块（包括数据块和校验块）丢失, 以RS(6，3)为例，每一个块组包含1-6个数据块，以及3个校验块, 所以呀我觉得不是绝对安全呀, 能容忍 6 个
  块丢失才好。但是他这意思明摆着3个块是任意的, 所以说绝对安全好像也可以, 我自行脑补一下吧: A&B=C, 这样增加 0.5 倍的存储成本, 能容忍 1/3(3/(6+3)) 出错
  最后说一句: 1.5 倍的存储成本好像也可以再降, A&B&C&D=E, 能容忍任意挂一个的话存储成本就是 5/4
2、Tasknative 优化。为MapReduce增加了C/C++的map output collector实现（包括Spill，Sort和IFile等），通过作业级别参数调整就可切换到该实现上。
对于shuffle密集型应用，其性能可提高约 30%。（https://issues.apache.org/jira/browse/MAPREDUCE-2841）

----
腾讯哥们问 hdfs cap
hdfs 似乎没有更新操作
说下 CAP:
C = 一致性 (Consistency) ：保证得到的都是完成状态的数据，否则直接失败
A = 可用性 (Availability) ：在容忍的响应时间内，每个操作总是能够返回
P = 分区容忍性 (Partition Tolerance) ：能够保证系统是分区的。
  原文是这样No set of failures less than total network failure is allowed to cause the system to respond incorrectly，比较难理解，
  简单的解释一下这是个反证，除非整个分布式系统所在的网络都挂掉，只要还有分区就能给出正确响应

----分区容错性：能容忍一部分机器网络故障 (分布式系统和必然要求, 所以往往在 C 与 A 之间权衡)
hdfs 应该是在可用性稍差, 一个 client put 文件, 另一个 客户端要等 datanode 处理完数据才能读到呢, 伪分部式还不明显, 分部式往往会 No such file or directory
NWR 策略:
N = 副本数
W = 一次成功的写操作必须完成的写副本数
R = 一次成功的读操作需要读的副本数（是的，随便读一个副本是不行的，你必须读到一定数量的副本，再相互比较取最新的数据）
策略来说就有具体的公式可供运算，有两个：W > N/2, W + R > N 
a. 若 N=3, W=1 则会出现数不一问题, 如果 N=3, W=2, R=1 时会出现读不到最新数据问题

b. 当然NWR还可能取其他值，不同的取值代表了不同的倾向。如果设定N=3, W=3, R=1，那么强调的是一致性，写数据的时候一定要把所有副本都刷新，杜绝中间状态，
如果N=3, W=1, R=1，那强调的是可用性，这种情况下一致性是被牺牲掉了，
N=3, W=2, R=2是一种折中的策略, 在这种配置下，虽然一个数据拥有三副本，但是容错上读写是不一样的。网络断线，硬盘故障等意外造成一个副本失效时，系统仍然可读
可写，但两个副本失效时，受影响的这部分数据系统就变成只读，无法再写了。
c. N=2 时的情形自行脑补, 但是是否可以有一个虚拟节点来完成与 N=3 同样的功能呢
d. hdfs 是怎么做的呢, 我觉得这些版本控制啥的在 namenode 里做好了, 不会出现数据不一致问题, 最多是去 datanode 读数据时数据暂时没有, 同理 hbase
  可以这么说所有分部式系统, 都是单点写的 hdfs/hbase/cassandra/kafka, 好像除了 zk
e.最近我一个朋友在网上购物,遇到一件有意思的事，某电商有个特价抢购，是个手机移动电源，他就很happy下了单，结果第2天送来了两瓶酱油。回头看订单详情，明明还是移动电源。再看促销，原来的促销已经变成了酱油。我们可以用前面的理论模拟下问题是如何产生的。朋友在查看商品的时候，他的这个会话，假设读到的库存数据是1，意思就是有货，就放到购物车里了。但同时估计也有很多人在查询，读到的数据都是1，大家都认为有货。除了我朋友，至少还有一个人也下了单，下单就需要后台需要将这个库存数据减去1，常见的逻辑应该是改写库存成功才能生成订单。如果设定的W是1，那么两个会话就会有机会都认为自己成功，两个订单同时生成，但货只有一个了，导致问题出现。

--NRW算法是基于 Quorum 机制的是一种CP(Consistency&Partion tolerance)算法。用于在数据一致性和可靠性之间达到一种平衡 https://blog.csdn.net/jeffsmish/article/details/54171812
