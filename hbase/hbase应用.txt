1、region merge
方式一：71.6 $ hbase> merge_region 'ENCODED_REGIONNAME', 'ENCODED_REGIONNAME'
	merge_region '33cfb558ffe884b73b472d8bef83c916_ns:MyTab,key937439,1516295899830.33cfb558ffe884b73b472d8bef83c916.','1de721aa0ea29f21f63675e92e41b498_ns:MyTab,key98,1516295899830.1de721aa0ea29f21f63675e92e41b498.'
方式二：146.2 $ bin/hbase org.apache.hadoop.hbase.util.Merge <tablename> <region1> <region2>, 要关闭hbase集群, 启动zk(hbase zookeeper)

2、region split
    $ hbase> split 'tableName', 'splitKey'
    $ hbase> split 'regionName', 'splitKey'
    $ hbase> scan 'hbase:meta', {COLUMNS=>'info:server'}
3、要手动 alter 'tab', NORMALIZATION_ENABLED =>'true', 否则不能自动 NORMALIZATION
3、region预分区:create 'ns:MyTab','cf',SPLITS => ['key3','key5'], 预分区后写入会快一些, 但不是太明显, 但是IO消耗差别应该还是很大, 因为写完之后还会有一段时间的 compact IO
4、major_compact '9b1bf877acc4334df195755ab384b53b','cf'	region中至少有两个Hfile时才生效（比如有很多delete的RowKey）

8、kill 掉一个HRegionServer节点, 相应region数据暂时是不能访问的, 但是过段时间（一两分钟吧）, 此HRegionServer下的region会转交给其它HRegionServer, 可以继续访问数据了
9、经我测试 minor compaction 时也会合并数据呀

==================================
create 'testImport1','cf','cg'
准备数据文件 sample.csv, 并上传到HDFS, 内容为：
1,tom,ss,jj
2,sam,rr,hh
3,jerry,hh,mm
4,marry,mm,dd
5,john,kk,rr
----
方式1: hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator="," -Dimporttsv.columns=HBASE_ROW_KEY,cf:a,cf:b,cg testImport1 /sample.csv

方式2: hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator="," -Dimporttsv.bulk.output=/result/hfile_tmp -Dimporttsv.columns=HBASE_ROW_KEY,cf:a,cf:b,cg testImport1 /sample.csv
  hbase org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles /result/hfile_tmp testImport1

----
做 HMaster HA, 只改这里即可, 其它节点 hbase-daemon.sh start master, 在前台看active状态（16010）
<name>hbase.master.port</name>
<value>60000</value>
=================================================
hbase org.apache.hadoop.hbase.snapshot.ExportSnapshot -snapshot ss -copy-to hdfs://192.168.58.172:9000/hbase
mr任务会报内存溢出, 看日志发现
2018-04-07 19:03:49,490 INFO [main] org.apache.hadoop.hbase.snapshot.ExportSnapshot: Using bufferSize=128 M
2018-04-07 19:03:49,969 FATAL [main] org.apache.hadoop.mapred.YarnChild: Error running child : java.lang.OutOfMemoryError: Java heap space
应该是默认值小于128 M, 于是更改
<name>mapred.child.java.opts</name>
<value>-Xmx1024m</value>
顺便把快照拷贝说完, 在另一个集群直接restore_snapshot 'ss', 如果没有表空间要创建一下create_namespace 'ns'
snapshot 'tableName','snapshotName'	list_snapshots	clone_snapshot 'snapshotName','newTableName'
经测试对集群负载没什么压力
=============================================
