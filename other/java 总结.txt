==================================== jvm/gc ====================================
1、java heap 内存分配方式有两种, 指针碰撞 空闲列表, 采用哪种方式跟 GC 方式有关
2、对象头组成: 如哈希码、GC分代年龄、锁状态标志, 另外一部分是类型指针, 即对象指向它的类型元数据的指针。任何对象的大小都必须是8字节的整数倍对象头在
  32位系统上占用8bytes,64位系统上占用16bytes, reference类型在32位系统上每个占用4bytes, 在64位系统上每个占用8bytes
33、
  java对象头会占用两个字(Word)的存储空间,第一个字存 hashcode,锁相关信息, 第二个字存储类所属字的指针。因此对象头占用8字节或16字节
  如果对象是个数组则占用3个字,为了节约空间,在4字节足以表示对象所属地址的情况下,java虚拟机会用4字节表示第2个字(UseCompressedClassPointer 是说这个事不 )。
  因此64位系统的对象头可能只占12(8+4)个字节(我觉得第一个字也可以压缩用4个字节呀)
有的不权威资料上说 【Oop指针,如果是32G内存以下的,默认开启对象指针压缩,4个字节】
对象以8字节为粒度进行对齐(为什么这样奢侈呢？必须这样自己品吧)
举例：
class ObjectA {
	String str;  // 4
	int i1; // 4
	byte b1; // 1
	byte b2; // 1
	int i2;	 // 4 
	ObjectB obj; //4
	byte b3;  // 1
}
8(_mark) + 4(oop指针) + 4(str) +  4(i1) + 1(b1) + 1(b2) + 2(padding) + 4(i2) + 4(obj) + 1(b3) + 7(padding) = 40
正确方式：
8(_mark) + 4(oop指针) + 4(i1) + + 4(i2) + 1(b1) + 1(b2) + 1(b3) + 1(padding) +  4(str) + 4(obj) = 32

虚拟机在为线程分配空间时,会优先使用一块叫作 TLAB(Threa Local Allocation Buffer) 的区域 TLAB 的相关内容在下 节详细介绍),对于体积不大的对象,很有可能会在 TLAB 上先行分

3、自JDK7起,原本存放在永久代的串常量池被移至 Java 堆之中
4、GC Roots 的对象主要有两类吧：
  各个线程被调用的方法堆栈中使用到的参数、局部变量
  在方法区中类静态属性引用的对象,譬如 Java类的引用类型静态变量
  为什么这两类往下几乎能找到所有对象, 我已经脑补过了

6、方法区垃圾回收条件很苛刻。在大量使用反射、动态代理 CGLib 等字节码框架,通常都需要Java虚拟机具备类型卸载的能力,以保证不会对方法区造成过大的内存压力
7、两个分代假说
   第三分代假说：
   但新生代中的对象是完全有可能被老年代所引用的,为了找出该区域中的存活对象,不得不在固定的 GC Roots 之外,再额外遍历整个老年代中所有对象来确保可达性分析
   结果的正确性,反过来也是一样,跨代引用假说(Intergenerational Reference Hypothesis)：跨代引用相对于同代引用来说仅占极少数
   第三分代假说的提出条件有点蒙,但脑补一下应该是那么回事。在 GC Roots 往下找对象时, 肯定不是找 heap 的所有对象, 而是年轻代/老年代
8、标记-清除, 标记-整理 算法
  移动存活对象并更新所有引用这些对象的地方将会是一种极为负重的操作,而且这种对象移动操作, 必须全程暂停用户应用程序才能进行
  关注吞吐量 Parallel Scavenge 集器是基于标记－整理算法的,而关注延迟的 CMS 收集器则是基于标记－清除算法的
9、所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的,耗时最长的查找引用链的过程已经可以做到与用户线程一起并发
根节点枚举并不需要一个不漏地检查完所有执行上下文和全局的引用位置,虚拟机应当是有办法直接得到哪些地方存放着对象引用的。是使用一组称为 OopMap 的数据结构
来达到这个目的
10、
新生代是 是基于标记复制算法, 老年代基于标记整理算法, CMS特殊
新生代：
	Serial 收集器,单线程；ParNew 多线程; 
	Parallel Scavenge 与 ParNew 类似关注 吞吐量
	Parallel Scavenge 收集器还有一个参数 -XX:+UseAdaptiveSizePolicy值得我们关注 这是一个开关参数,当这个参数被激活之后,就不需要人工指定新生代的
	大小 Eden与Survivor 区的比例  晋升老年代对象大小(－XXPretenureSizeThreshold )等细节参数了, 虚拟机会根据当前系统的运行情况收集性能监控信
	息,动态调整这些参数以提供最合适的停顿时间或者最大的吞吐 这种调节方式称为垃圾收集的自适应的调节策略

老年代：
	Serial Old 收集器
	Parallel Old 收集器
	CMS收集器
  1)初始标记( CMS initial mark )
  2)并发标记( CMS concurrent mark )
  3)重新标记( CMS remark )
  4)并发清除( CMS concurrent sweep) 
  其中初始标记、重新标记这两个步 然需要" Stop The World 
  初始标记仅仅只是标记一下 GC Roots能直接关联到的对象,速度很快,而重新标记阶段则是为了修正并发标记期间,因用户程序继续运作而导致标记产生变动的那一部分
对象的标记记录。最后是并发清除阶段 ,清理删除掉标记阶段判断的已经死亡的对象, 由于不需要移动存活对象,所以这个阶段也是可以与用户线程同时并发的
一起并发执行的。至少有以下三个明显的缺点：
  由于 CMS 收集器无法处理"浮动垃圾"(Floating Garbage ),有可能出现" Concurrent Mode Failur巳"失败进而导致另一次完全"Stop The World"的 Full GC 
的产生。在CMS 的并发标记和并发清理阶段,用户线程是还在继续运行的,程序在运行自然就还会伴随有新的垃圾对象不断产生,但这一部分垃圾对象是出现在标记过程
结束以后,CMS 无法在当次收集中处理掉它们,只好留待下一次垃圾收集时再清理掉。这一部分垃圾就称为"浮动垃圾"。
同样也是由于在垃圾 集阶段用户线程还需要持续
运行 ,那就还需要预留足够内存空间提供给用户线程使用,因此 CMS 收集器不能像其他收集器那样等待到老年代几乎完全被填满了再进行收集,必须预留一部分空间
供并发收集时的程序运作使用。
要是 CMS 运行期间预留的内存无法满足程序分配新对象的需要, 就会出现一次"并发失败"( Concurrent Mode Failure ), 这时候虚拟机将不得不启动后备预案
冻结用户线程的执行, 临时启用 Serial Old 收集器来重新进行老年代的垃圾收集,但这样停顿时间就很长了
空间碎片过多时,将会给大对象分配带来很大麻烦 ,往往会出现老年代还有很多剩余空间,但就是无法找到足够大的连续空间来分配当前对象,
而不得不提前触发一次 Full GC 的情况。为了解决这个问题,改为进入 Full GC 前会先进行碎片整理


部分收集( Partial GC )：指目标不是完整收集整个 Java 堆的垃圾收集,其中又分为
	新生代收集(Minor GC/Young GC )：指目标只是新生代的垃圾收集
	老年代收集( Major GC/Old GC )：指目标只是老年代的垃圾收集 目前只有CMS 收集器会有单独收集老年代的行为 另外请注意" Major GC "这个说
		法现在有点混淆,在不同资料上常有不同所才旨,读者需按上下文区分到底是指老年代的收集还是整堆收集
	混合收集( Mixed GC )：指目标是收集整个新生代以及部分老年代的垃圾收目前只有 Gl 收集器会有这种行为
整堆收集( Full GC )：收集整个 Java 堆和方法区的垃圾收集


11、大对象直接进入老年代,-XX:PretenureSizeThreshold 
  对象晋升老年代的年龄阈值可通过 -XX:MaxTenuringThreshold 设置
  动态对象年龄判定：如果在 Survivor空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半 ,年龄大于或等于 亥年龄的对象就可以直接进入老年代
  空间分配担保：
  在发生 Minor GC 之前,虚拟机必须先检查老年代最大可用的连续空间是否大于新生代所有对象总空间,如果这个条件成立,那这一次Minor GC 可以确保是安全的 
如果不成立,则虚拟机会先查看-XX:Hand ePromotionFailure 参数 的设置值是否允许担保失败(Handle Promotion Failure )；如果允许,那会继续检查老年代最大可用
的连续空间是否大于历次晋升到老年代对象的平均大小,如果大于,将尝试进行一次Minor GC ,尽管这次Minor GC 是有风险的；如果小于,
或者 -XX:HandlePromotionFailure 设置不允许冒险,那这时就要改为进行一次 Full GC
其实我觉得还有个问题, 如果 Survivor 装不下怎么办,书上说过：
当 Survivor 间不足以容纳一次 MinorGC 之后存活的对象时,就需要依赖其他内存区域(实际上大多就是老年代)进行分配担保(Handle Promotion

12、回收12GB的Java 堆,一次 Full GC 的停顿时间就高达 14s 
  所以 GC 时间特别长的都是大内存的程序, 如果程序中有大对象直接进入老年代其实是最恶心的, 我突然想 web 程序是不是要避免线上 Full GC 呀,通过重启的方式
  当然对多节点来说解决这个问题不大。
  还要注意一下 堆外内存导致的溢出错误

18、未来我做主:G1回收器(JDK9及之后版本的默认回收器〉
从分代上看, 依然属于分代垃圾回收器,它会区分年轻代和老年代 依然有 eden 区和 survivor 区
依然是一个分代回收器,但是和之前的回收器不同,它同时兼顾年轻代和老年代,
在回收过程中,会进行适当的对象移动,不像 CMS ,只是简单地标记清
理对象,在若干次 GC 后, CMS 必须进行一次碎片整理。而 Gl 不同,它每次回收都会
有效地复制对象,减少碎片空间

18、虚拟机可能使用一种叫作卡表的数据结构。卡表为一个比特位集合,每一个特位可以用来表示老年代的某一区域中的所有对象是否持有新生代对象的引用

确定对象何时晋升的另外一个重要 数为 TargetSurvivorRatio, 它用于设置 urvivo 区的目标使用率,默认为 ,即如果 urvivor 区在 GC 后使用率超过 50%,就很可能 用较小的 age 作为 年龄。


GC 是内存回收的关键,如果 GC 效率低下,那么系统的性能会受到严重的影响 如果系统
的堆空间太小,那么 GC 所花的时间就会较多,并且回收所释放的内存会较少 根据 GC 占用
的系统时间,以及释放内存的大小,虚拟机会评估 GC 的效率, 旦虚拟机认为 GC 的效率过
低,就有可能直接抛出 OOM 但是,虚拟机不会太随意判定,因为即使 GC 效率不高,强制中
止程序还是显得有些野蛮 一般情况下,虚拟机会检查以下几种情况：
·花在 GC 上的时间是否超过了 98%
·老年代释放的内存是否小于 2%
? eden 区释放的内存是否小于 2%
·是否连续 GC 都出现了上述几种情况(注意是同时出现,不是出现 个)
只有满足所有条件,虚拟机才有可能抛出如下 OOM:
java.lang .OutOfMemoryErr or: GC overhead limit exceeded 
尽管虚拟机限制的条件如此严格,但是在绝大部分场合,还是会抛出堆溢出错误 这个 OOM
只起到辅助作用,帮助提示系统分配的堆可能太小,因此虚拟机并不强制一定要开启这个错误
提示,可以通过关闭－XX :-UseGCOverheadLimit 来禁止这种 OOM 产生。
==================================== 类加载器 ====================================
  类加载器的设计初衷, 后来的应用, 为了实现而对原有规则的扰乱, 好与不好我也不知道, 但是我觉得它似乎可以在导包问题上发挥一下
  各个类加载器本质就是到指定路径加载类,类真正被加载是通过 findclass, 而 loadClass 是个递归调用, 用来实现双亲委派
  如果没有使用双亲委派模型,都由各个加载器自行去加载的话,如果用户自己也编写了一个名为 java.lang.Object 的类,并放在程序的 ClassPath 中,
那系统中就会出现多个不同的 Object 类, Java 类型体系中 基础的行为也就无从保证
  热部署首先要卸载掉加载此模块的所有Class的类加载器,卸载类加载器会导致所有类的卸载。要破坏双亲委派机制, 重写 loadClass
  线程上下文类加载器也没什么特殊的吧,同样是在上面的圈子里
14、Tomcat 正统的类加载器架构
  主流的 Java 服务器,如 Tomcat... 都实现了自己定义的类加载器,而且一般还都不止一个 因为一个功能健全Web 服务器,都要解决如下的这些问题：
	a. 部署在同一个服务器上的两个 Web 应用程序所使用的 Java 类库可以实现相互隔离这是最基本的需求,两个不同的应用程序可能会依赖同一个第三方类库的不同
	版本,不能要求每个类库在一个服务器中只能有一份,服务器应当能够保证两个独立应用程序的类库可以互相独立使用
    b. 部署在同一个服务器上的两个 Web 应用程序所使用的 Java 类库可以互相共享。这个需求与前面一点正好相反,但是也很常见,例如用户可能有 10 个使用 
	Spring组织的应用程序部署在同 台服务器上,如果把 10份 Spring 分别存放在各个应用程序的隔离目录中,将会是很大的资源浪费一一这主要倒不是浪费磁盘空间
	的问题,而是指类库在使用时都要被加载到服务器内存,如果类库不能共享,虚拟机的方法区就会很容易出现过度膨胀的风险
    c. 服务器需要尽可能地保证自身的安全不受部署的 Web 应用程序影响 目前,有许多主流的 Java Web 服务器自身也是使用 Java 语言来实现的 因此服务器本身也有
	类库依赖的问题, 般来说,基于安全考虑,服务器所使用的类库应该与应用程序的类库互相独立
  由于存在上述问题,在部署 Web 应用时,单独的一个ClassPath 就不能满足需求了,所以各种 Web 服务器都不约而同地提供了好几个有着不同含义的 ClassPath 
路径供用户存放第三方类库。被放置到不同路径中的类库具备不同的访问范围和服务对象,通常每一个目录都会有一个相应的自定义类加载器去加载放置在里面的Java类库
  tomcat把Java 类库放置在这4组目录中,每一组都有独立的含义,分别是：
	放置在/common 目录中 类库可被Tomcat 和所有的 Web 应用程序共同使用
	放置在/server 目录中 类库可被 Tomcat 使用
	放置在/shared 目录中 类库可被所有的 Web 应用程序共同使用,但对 Tomcat 自己不可见
	放置在/WebApp/Web-INF 目录中 类库仅仅可以被该 Web 应用程序使用,对 Tomcat 和其它Web 应用程序都不可见
  如果有 10 个Web 应用程序都是用 Spring 来进行组织和管理的话,可以把 Spring 放到 Common或Shared 目录下让这些程序共享 Spring 要对用户程序的类进行管理,
自然要能访问到用户程序的类,而用户的程序显然是放在/WebApp WEB-INF 目录中的

	实现这个我觉得也好简单, tomcat 进程启动时 classpath 中不加入以上目录, 再专门有对应的类加载器去相应目录中去加载
    我觉得用多个子加载器是为了解决隔离问题,而子加载器要把类委托给父加载器不行再自己加载,目的是解决共享问题

29、类加载器
a.
手动写了一个 com.xryj.ExampleT 类打成jar包放入 /usr/local/app/jdk1.8.0_77/jre/lib/ext 下,
  Class.forName("com.xryj.ExampleT").getClassLoader() --> sun.misc.Launcher$ExtClassLoader@7ea987ac

bootstrapLoader 加载以下文件(Launcher.getBootstrapClassPath().getURLs(),好像也能通过 System.getProperty("sun.boot.class.path"))
	file:/usr/local/app/jdk1.8.0_77/jre/lib/resources.jar:file:/usr/local/app/jdk1.8.0_77/jre/lib/rt.jar:file:/usr/local/app/jdk1.8.0_77/jre/lib/sunrsasign.jar:file:/usr/local/app/jdk1.8.0_77/jre/lib/jsse.jar:file:/usr/local/app/jdk1.8.0_77/jre/lib/jce.jar:file:/usr/local/app/jdk1.8.0_77/jre/lib/charsets.jar:file:/usr/local/app/jdk1.8.0_77/jre/lib/jfr.jar:file:/usr/local/app/jdk1.8.0_77/jre/classes
extClassloader加载以下文件 (System.getProperty("java.ext.dirs"))
	/usr/local/app/jdk1.8.0_77/jre/lib/ext:/usr/java/packages/lib/ext
appClassLoader加载以下文件 (System.getProperty("java.class.path"))
	/usr/local/app/jdk1.8.0_77/jre/lib/charsets.jar:/usr/local/app/jdk1.8.0_77/jre/lib/deploy.jar:/usr/local/app/jdk1.8.0_77/jre/lib/ext/cldrdata.jar:/usr/local/app/jdk1.8.0_77/jre/lib/ext/dnsns.jar:/usr/local/app/jdk1.8.0_77/jre/lib/ext/jaccess.jar:/usr/local/app/jdk1.8.0_77/jre/lib/ext/jfxrt.jar:/usr/local/app/jdk1.8.0_77/jre/lib/ext/localedata.jar:/usr/local/app/jdk1.8.0_77/jre/lib/ext/nashorn.jar:/usr/local/app/jdk1.8.0_77/jre/lib/ext/sunec.jar:/usr/local/app/jdk1.8.0_77/jre/lib/ext/sunjce_provider.jar:/usr/local/app/jdk1.8.0_77/jre/lib/ext/sunpkcs11.jar:/usr/local/app/jdk1.8.0_77/jre/lib/ext/zipfs.jar:/usr/local/app/jdk1.8.0_77/jre/lib/javaws.jar:/usr/local/app/jdk1.8.0_77/jre/lib/jce.jar:/usr/local/app/jdk1.8.0_77/jre/lib/jfr.jar:/usr/local/app/jdk1.8.0_77/jre/lib/jfxswt.jar:/usr/local/app/jdk1.8.0_77/jre/lib/jsse.jar:/usr/local/app/jdk1.8.0_77/jre/lib/management-agent.jar:/usr/local/app/jdk1.8.0_77/jre/lib/plugin.jar:/usr/local/app/jdk1.8.0_77/jre/lib/resources.jar:/usr/local/app/jdk1.8.0_77/jre/lib/rt.jar:/home/tyx/app/mygit/javaBase/target/classes:/home/tyx/.m2/repository/junit/junit/4.10/junit-4.10.jar:/home/tyx/.m2/repository/org/hamcrest/hamcrest-core/1.1/hamcrest-core-1.1.jar:/home/tyx/.m2/repository/cglib/cglib/2.2/cglib-2.2.jar:/home/tyx/.m2/repository/asm/asm/3.1/asm-3.1.jar:/usr/local/app/idea-IC-191.7479.19/lib/idea_rt.jar
	--虽然这里没有工程的类路径, 但是在 jconsole 工具里看到是有 /home/tyx/app/mygit/javaBase/target/classes 的, 说明通过IDE启动java程序是会把工程的类
	路径加到 classpath 中

b.
  分析了源码,里面有些墨盒操作实现搞不懂不去管了,以下所说不保证完全正确. 类加载器的委托机制就是通过 java.lang.ClassLoader#loadClass 这个方法递归实现的,
有必要特此说明一下,如果加载类时用 findClass 不走委托机制,当一个类调用 loadClass 后,并不会直接将其加载,而是交给父类加载器,直到顶层类加载器(而且一定
会传到顶层的哈,能不能加载我不管),然后再仍次向下进行加载(这里所说仍将向下我觉得没什么意义,也是无奈之举吧因为用递归实现,比如我把一个类 
com.xryj.ExampleT,把完包放 %JAVE_HOME/jre/lib/ext 下了,ext/boot 类加载器加载哪些类本质不就是到对应的目录中加载jar包么, 所以传到 boot 自然是加载不到,
还是回到了 ext 这一层代码往下走是调用 findClass,肯定是能加载到的吧,于是 com.xryj.ExampleT 的类加载器就是 ext.)。前面这个一括到底的括号快说完了,
补充一下类真正被加载(加载字节码)是我觉得通过 findClass 的, 调了 loadClass 也会进一调 findClass, 包括调用 boot 时的方法也叫 findBootstrapClassOrNull

  说一下书中自定义类加载例子为什么要删除 IDE 中的类,因为他是用 myClassLoader.loadClass("***"); 所以不删的话肯定直到 app 类加载器中了,而没有达到让
类加载器是 myClassLoader 的目的。若类加载器是 myClassLoader 那必然会走重写的 findClass,我要说的是调用 findClass 也是从 ClassLoader#loadClass 进去的
  书中说的两种不删 IDE中类的方案,方案一是让 ext 成为 MyClassLoader 的父加载器, 创建类加载器时可以指定父类加载器。方案二其是道理类似,让父加载器为 null, 相当于父加载器就是 boot 了。两种方案都是让父加载器加载不到类,只能交给 MyClassLoader
引述书中：由于 loadClass 指定了 resolve 为 false, 所以不会进行连接阶段的继续执行,这也就解释了为什么通过类加载器加载并不会导致类的初始化

c. (源自网上说法,做为补充)
	5.2 类加载器的委托机制：
		当Java虚拟机要加载第一个类的时候,到底派出哪个类加载器去加载呢？
		(1).首先当前线程的类加载器去加载线程中的第一个类(当前线程的类加载器：Thread类中有一个get/setContextClassLoader(ClassLoader cl)) 
		  但是没验证成功, 不怪我, 谁知道我在 run 方法中写的第一行代码之前有没有执行过别的
		(2).如果类A中引用了类B,Java虚拟机将使用加载类A的类加载器来加载类B (这个已验证过 findclass 加载也是这样)
		(3).当然我觉得以上说法是隐式的,显示是可以指定具体类加载器的哈

d. 破坏双亲委派机制
  热部署首先要卸载掉加载此模块的所有Class的类加载器,卸载类加载器会导致所有类的卸载
	破坏双亲委派机制, 重写 loadClass
    @Override
    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
        synchronized (getClassLoadingLock(name)) {
            Class<?> klass = findLoadedClass(name);
            if (klass == null) {
                if (name.startsWith("java.") || name.startsWith("javax")) {
                    try {
                        klass = getSystemClassLoader().loadClass(name);
                    } catch (Exception e) {
                    }
                } else {
                    try {
                        klass = this.findClass(name);
                    } catch (ClassNotFoundException e) {
                        //ignore
                    }
                    if (klass == null) {
                        if (getParent() != null) {
                            klass = getParent().loadClass(name);
                        } else {
                            klass = getSystemClassLoader().loadClass(name);
                        }
                    }
                }
            }
            if (null == klass) {
                throw new ClassNotFoundException("The class " + name + " not found.");
            }
            if (resolve) {
                resolveClass(klass);
            }
            return klass;
        }
    }

  在运行期间加载了多少class,可以通过 -verbose:class 观察到
  JVM 规定了一个 Class 保有在满足以下三个条件时才会被卸载：
	该类的所有实例已经被 GC
	该类的 classLoader 实例被回收
	该类的 class 实例没有在其它地方被引用

不能定义与JDK 核心类库完全限定名相同的类, java.lang.ClassLoader#preDefineClass 方法中会做安全性检查

setContextClassLoader(); getContextClassLoader(); 如果当前线程没有设置类加载器, 他将和父线程保持同样的类加载器
java.sql 下接口的类加载器都是根加载器, 第三方厂商提供的类库驱动则是由系统类加载器加载的
  --是不是说子类父类, 接口实现类之间不是一个类加载器会有问题
  不是的
	class ExampleChile1 extends Date {}
	Date dd = new ExampleChile1();
	System.out.println(Date.class.getClassLoader());// null 因为是 根/引导类加载器
	System.out.println(dd.getClass().getSuperclass().getClassLoader());// null 同上
	System.out.println(dd.getClass().getClassLoader());// sun.misc.Launcher$AppClassLoader@1f7182c1
	
  MyClassLoader("/usr/local/app/mygit/javaBase/target/classes/", null);创建自定义类加载器时, 父加载器传空不传空差别很大
  Class<?> c1 = myClassLoader.loadClass("classloader.demo.ExampleChile");
  Example ec = (Example/ExampleChile) c1.newInstance();// 报错
  亲测了一下, 是不行的, instanceof 也是同理 , 是不是说只要显示的写类名 Example 都是系统类加载器呀, 打印一下
  System.out.println(Example.class.getClassLoader());// sun.misc.Launcher$AppClassLoader@18b4aac2
  System.out.println(c1.getClassLoader());// classloader.demo.MyClassLoader@4b67cf4d
  但当我看到了 
  public class Example {
	private Example	 example;
	// 被自定义过的类加载器加载的 Example 对象调用时
	public void setExample(Object instance ) throws ClassNotFoundException, InstantiationException, IllegalAccessException{
		System.out.println(new Example().getClass().getClassLoader());//classloader.demo.MyClassLoader@38cdedfd 
		System.out.println(instance instanceof Example);// true
		Example ee = (Example) instance;// 没有报错
  }
  }
  我又懂了好多, 这句话【如果类A中引用了类B,Java虚拟机将使用加载类A的类加载器来加载类B】被验证了

  jdbc 之所以破坏双亲委派(根加载器委托子加载器加载类), 是因为 java.sql.DriverManager.getConnection, 看下路径名不用多说了
  话说 java.sql.DriverManager#getConnection 用到了 callerCL = Thread.currentThread().getContextClassLoader(); 我也不想细看了
  猜想一下吧, 什么线程上下文类加载器呀, 不过就是一个传参的媒介罢了, 没有任何新变化
  顺便一定要提一下:
public class com.mysql.jdbc.Driver extends NonRegisteringDriver implements java.sql.Driver {
    public Driver() throws SQLException {}
    static {
        DriverManager.registerDriver(new Driver());
    }
}
==================================== 锁优化 ====================================
16、
	而这里说的"上下文",以程序员的角度来看,是方法调用过程中的各种局部的变量与资源 以线程的角度来看,是方法的调用找中存储的各类信息 
	而以操作系统和硬件的角度来看, 则是存储在内存、缓存和寄存器中的一个个具体数值
	物理硬件的各种存储设备和寄存器是被操作系统内所有线程共享的资源,当中断发生,从线程A切换到线程B去执行之前,操作系统首先要把线程A的上下文数据妥善
	保管好,然后把寄存器 内存分页等恢复到线程B挂起时候的状态,这样线程B被重新激活后才能仿佛从来没有被挂起过,这种保护和恢复现场的工作,免不了涉及一系列
	数据在各种寄存器 缓存中的来回拷贝,当然不可能是一种轻量级的操作
    线程切换的上下文(Context),它一般包括通用寄存器(General Purpose Register)的内容和程度计数器(Program Counter)的内容.切出时操作系统需要将
上下文保存到内存中,切入时需要从内存中恢复被选中线程上上下文

自旋锁, 锁消除(逃逸分析), 锁粗化
轻量级锁能提升程序同步性能的依据是"对于绝大部分的锁,在整个同步周期内都是不存在竞争的"这一经验法则 如果没有竞争,轻级锁便通过 CAS 操作成功避免了使用
互斥量的开销；但如果确实存在锁竞争,除了互斥 的本身开销 ,还额外发生了 CAS作的开销 因此在有竞争的情况下,轻量级锁反而会比传统的重量级锁更慢

如果说轻量级锁是在无竞争的情况下使用 CAS 操作去消除同步使用的互斥, 那偏向锁就是在无竞争的情况下把整个同步都消除掉,连CAS 操作都不去做了

级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态,这几个状态会随着竞争情况逐渐升级
轻量级锁如果成功,当前线程获得锁,如果失败,表示其他线程竞争锁,当前线程便尝试使用自旋来获取锁, 
  --自旋不自旋是不是, 偏向锁与轻量级锁是重要的区别？偏向则直接放弃不会自旋
  --它俩可以认为在性能上几乎是等同, 我想说下重量锁比它俩重在哪, 1. 所维护一个队列吧装着阻塞的线程 2. 保存线程上下文吧

自旋锁:
	参数：-XX:+UseSpinning  -XX:+PreBlockSpin
  如果物理机器有一个以上的处理器或者处理器核心,能让两个或以上的线程同时并行执行,我们就可以让后面请求锁的那个线程稍等一会,但不放弃处理器的执行时间,
看看持有锁的线程是否很快就会释放锁。为了让线程等待,我们只须让线程执行一个忙循环(自旋),这项技术就是所谓的自旋锁
  如果锁被占用的时间很短,自旋等待的效果就会非常好,反之如果锁被占用的时间很长,那么自旋的线程只会白白消耗处理器资源,而不会做任何有价值的工作,
这就会带来性能的浪费。因此自旋等待的时间必须有一定的限度 如果自旋超过了限定的次数仍然没有成功获得锁,就应当使用传统的方式去【挂起】线程 自旋次数的
默认值是十次

  在 JDK 6 中对自旋锁的优化,引人了自适应的自旋 自适应意味着自旋的时间不再是固定的了,而是由前一次在同 个锁上的自旋时间及锁的拥有者的状态来决定的。
如果在同一个锁对象上,自旋等待刚刚成功获得过锁,并且持有锁的线程正在运行中,那么虚拟机就会认为这次自旋也很有可能再次成功,进而允许自旋等待持续相对
更长的时间,比如持续 100 次忙循环. 另一方面,如果对于某个锁,自旋很少成功获得过锁,那在以后要获取这个锁时将有可能直接省略掉自旋过程,以避免浪费处理器资源

锁消除:
	锁消除是指虚拟机即时编译器在运行时,对一些代码要求同步,但是对被检测到不可能存在共享数据竞争的锁进行消除,锁消除的主要判定依据来源于逃逸分析的数据
支持(第11章已经讲解过逃逸分析技术),如果判断到一段代码中,在堆上的所有数据都不会逃逸出去被其他线程访问到 ,那就可以把它们当作栈上数据对待,认为它们
是线程私有的,同步加锁自然就无须再进行

锁粗化:
  原则上,我们在编写代码的时候,总是推荐将同步块的作用范围限制得尽量小--在共享数据的实际作用域中才进行同步,这样是为了使得需要同步的操作数量尽可能变少,
即使存在锁竞争,等待锁的线程也能尽可能快地拿到锁大多数情况下,上面的原则都是正确的 但是如果一系列的连续操作都对同一个对象反复加锁和解锁,甚至加锁操作
是出现在循环体之中的,那即使没有线程竞争,频繁地进行互斥同步操作也会导致不必要的性能损耗
  如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁,将会把加锁同步的范围扩展(粗化)到整个操作序列的外部

轻量级锁:
  如果出现两条以上的线程争用同一个锁的情况,那轻量级锁就不再有效,必须要膨胀为重 级锁
  轻量级锁能提升程序同步性能的依据是"对于绝大部分的锁,在整个同步周期内都是不存在竞争的"这一经验法则 如果没有竞争,轻级锁便通过 CAS 操作
成功避免了使用互斥量的开销(我能想到的是至少要创建一个队列)

偏向锁
虚拟机将会把对象头中的标志位设置为 01、把偏向模式设置为 1，表示进入偏向模式 同时使用 CAS 操作把获取到这个锁的线程的 ID 录在对象的 Mark Word 之中
而作为绝大多数对象哈希码来源的 Object::hashCode()方法,返回的是对象的一致性哈希码,这个值是能强制保证不变的,
它通过在对象头中存储计算结果来保证第一次计算之后,再次调用该方法取到的哈希码值永远不会再发生改变 因此,当 个对象已经计算过一致性哈希码后,
它就再也无法进入偏向锁状态了；而当一个对象当前正处于偏向锁状态,又收到需要计算其一致性哈希码请求时,它的偏向状态会被立即撤销,并且锁会膨胀为重量级锁

--我觉得 轻量级锁与偏向锁本质是一回事么, 都是 cas 

synchronized 代码块同步是使用monitorenter 和monitorexit指令实现的, 任何对象都有一个monitor与之关联,当且一个monitor被持有后,它将处于锁定状态。
线程执行到monitorenter 指令时,将会尝试获取对象所对应的monitor的所有权,即尝试获得对象的锁。

==================================== 线程 ====================================
自我假定：
   a. cpu 利用率是以占用时间片为准则的, 到用了时间片就认为使用了 cpu, 哪怕自旋
   b. 有一个关键问题需要解决, 操作系统分配时间片时, 是否知道各线程状态, 如果不知道好像不可能, 因为分配一次时间片到不同的线程, 要进行一次上下文切换
     我觉得操作系统有办法知道这个, 否则分配时间片将线程自己是否非阻塞也太浪费资源了	 
   c. 我不得不做出另一个假定, 操作系统分配时间片时, 线程习惯用哪个 cpu 还会断续用那个 cpu, 否则一次时间片分配就要线程上下文切换(我占着 cpu 只要给我时间片我还占着 cpu)

线程的状态 : 可以通过 getState() 方法获取
	NEW
	RUNNABLE: READY + RUNNING(他俩之间切换是系统调度控制, 还有个方法yield可以提醒系统调度)
		我觉得哈,操作系统能控制的只有分配时间片,他也不能做到叫 cpu 立即给线程用
		  操作系统书中(3.3.2.3 时间片大小的确定 P93)说时间片太小意味着频繁的线程上下文切换 
		  cpu 时间片切换只会是在 READY <--> RUNNING 或 READY <--> READ 状态之间, 哪个引起上下文切不用说了
		  READY <--> RUNNING 分析：时间片分给了 READ 的线程, 他立即去获取cpu,如果能拿到就 --> RUNNING (我又灵机一动 并行时间片多于 cpu core 数才更合理)
		  BLOCKED/WAITING <--> READY: 这好像没啥好分析的,I/O线束或调用 notify() 就这样了呗

	BLOCKED: 一个线程发起一个阻塞I/O(Blocking I/O),或申请一个由其它线程持有的独占资源(如锁)时,相应的线程会处于该状态. 线程并不会占用处理器资源,
	  当阻塞I/O操作完成后, 或者线程获得了其申请的资源,该线程的状态又可转化为 RUNNABLE 
	WAITING: 一个线程执行某些特定方法之后,就会处于这种等待其它线程执行另外一些特定操作的状态,特定方法包括 Object.wait(),Thread.join(),
	  LockSupport.park. 能够使线程从 WAITING 变为 RUNNABLE 的相应方法包括: Object.notify(), Object.notifyAll(), LockSupport.unpark() 
	TIMED_WAITING: 与 WAITING 相似,区别在于该状态的线程并非无限制地等待其它线程执行特定操作,而是处于带有时间状态的等待状态,超时自动转为 RUNNABLE
	TERMINATED: 已经执行结束的线程处于该状态. 由于一个线程实例只能被启动一次. Thread.run()正常返回或者由抛出异常使线程处于该状态
	引申：
	      1. 我分析 BLOCKED 与 WAITING 可认为是等同吧,应该是不占用时间片(应该是不占用,因为时间片分配的控制权在操作系统,线程状态不对就不分配么, 
				话又说回来占用时间片拿不到cpu 也是一样的吧, 因为拿不到cpu就没有线程上下文切换不消耗性能),因为这两种状态的线程很多时top 查看 cpu 
				占用并不多,虽然不占用但如果经常切换状态的话对性能影响也不小,毕竟要保存线程上下文

32位jvm 中除 long/double 类的任何基础和引用类型的写操作都是原子的,可以用 volatile 解决,volatile 能保证变量读写操作的原子性
(似乎是在 volatile 的两个功能下顺便实现的)

导致自发上下文切换的情况：
	Thread.sleep Object.wait Thread.yield Thread.join LockSupport.park
	线程发起了I/O操作(阻塞式)或者等待其它线程持有的锁
非自发上下文件切换：时间片用完


21、Java代码在编译后会变成Java字节码,字节码被类加载器加载到JVM里,JVM执行字节码,最终需要转化为汇编指令在CPU上执行
经我观察,4core CPU ,程序中只有一个线程,top命令查看进程占cpu用 200%,两个线程时 200%,三个线程时 300%,四个线程时 400%,八个线程时 400%...
  但是一个线程占200% 我分析这个线程确实是用两core 跑的,但对程序执行效率并没有提高,两个线程时也是用这两core

如何减少上下文切换
  避免使用锁,如将数据的ID按照Hash算法取模分段,不同的线程处理不同段的数据
  引申：例如将本要存 LinkedBlockingQueue 的数据取 hash%[线程数] 后存入 HashMap 中

死锁
  jstack 77235
  "Thread-1" #11 prio=5 os_prio=0 tid=0x00007f7618243800 nid=0x285b waiting for monitor entry [0x00007f75ff9e3000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at thread.DeadLockDemo$2.run(DeadLockDemo.java:31)
        - waiting to lock <0x00000000d7208e38> (a java.lang.String)
        - locked <0x00000000d7208e68> (a java.lang.String)

"Thread-0" #10 prio=5 os_prio=0 tid=0x00007f7618241800 nid=0x285a waiting for monitor entry [0x00007f75ffae4000]
   java.lang.Thread.State: BLOCKED (on object monitor)
        at thread.DeadLockDemo$1.run(DeadLockDemo.java:17)
        - waiting to lock <0x00000000d7208e68> (a java.lang.String)
        - locked <0x00000000d7208e38> (a java.lang.String)
  尝试使用定时锁,使用 tryLock(timeout)

锁的持有线程在锁的获得之后和锁释放之前所执行的代码被称为临界区(critical section)

22、volatile的应用
	内存屏障(Memory barriers)：是一组处理器指令,用于实现对内存操作的顺序限制
	有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码,通过查IA-32架,构软件开发者手册可知,Lock前缀的指令在多核处理器下会引发了两件事情
		1)将当前处理器缓存行的数据写回到系统内存
		2)这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效
	  LinkedTransferQueue 使用 volatile变量时,用一种追加字节的方式来优化队列出队和入队的性能, 一个对象的引用占4个字节,它追加了15个变量(共占60个字节),
	  再加上父类的value变量,一共64个字节

	1. volatile
	1.1. 在java内存模型中,也会存在缓存一致性问题和指令重排序的问题
	1.3. volatile关键字的两层语义, 容易忘的是禁止指令重排序。
	　  先看一段代码,假如线程1先执行,线程2后执行, stop 不加 volatile 可能导致死循环
		//线程1
		boolean stop = false;
		while(!stop){
			doSomething();
		}
		//线程2
		stop = true;
	1.4. //线程1:
		context = loadContext();   //语句1
		inited = true;             //语句2
		//线程2:
		while(!inited){
		  sleep()
		}
		doSomethingwithconfig(context);
		 　　前面举这个例子的时候,提到有可能语句2会在语句1之前执行,那么久可能导致context还没被初始化,而线程2中就使用未初始化的context去进行操作,导致程序出错。
		 这里如果用volatile关键字对inited变量进行修饰,就不会出现这种问题了,因为当执行到语句2时,必定能保证context已经初始化完毕。

23、线程同步机制的底层助手:内存屏障
  获得锁和释放锁分别执行的两个动作：刷新处理器缓存、冲刷处理器缓存。jvm 底层实际上借助内存屏障(Memory Barrier/Fence),来实现这两个动作
  内存屏障是被插入到两个指令之间进行使用的,作用是禁止编译器处理器重排序从而保障有序性,为了实现禁止重排序功能,这个指令有个副作用,
  刷新处理器缓存、冲刷处理器缓存,从而保证可见性

23、
  在并发编程中使用HashMap可能导致程序死循环。而使用线程安全的HashTable效率又非常低下,基于以上两个原因,便有了ConcurrentHashMap的登场机会
  HashMap在并发执行put操作时会引起死循环,是因为多线程会导致HashMap的Entry链表形成环形数据结构,一旦形成环形数据结构,Entry的next节点
  永远不为空,就会产生死循环获 取Entry
24、
执行 notify()方法后,当前线程不会立即释放对象锁,wait线程也不会马上得到对象锁,要等待执行notify方法的线程,退出syn块之后。
当线程是 wait()/sleep/join ,调用线程对象的 interrupt 方法会出现 InterruptedException 

26、
public class IncorrectDCLSingletion {
  private static IncorrectDCLSingletion instance = null;
  private IncorrectDCLSingletion() {
  }
  public static IncorrectDCLSingletion getInstance() {
    if (null == instance) {// 操作①：第1次检查
      synchronized (IncorrectDCLSingletion.class) {
        if (null == instance) {// 操作②：第2次检查
          instance = new IncorrectDCLSingletion();// 操作③
        }
      }
    }
    return instance;
  }
}

操作③可以分解为以下伪代码所示的几个独立子操作：
objRef = allocate(IncorrectDCLSingletion.class); // 子操作①：分配对象所需的存储空间
invokeConstructor(objRef); // 子操作②：初始化objRef引用的对象
instance = objRef; // 子操作③：将对象引用写入共享变量

  临界区内的操作可以在临界区内被重排序。因此,JIT编译器可能将上述的子操作重排序为：子操作①→子操作③→子操作②,即在初始化对象之前将对象的
引用写入实例变量instance(正如我们在第2章清单2-10所示的Demo中所看到的现象)。由于锁对有序性的保障是有条件的,而操作①(第1次检查)
读取instance变量的时候并没有加锁,因此上述重排序对操作①的执行线程是有影响的：该线程可能看到一个未初始化(或未初始化完毕)的实例,
即变量instance的值不为null,但是该变量所引用的,对象中的某些实例变量的变量值可能仍然是默认值,而不是构造器中设置的初始值。也就是说,
一个线程在执行操作①的时候发现instance不为null,于是该线程就直接返回这个。instance变量所引用的实例,而这个实例可能是未初始化完毕的,
这就可能导致程序出错！而加上volatile关键字,被修饰的共享变量的写操作之前会插入释放屏障防止重排序,从而保证了有序性。

27、过早唤醒：不该唤醒的线程由于调用notifyAll()方法被唤醒但条件不成立仍然要wait()等待造成资源浪费。过早唤醒用Condition接口来解决

28、static class AlignHotVariable extends PlainHotVariable{
        // 用于填充,6个long 类型的变量 ,总占用内存为 6*8 = 48 字节
        // 加上继承父类的一个变量value,那么总共该对象 占用内存为：8字节对象头 + 8字节父类变量+ 6*8字节填充变量 = 64字节,
        // 正好满足一个对象全部在一个缓存行中,消除了伪竞争问题
        public long p1,p2,p3,p4,p5,p6;
    }

==================================== 堆外内存, 零拷贝 ====================================

3、
a. Linux 操作系统和驱动程序运行在内核空间, 应用程序运行在用户空间。两者不能简单地使用指针传递数据, 因为Linux使用的虚拟内存机制,用户空间
的数据可能被换出,当内核空间使用用户空间指针时,对应的数据可能不在内存中。用户空间的内存映射采用段页式,而内核空间有自己的规则；
b. os分配给每个进程一个独立的、连续的、虚拟的地址内存空间,该大小一般是4G(32位操作系统,即2的32次方),其中将高地址值的内存空间分配给os占用,
  linux os占用1G,window os占用2G；其余内存地址空间分配给进程使用。
c. 通常32位Linux内核虚拟地址空间划分0~3G为用户空间,3~4G为内核空间(注意,内核可以使用的线性地址只有1G)。注意这里是32位内核地址空间划分,
64位内核地址空间划分是不同的。

进程寻址空间0~4G
进程在用户态只能访问0~3G,只有进入内核态才能访问3G~4G  
进程通过系统调用进入内核态
每个进程虚拟空间的3G~4G部分是相同的  
进程从用户态进入内核态不会引起CR3的改变但会引起堆栈的改变(cr3 好像可以理解为寄存器)

  vmstat 是Virtual Meomory Statistics(虚拟内存统计)的缩写,可对操作系统的虚拟内存、进程、CPU活动进行监控
  在linux下还有一个虚拟内存的概念,虚拟内存就是为了满足物理内存的不足而提出的策略,它是利用磁盘空间虚拟出的一块逻辑内存,用作虚拟内存的
磁盘空间被称为交换空间(Swap Space)作为物理内存的扩展,linux会在物理内存不足时,使用交换分区的虚拟内存,更详细的说,就是内核会将暂时不用
的内存块信息写到交换空间,这样以来,物理内存得到了释放,这块内存就可以用于其它目的,当需要用到原始的内容时,这些信息会被重新从交换空间读入
物理内存有时我们会看到这么一个现象：linux物理内存还有很多,但是交换空间也使用了很多。其实,这并不奇怪,例如,一个占用很大内存的进程运行时,
需要耗费很多内存资源,此时就会有一些不常用页面文件被交换到虚拟内存中,但后来这个占用很多内存资源的进程结束并释放了很多内存时,刚才被交换出
去的页面文件并不会自动的交换进物理内存,除非有这个必要,那么此刻系统物理内存就会空闲很多,同时交换空间也在被使用,就出现了刚才所说的现象了

33、ByteBuffer b=ByteBuffer.allocate(500);ByteBuffer b=ByteBuffer.allocateDirect(500);
b.putInt(j);b.getInt();
Direct 内存读写几乎是 堆内存的两倍
直接内存适合申请次数较少、访问较频繁的场合。如果需要频繁申请内存空间, 则并不适合使用直接内存
为什么我不明白? 但至少说明堆外内存也在用户空间吧

https://blog.csdn.net/judyjie/article/details/90612504
https://www.zhihu.com/question/284750570?sort=created

1、这是一个从磁盘文件中读取并且通过 Socket 写出的过程,对应的系统调用如下。
read(file, tmp_buf, len);
write(socket, tmp_buf, len);

a. 程序使用 read()系统调用,系统由用户态转换为内核态, 磁盘中的数据由 DMA(Direct memory access)的方式读取到内核读缓冲区(kernel buffer)。
  DMA过程中CPU不需要参与数据的读写,而是DMA处理器直接将硬盘数据通过总线传输到内存中。
b. 系统由内核态转为用户态, 当程序要读的数据已经完全存入内核读缓冲区以后,**程序会将数据由内核读缓冲区, 写入到用户缓冲区,
  这个过程需要CPU参与数据的读写。--这过程我觉得可以比从堆外内存读数据了
c. 程序使用 write()系统调用,系统由用户态切换到内核态,数据从用户缓冲区写入到网络缓冲区(Socket Buffer),这个过程需要CPU参与数据的读写。
d. 系统由内核态切换到用户态,网络缓冲区的数据通过DMA的方式传输到网卡的驱动(存储缓冲区)中(protocol engine)

tmp_buf = mmap(file, len);
write(socket, tmp_buf, len);
a. 这是使用的系统调用方法,这种方式的I/O原理就是将**用户缓冲区(user buffer)的内存地址和内核缓冲区(kernel buffer)的内存地址做一个映射,
  也就是说系统在用户态可以直接读取并操作内核空间的数据。
b. mmap()系统调用首先会使用DMA的方式将磁盘数据读取到内核缓冲区,然后通过内存映射的方式,使用户缓冲区和内核读缓冲区的内存地址为同一内存地址,
  也就是说不需要CPU再讲数据从内核读缓冲区复制到用户缓冲区。
当使用write()系统调用的时候,cpu将内核缓冲区(等同于用户缓冲区)的数据直接写入到网络发送缓冲区(socket buffer),然后通过DMA的方式将数据
  传入到网卡驱动程序中准备发送
c. 可以看到这种内存映射的方式减少了CPU的读写次数, 但是用户态到内核态的切换(上下文切换)依旧有四次,同时需要注意在进行这种内存映射的时候,
  有可能会出现并发线程操作同一块内存区域而导致的严重的数据不一致问题, 所以需要进行合理的并发编程来解决这些问题
d. 说白了就是通过映射减少两次拷贝(内核 --> 用户, 用户 --> 内核), 别的没变

通过 sendfile()系统调用, 可以做到内核空间内部直接进行 I/O 传输。
a. sendfile()系统调用也会引起用户态到内核态的切换,与内存映射方式不同的是,用户空间此时是无法看到或修改数据内容, 也就是说这是一次完全意义
  上的数据传输过程。
b. 从磁盘读取到内存是DMA的方式,从内核读缓冲区读取到网络发送缓冲区,依旧需要CPU参与拷贝,而从网络发送缓冲区到网卡中的缓冲区依旧是DMA方式。
c. 依旧有一次CPU进行数据拷贝,两次用户态和内核态的切换操作,相比较于内存映射的方式有了很大的进步,但问题是程序不能对数据进行修改,而只是
  单纯地进行了一次数据的传输过程。
d. 我分析一下这几个过程1: 
    1)用户态 --> 内核态, 操作: 磁盘 --DMA 拷贝--> 内核空间
    2)内核态 操作: 内核空间 --cup 拷贝--> 用户空间 (理解为是可直接操控 byte 数组了)  --> 用户态
    3)用户态 操作: 用户空间 --cup 拷贝--> 内核空间 (其实就是与上面交换一下么)  --> 内核态
    4)内核态 操作: 内核空间 --DMA 拷贝--> 磁盘 (其实是与一相反的) --> 用户态
    5) 2 3 两个过程用户空间是有缓存的吧, 所以避免了每个字节都要走上面一轮
e.过程2: 
    1)用户态 --> 内核态, 操作: 磁盘 --DMA--> 内核空间
    2)内核态 操作: 内核空间 --cup 映射--> 用户空间  --> 用户态
    3)用户态 操作: 用户空间 --cup 映射--> 内核空间  --> 内核态
    4)内核态 操作: 内核空间 --DMA 拷贝--> 磁盘 (其实是与一相反的) --> 用户态
    5) 少了两次拷贝么, 别的没变	
f. 过程3:
    1)用户态 --> 内核态, 操作: 磁盘 --DMA 拷贝--> 内核空间
    2)内核态 操作: 内核空间 --cpu 拷贝--> 内核空间
	3)内核态 操作: 内核空间 --DMA 拷贝--> 磁盘 (其实是与一相反的) --> 用户态

理想状态下的零拷贝I/O: 依旧是系统调用 sendfile(), sendfile(socket, file, len);
借助于硬件上的帮助,我们是可以办到的。之前我们是把页缓存的数据拷贝到socket缓存中,实际上我们仅仅需要把缓冲区描述符传到socket缓冲区,再把数据长度传过去,
这样DMA控制器直接将页缓存中的数据打包发送到网络中就可以了,可以看到在这种模式下,是没有一次CPU进行数据拷贝的,所以就做到了真正意义上的零拷贝
g. 过程4:
    1) 内核态, 操作: 磁盘 --DMA 拷贝--> 内核空间
    2) 内核态, 操作: 内核空间 --DMA 拷贝--> 磁盘
    3) 没有 cpu 参与, 没有状态切换
h.再补充一下我理解的堆外内存吧:
    1) 用户空间读写 --映射(DirectByteBuffer)--> 内核空间
	2) 所以说 DirectByteBuffer 就是两个空间的映射, 两个空间都能操作他

NIO中内存映射方式I/O：
首先要说明的是,JavaNIO中的Channel(通道)就相当于操作系统中的内核缓冲区,有可能是读缓冲区,也有可能是网络缓冲区,而Buffer就相当于操作系统中
的用户缓冲区
	File file = new File("test.zip");
	RandomAccessFile raf = new RandomAccessFile(file, "rw");
	FileChannel fileChannel = raf.getChannel();
	MappedByteBuffer buffer = fileChannel.map(FileChannel.MapMode.READ_ONLY, 0, fileChannel.size());
NIO中的FileChannel.map()方法其实就是采用了操作系统中的内存映射方式,将内核缓冲区的内存和用户缓冲区的内存做了一个地址映射。 
这种方式适合读取大文件,同时也能对文件内容进行更改,但是如果其后要通过SocketChannel发送,还是需要CPU进行数据的拷贝
	processData();
	// 数据处理完成以后,打卡一个SocketChannel
	SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress("", 1234));
	// 这时依旧需要CPU将内核缓冲区的内容拷贝到网络缓冲区
	socketChannel.write(buffer);
NIO中的零拷贝：
	File file = new File("test.zip");
	RandomAccessFile raf = new RandomAccessFile(file, "rw");
	FileChannel fileChannel = raf.getChannel();
	SocketChannel socketChannel = SocketChannel.open(new InetSocketAddress("", 1234));
	// 直接使用了 transferTo() 进行通道间的数据传输
	fileChannel.transferTo(0, fileChannel.size(), socketChannel);
a. transferTo()方法直接将当前通道内容传输到另一个通道,**没有涉及到Buffer的任何操作,NIO中的Buffer是JVM堆或者堆外内存,
  但不论如何他们都是操作系统内核空间的内存。**也就是说这种方式不会有内核缓冲区到用户缓冲区的读写问题。
  NIO中的Buffer都在用户空间中,包括DirectBuffer,也是C语言malloc出来的一块内存。
b. transferTo()的实现方式就是通过系统调用sendfile()(当然这是Linux中的系统调用,Windows中系统调用有所不同),根据我们上面所写说这个
  过程是效率远高于从内核缓冲区到用户缓冲区的读写的。

也认识到了更多现实,首先就是Java语言得IO效率比起C和C++是远远不如的,因为有JVM的存在就导致了Java的IO永远要比其他语言多一层内存交换
零拷贝完全依赖于操作系统。操作系统支持,就有；不支持,就没有。那么linux具体怎么实现的呢？这就引入了另外两个技术点：mmap,sendfile

==================================== mysql ====================================
MySQL在5.1版引入的分区是一种简单的水平拆分,用户需要在建表的时候加上分区参数,对应用是透明的无需修改代码。
对用户来说,分区表是一个独立的逻辑表,但是底层由多个物理子表组成,实现分区的代码实际上是通过对一组底层表的对象封装,但对SQL层来说是一个
完全封装底层的黑盒子。MySQL实现分区的方式也意味着索引也是按照分区的子表定义,没有全局索引
但是分区表的总入口还是一个MySQL示例。从而导致它的并发能力非常一般,远远达不到互联网高并发的要求
分区的类型：RANGE 分区, HASH 分区...

垂直分库是根据数据库里面的数据表的相关性进行拆分,比如：一个数据库里面既存在用户数据,又存在订单数据,那么垂直拆分可以把用户数据放到用户库、把订单数据放到订单库
垂直分表是对数据表进行垂直拆分的一种方式,常见的是把一个多字段的大表按常用字段和非常用字段进行拆分,每个表里面的数据记录数一般情况下是相同
的,只是字段不一样,使用主键关联

水平拆分是通过某种策略将数据分片来存储,分库内分表和分库两部分,每片数据会分散到不同的MySQL表或库,达到分布式的效果,能够支持非常大的数据量。
前面的表分区本质上也是一种特殊的库内分表
缺点是：分片事务一致性难以解决。 尽量不要在一个事务中的SQL跨越多个分片,分布式事务一直是个不好处理的问题
实际情况中往往会是垂直拆分和水平拆分的结合,即将Users_A_M和Users_N_Z再拆成Users和UserExtras,这样一共四张表。

虽然大家都是采用分库分表方案来处理海量核心数据, 但是还没有一个一统江湖的中间件, 但是这么多的分库分表中间件全部可以归结为两大类型:
CLIENT模式: 
PROXY模式: 实现难度比较高,需要对SQL进行解析,解析后改写,需要对于Mysql协议有很深入的了解
CLIENT模式代表有阿里的TDDL, PROXY模式代表有阿里的cobar,民间组织的MyCAT
无论是CLIENT模式,还是PROXY模式。几个核心的步骤是一样的：SQL解析,重写,路由,执行,结果归并

2.1 缓存穿透
缓存穿透是指查询一个一定不存在的数据, 因为缓存中也无该数据的信息,则会直接去数据库层进行查询,从系统层面来看像是穿透了缓存层直接达到db,
从而称为缓存穿透,没有了缓存层的保护,这种查询一定不存在的数据对系统来说可能是一种危险,如果有人恶意用这种一定不存在的数据来频繁请求系统,
不,准确的说是攻击系统,请求都会到达数据库层导致db瘫痪从而引起系统故障。
2.2 解决方案
缓存穿透业内的解决方案已经比较成熟,主要常用的有以下几种：
bloom filter：类似于哈希表的一种算法,用所有可能的查询条件生成一个 bitmap,在进行数据库查询之前会使用这个bitmap进行过滤,如果不在其中则直接
过滤,从而减轻数据库层面的压力。guava中有实现BloomFilter算法
-- 我分析一下, 就是入库时把 key 写到 bitmap/bloomfilter 中呗

空值缓存：一种比较简单的解决办法,在第一次查询完不存在的数据后,将该key与对应的空值也放入缓存中,只不过设定为较短的失效时间,例如几分钟,
这样则可以应对短时间的大量的该key攻击,设置为较短的失效时间是因为该值可能业务无关,存在意义不大,且该次的查询也未必是攻击者发起,
无过久存储的必要,故可以早点失效。

要了解一下 redis 的 hash 分片策略

磁盘读取依靠的是机械运动,分为寻道时间、旋转延迟、传输时间三个部分,这三个部分耗时相加就是一次磁盘IO的时间,大概9ms左右。这个成本是访问
内存的十万倍左右；正是由于磁盘IO是非常昂贵的操作,所以计算机操作系统对此做了优化：预读；每一次IO时,不仅仅把当前磁盘地址的数据加载到内存,
同时也把相邻数据也加载到内存缓冲区中。因为局部预读原理说明：当访问一个地址数据的时候,与其相邻的数据很快也会被访问到。每次磁盘IO读取的数据
我们称之为一页(page)。一页的大小与操作系统有关,一般为4k或者8k。这也就意味着读取一页内数据的时候,实际上发生了一次磁盘IO

从二叉树的查找过程了来看,树的高度和磁盘IO的次数都是4,所以最坏的情况下磁盘IO的次数由树的高度来决定
插入或者删除元素都会导致节点发生裂变反应,有时候会非常麻烦,但正因为如此才让B树能够始终保持多路平衡,这也是B树自身的一个优势：自平衡；

红点表示是指向卫星数据的指针,指针指向的是存放实际数据的磁盘页,卫星数据就是数据库中一条数据记录。
叶子节点中还有一个指向下一个叶子节点的next指针,所以叶子节点形成了一个有序的链表,方便遍历B+树。

单元素查找:貌似与B树的查询过程没有什么区别。但实际上有两点不一样：
a、首先B+树的中间节点不存储卫星数据,所以磁盘页可以容纳更多的节点元素,相同数量的数据下,B+树就相对来说要更加矮胖,磁盘IO的次数更少。
b、由于只有叶子节点才保存卫星数据,B+树每次查询都要到叶子节点；而B树每次查询则不一样,最好的情况是根节点,最坏的情况是叶子节点

叶子节点形成有顺链表,范围查找性能更优

13、事务
	a. 脏读：脏读又称无效数据的读出,是指在数据库访问中,事务T1将某一值修改,然后事务T2读取该值,此后T1因为某种原因撤销对该值的修改,
	  这就导致了T2所读取到的数据是无效的
	b. 不可重复读：不可重复读,是指在数据库访问中,一个事务范围内两个相同的查询却返回了不同数据。这是由于查询时系统中其他事务修改的提交而
	  引起的。比如事务T1读取某一数据,事务T2读取并修改了该数据,T1为了对读取值进行检验而再次读取该数据,便得到了不同的结果
		--------------------------------------------------------------------
			事务一							|		事务二
		/* Query 1 */						|		
		SELECT * FROM users WHERE id = 1;	|
		------------------------------------|-------------------------------
											|  /* Query 2 */
											|  UPDATE users SET age = 21 WHERE id = 1;
											|  COMMIT;
		------------------------------------|-------------------------------
		/* Query 1 */						|
		SELECT * FROM users WHERE id = 1;	|
		COMMIT;								|
		--------------------------------------------------------------------
	c. 幻读是指当事务不是独立执行时发生的一种现象,例如第一个事务对一个表中的数据进行了修改,比如这种修改涉及到表中的"全部数据行"。同时,
	  第二个事务也修改这个表中的数据,这种修改是向表中插入"一行新数据"。那么以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行,
	  就好象发生了幻觉一样.一般解决幻读的方法是增加【范围锁RangeS】,锁定检锁范围为只读,这样就避免了幻读。
	  -- 范围锁这事好像不靠谱, 主键可以加范围, 那么多其它字段怎么加范围
		--------------------------------------------------------------------
			事务一											|		事务二
		/* Query 1 */										|		
		SELECT * FROM users WHERE age BETWEEN 10 AND 30;	|
		----------------------------------------------------|-------------------------------
															|  /* Query 2 */
															|  INSERT INTO users VALUES ( 3, 'Bob', 27 );
															|  COMMIT;
		----------------------------------------------------|-------------------------------
		/* Query 1 */										|
		SELECT * FROM users WHERE age BETWEEN 10 AND 30;	|
		--------------------------------------------------------------------
		上面的两个事务执行情况及现象如下：
		1.事务一的第一次查询条件是 age BETWEEN 10 AND 30;如果这是有十条记录符合条件。这时,他会给符合条件的这十条记录增加行级共享锁。
		  任何其他事务无法更改这十条记录。
		2.事务二执行一条sql语句,语句的内容是向表中插入一条数据。因为此时没有任何事务对表增加表级锁,所以,该操作可以顺利执行。
		3.事务一再次执行SELECT * FROM users WHERE age BETWEEN 10 AND 30;时,结果返回的记录变成了十一条,比刚刚增加了一条,增加的这条正是
		  事务二刚刚插入的那条。所以,事务一的两次范围查询结果并不相同。这也就是我们提到的幻读。

0、有个事得掰扯一下：
	a. 隔离级别有四种,从高到底依次为：可序列化(Serializable)、可重复读(Repeatable reads)、提交读(Read committed)、未提交读(Read uncommitted)
	b. 如果控制不好隔离级别,就有可能产生脏读、不可重复读或者幻读等读现象
	c. 别把两者搞混,如果非放一起排个序的话  (脏读)/[未提交读] -- [提交读] -- (不可重复读)-- [可重复读] -- (幻读) -- [可序列化]
	
1、未提交读(READ UNCOMMITTED)是最低的隔离级别。通过名字我们就可以知道,在这种事务隔离级别下,一个事务可以读到另外一个事务未提交的数据。
  未提交读会导致脏读
   未提交读的数据库锁情况(实现原理)：
	事务在读数据的时候并未对数据加锁。
	务在修改数据的时候只对数据增加行级共享锁(我怎么觉得应该加排它锁呢,写事务加共享锁这是原则问题)。
2、 提交读(READ COMMITTED)也可以翻译成读已提交,通过名字也可以分析出,在一个事务修改数据过程中,如果事务还没提交,其他事务不能读该数据。
		提交读可以解决脏读的现象,但是不能解决不可重复读的读现象
	提交读的数据库锁情况：
	事务对当前被读取的数据加行级共享锁(当读到时才加锁),一旦读完该行,立即释放该行级共享锁；
	事务在更新某数据的瞬间(就是发生更新的瞬间),必须先对其加 行级排他锁,直到事务结束才释放。
	引申：(当读到时才加锁)(就是发生更新的瞬间)这么说有点搞笑啊。。。而且没说明白为什么不能解决不可重复读的读现象,本质应该是读事务的
	  两次读虽然都加了共享读锁但是读完就释放了锁,让写事务钻了空子
3、可重复读(Repeatable reads)
		可重复读(REPEATABLE READS),由于提交读隔离级别会产生不可重复读的读现象。所以比提交读更高一个级别的隔离级别就可以解决不可重复读的问题。
			这种隔离级别就叫可重复读(这名字起的是不是很任性！！)。但是解决不了幻读
		可重复读的数据库锁情况
			事务在读取某数据的瞬间(就是开始读取的瞬间),必须先对其加 行级共享锁,直到事务结束才释放；
			事务在更新某数据的瞬间(就是发生更新的瞬间),必须先对其加 行级排他锁,直到事务结束才释放。
4、可序列化(Serializable)
	可序列化(Serializable)是最高的隔离级别,前面提到的所有的隔离级别都无法解决的幻读,在可序列化的隔离级别中可以解决。
	可序列化的数据库锁情况:
		事务在读取数据时,必须先对其加 表级共享锁 ,直到事务结束才释放；
		事务在更新数据时,必须先对其加 表级排他锁 ,直到事务结束才释放。
5、没太明白, 如果加上 mvcc 控制, 好多问题都不是问题了呀
		
14、锁 
	1. 行级锁是Mysql中锁定粒度最细的一种锁,行级锁能大大减少数据库操作的冲突。行级锁分为共享锁和排他锁两种
	1.1. 共享锁又称读锁,是读取操作创建的锁。其他用户可以并发读取数据,但任何事务都不能对数据进行修改(获取数据上的排他锁),直到已释放
	所有共享锁。
	在查询语句后面增加LOCK IN SHARE MODE,Mysql会对查询结果中的每行都加共享锁,当没有其他线程对查询结果集中的任何一行使用排他锁时,可以
	成功申请共享锁,否则会被阻塞。其他线程也可以读取使用了共享锁的表,而且这些线程读取的是同一个版本的数据
	用法：SELECT ... LOCK IN SHARE MODE;
		在查询语句后面增加LOCK IN SHARE MODE,Mysql会对查询结果中的每行都加共享锁
	1.2. 排他锁又称写锁,如果事务T对数据A加上排他锁后,则其他事务不能再对A加任任何类型的封锁。获准排他锁的事务既能读数据,又能修改数据
		用法：SELECT ... FOR UPDATE;
		在查询语句后面增加FOR UPDATE,Mysql会对查询结果中的每行都加排他锁
	1.4 关于表级锁,mysql可以由用户控制吗,因为mysql提供的意向锁是自动加上的听说,当然这个问题不用探究了,知道有个表级锁就好
	1.5 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快,但冲突多,行级冲突少,但速度慢。所以取了折衷的页级,
	  一次锁定相邻的一组记录。BDB支持页级锁
	1.6 Innodb中的行锁与表锁
		InnoDB行锁是通过给索引上的索引项加锁来实现的,这一点MySQL与Oracle不同,后者是通过在数据块中对相应数据行加锁来实现的。
		InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据,InnoDB才使用行级锁,否则,InnoDB将使用表锁！
		
	2.1 悲观锁 当我们要对一个数据库中的一条数据进行修改的时候,为了避免同时被其他人修改,最好的办法就是直接对该数据进行加锁以防止并发。
	   这种借助数据库锁机制在修改数据之前先锁定,再修改的方式被称之为悲观并发控制(又名"悲观锁",Pessimistic Concurrency Control,
	   缩写"PCC"),悲观并发控制主要用于数据争用激烈的环境,以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中
	2.2 在关系数据库管理系统里,乐观并发控制(又名"乐观锁",Optimistic Concurrency Control,缩写"OCC")是一种并发控制的方法。它假设多用户
	并发的事务在处理时不会彼此互相影响,各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前,每个事务会先检查在该事务
	读取数据后,有没有其他事务又修改了该数据。如果其他事务有更新的话,正在提交的事务会进行回滚。
		实现数据版本有两种方式,第一种是使用版本号,第二种是使用时间戳
		使用版本号实现乐观锁：
			1.查询出商品信息  select (status,status,version) from t_goods where id=#{id}
			2.根据商品信息生成订单
			3.修改商品status为2
			update t_goods set status=2,version=version+1 where id=#{id} and version=#{version};//引申：如果执行失败说明version变了,
		所以只用cas控制就好了用不着锁
		以上SQL其实还是有一定的问题的,就是一旦发上高并发的时候,就只有一个线程可以修改成功,那么就会存在大量的失败。对于像淘宝这样的电商
		网站,高并发是常有的事,总让用户感知到失败显然是不合理的。所以,还是要想办法减少乐观锁的粒度的
		有一条比较好的建议,可以减小乐观锁力度,最大程度的提升吞吐率,提高并发能力！如下：
		//修改商品库存 
		update item set quantity=quantity - 1 where id = 1 and quantity - 1 > 0 
		以上update语句,在执行过程中,会在一次原子操作中自己查询一遍quantity的值,并将其扣减掉1
	2.3 随着互联网三高架构(高并发、高性能、高可用)的提出,悲观锁已经越来越少的被使用到生产环境中了,尤其是并发量比较大的业务场景

==================================== bloom, bitmap, hyperloglog ====================================
删除字符串过程:
字符串加入了就被不能删除了,因为删除会影响到其他字符串。实在需要删除字符串的可以使用Counting bloomfilter(CBF),这是一种基本Bloom Filter的
变体,CBF将基本Bloom Filter每一个Bit改为一个计数器,这样就可以实现删除字符串的功能了。

Bloom Filter决不会漏掉任何一个在黑名单中的可疑地址。而至于误判问题,常见的补救办法是在建立一个小的白名单,存储那些可能别误判的邮件地址
hbase 的 bloom filter 是惰性加载的,在写压力比较大的情况下,会有不停的 compact 并产生 storefile, 那么新的storefile是不会马上将 bloom filter 加载到内存的,
等到读请求来的时候才加载

reduce side join + BloomFilter 在hadoop中的应用举例：
  SemiJoin抽取出来的小表的key集合在内存中仍然存放不下,这时候可以使用BloomFiler以节省空间。将小表中的key保存到BloomFilter中,在map阶段过滤
  大表,可能有一些不在小表中的记录没有过滤掉(但是在小表中的记录一定不会过滤掉),这没关系,只不过增加了少量的网络IO而已。最后再在reduce
  阶段做表间join即可

Bitmap 有什么用
快速排序:
  所有的数据不能重复。即不可对重复的数据进行排序和查找。
  只有当数据比较密集时才有优势
快速去重, 查找
好像只能处理数字吧, 可以把字母做一下转化, 26*2+10+xxx

==================================== 网络 ====================================

第一次握手 → 客户端请求建立连接。
第二次握手 → 服务端应答客户端,并请求建立连接。
第三次握手 → 客户端针对服务端请求确认应答。
这样就完成TCP三次握手 = 一条TCP连接建立完成 = 可以开始发送数据
	引申：之所以握多次手主要是为了排除网络延迟的影响
	我觉得之所以是三个握手是保证两端都有两次通信,因为不能通过准确时间来确定网络是否通畅,只能通过两次通信的时间差

为什么TCP建立连接需要三次握手？
为了防止服务器端因为接收了早已失效的连接请求报文从而一直等待客户端请求,从而浪费资源。
TCP三次握手有什么漏洞吗？
漏洞：☛ SYN洪泛攻击
通过网络服务所在的端口发送大量伪造原地址的攻击报文,发送到服务端,造成服务端上的半开连接队列被占满,从而阻止其他用户进行访问
解决方案：
无效连接监控释放
延缓TCB分配方法
防火墙
TCP中的四次挥手：
四次挥手即终止TCP连接,就是指断开一个TCP连接时,需要客户端和服务端总共发送4个包以确认连接的断开。
注意：可以是客户端先发出中断,也可以是服务器端先发出中断。甚至是两方同时发出中断的情况也是有的！

第一次挥手：客户端发送关闭请求
第二次挥手：服务端响应客户端关闭请求
第三次挥手：服务端发送关闭请求
第四次挥手：客户端发送关闭确认请求
--第四次挥手：客户端收到FIN=N报文后,就知道可以关闭连接了,但是他还是不相信网络,怕服务器端不知道要关闭,所以发送ack=N+1后进入TIME_WAIT状态,如果Server端没有收到ACK则可以重传。服务器端收到ACK后,就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复,则证明服务器端已正常关闭,那好,我客户端也可以关闭连接了。最终完成了四次握手
我觉得四次挥手的目的就是防止第三次挥手客户端收不到
去掉不行, 为什么? 无论三次还是四次挥手, 主要是为了保证客户端有请求还要有确认, 这样我才相信你的请求是真的
--上面解释得不太好, 三次握手可以解读为时间差, 四次握手完全是保障两边都把数据写完对方收到, 而且这个过程中不考虑网络拦截问题, 二三之间是 server 端把数据
写完, 还要等四次是保障 client 处理完 server 发过去的数据
https://blog.csdn.net/qq_38950316/article/details/81087809

UDP: 将数据及源和目的封装成数据包中,不需要建立连接
--------
http: 
回过头来看 keep-alive (又称持久连接,连接复用)做的就是复用连接, 保证连接持久有效。
画外音: Http 1.1 之后 keep-alive 默认支持并开启,目前大部分网站都用了 http 1.1 了,也就是说大部分都默认支持连接复用了

HTTP的短连接&长连接:
所谓短连接,就是每次请求一个资源就建立连接,请求完成后连接立马关闭。每次请求都经过"创建tcp连接->请求资源->响应资源->释放连接"这样的过程
所谓长连接(persistent connection),就是只建立一次连接,多次资源请求都复用该连接,完成后关闭。要请求一个页面上的十张图,只需要建立一次tcp连接,然后依次请求十张图,等待资源响应,释放连接
所谓并行连接(multiple connections),其实就是并发的短连接
具体client和server要从短连接到长连接最简单演变需要做如下改进:
a. client发出的HTTP请求头需要增加Connection:keep-alive字段
b. Web-Server端要能识别Connection:keep-alive字段,并且在http的response里指定Connection:keep-alive字段,告诉client,我能提供keep-alive服务,并且"应允"client我暂时不会关闭socket连接

在HTTP/1.0里,为了实现client到web-server能支持长连接,必须在HTTP请求头里显示指定: Connection:keep-alive
在HTTP/1.1里,就默认是开启了keep-alive,要关闭keep-alive需要在HTTP请求头里显示指定: Connection:close

==================================== 锁 ====================================

对于同步方法,JVM采用ACC_SYNCHRONIZED标记符来实现同步。 对于同步代码块。JVM采用monitorenter、monitorexit两个指令来实现同步

b. 同步代码块使用monitorenter和monitorexit两个指令实现
大致内容如下： 可以把执行monitorenter指令理解为加锁,执行monitorexit理解为释放锁。 每个对象维护着一个记录着被锁次数的计数器。未被锁定的对象的该计数器为0,
当一个线程获得锁（执行monitorenter）后,该计数器自增变为 1 ,当同一个线程再次获得该对象的锁的时候,计数器再次自增。当同一个线程释放锁（执行monitorexit
指令）的时候,计数器再自减。当计数器为0的时候。锁将被释放,其他线程便可以获得锁

c. 无论是ACC_SYNCHRONIZED还是monitorenter、monitorexit都是基于Monitor实现的,在Java虚拟机(HotSpot)中,Monitor是基于C++实现的,由 ObjectMonitor 实现
源码地址：objectMonitor.hpp
ObjectMonitor中有几个关键属性：
_owner：指向持有ObjectMonitor对象的线程
_WaitSet：存放处于wait状态的线程队列
_EntryList：存放处于等待锁block状态的线程队列
_recursions：锁的重入次数
_count：用来记录该线程获取锁的次数

ObjectMonitor类中提供了几个方法,如 enter exit wait notify notifyAll 等。sychronized加锁的时候,会调用objectMonitor的enter方法,解锁的时候会调用exit方法。

Java的线程是映射到操作系统原生线程之上的,如果要阻塞或唤醒一个线程就需要操作系统的帮忙,这就要从用户态转换到核心态,因此状态转换需要花费很多的处理器
时间,对于代码简单的同步块（如被synchronized修饰的get 或set方法）状态转换消耗的时间有可能比用户代码执行的时间还要长,所以说synchronized是java语言中
一个重量级的操纵

https://mp.weixin.qq.com/s?__biz=MzI3NzE0NjcwMg==&mid=2650120784&idx=1&sn=3436c978f0d7ab3bb672d03689518902&chksm=f36bbf71c41c36672a3a6a7edebe0b913f2f5cf33d75d594d228f086ec7bdb9e253ab0beeae4&scene=21#wechat_redirect
看看几张图就行了

==================================== 排序 ====================================
对比一下选择和插入排序:
0、快速记忆十大排序算法: 三三堆
1、冒泡没啥好说的
2、选择排序对数组和链表来说是一样的, 插入排序链表比数据要好
4、希尔, 插入排序的改进版, 如果说对插入排序深入思考未必我就搞不出来个希尔(牛逼吹大了我真搞不出来), 不像计数推演出桶是轻而一举之事
  很厉害了, 居然不是用递归思想把复杂度降下来的
  
5、归并, 感觉像二分, 但是 merge 两个数组时, 好像得开辟一个长度为两个数组和的空间, 否则太耗时
6、快排, 还是有点绕的, 两个下标, 当前下标向后推进, 或者尾端下标向前逼进. 但是案例中只用一个下标, 是不是我这种效率更高
  快排是从外往里, 归并是从里往外, 他俩都是二分, 多分会不会好一些呢, 好像不行因为没法划分区间均匀
7、堆排序
  堆排的思想与官员选拔/科举考试的思想一致, 还有一点高明之处是隶属关系与办公地点不耦合在一起
  堆排容易误入递归
8、计数排序, 数组下标值自带计数了
9、桶排序, 哈哈这就是 MR 全排序的思想源头啊, 确定桶个数有点意思: int bucketNum = (max - min) / arr.length + 1; 桶内排序可以用插入
  可以认为是计数排序的升级版, 数据区间小于数组长度时可认为两者等同, 数据区间大小数组长度时桶更好
  计数排序扮演出桶排序其实好简单
10、基数排序, 这思想也相当牛逼了, 感觉是桶排序的变种啊, 但有牛逼之处, 先比较低位, 厉害厉害
  高位相当于是桶, 低位比较相当于桶内排序, 所以先比较低位是让多个桶的桶内排序在明面上进行, 在公共区域做一次就行了, 这种思路真厉害,
  也可以认为是递归思想(每级比较逻辑相同, 但是外部可以直接看到层级, 同堆的"递归", 而一般的递归只有到了内部才能看到下一级), 
  比较分为多级, 每次都比较低维空间, 高维空间的比较很容易, 或者也可以认为每个维度的比较都很容易。所以呀他该是桶与递归的结合了
  总结一下牛逼的思想, 按段位排, 第一个是递归, 第二第三是堆/计数, 第四就是这里了
  其实明确次数的叫桶, 次数不明要深入进去的叫递归
  