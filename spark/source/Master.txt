
private[deploy] class org.apache.spark.deploy.master.Master(override val rpcEnv: RpcEnv, address: RpcAddress, webUiPort: Int, val securityMgr: SecurityManager, val conf: SparkConf) extends ThreadSafeRpcEndpoint with Logging with LeaderElectable {
	override def receive: PartialFunction[Any, Unit] = {
		case RegisterApplication(description, driver) =>
			logInfo("Registering app " + description.name)
			val app = createApplication(description, driver)
			registerApplication(app)
			persistenceEngine.addApplication(app)
			driver.send(RegisteredApplication(app.id, self))
			schedule()
	}
	private def schedule(): Unit = {
		val shuffledAliveWorkers = Random.shuffle(workers.toSeq.filter(_.state == WorkerState.ALIVE))
		val numWorkersAlive = shuffledAliveWorkers.size
		var curPos = 0
		for (driver <- waitingDrivers.toList) {
			var launched = false
			var isClusterIdle = true
			var numWorkersVisited = 0
			while (numWorkersVisited < numWorkersAlive && !launched) {
				val worker = shuffledAliveWorkers(curPos)
				isClusterIdle = worker.drivers.isEmpty && worker.executors.isEmpty
				numWorkersVisited += 1
				if (canLaunchDriver(worker, driver.desc)) {
					val allocated = worker.acquireResources(driver.desc.resourceReqs)
					driver.withResources(allocated)
					launchDriver(worker, driver)
					waitingDrivers -= driver
					launched = true
				}
				curPos = (curPos + 1) % numWorkersAlive
			}
		}
		startExecutorsOnWorkers()
	}
  
	private def startExecutorsOnWorkers(): Unit = {
		for (app <- waitingApps) {
			val coresPerExecutor = app.desc.coresPerExecutor.getOrElse(1)
			if (app.coresLeft >= coresPerExecutor) {
				val assignedCores = scheduleExecutorsOnWorkers(app, usableWorkers, spreadOutApps)
				for (pos <- 0 until usableWorkers.length if assignedCores(pos) > 0) {
					allocateWorkerResourceToExecutors(
					app, assignedCores(pos), app.desc.coresPerExecutor, usableWorkers(pos))
				}
			}
		}
  }
	private def allocateWorkerResourceToExecutors(app: ApplicationInfo, assignedCores: Int, coresPerExecutor: Option[Int], worker: WorkerInfo): Unit = {
		val numExecutors = coresPerExecutor.map { assignedCores / _ }.getOrElse(1)
		for (i <- 1 to numExecutors) {
			val allocated = worker.acquireResources(app.desc.resourceReqsPerExecutor)
			val exec = app.addExecutor(worker, coresToAssign, allocated)
			launchExecutor(worker, exec)
			app.state = ApplicationState.RUNNING
		}
	}
	private def launchExecutor(worker: WorkerInfo, exec: ExecutorDesc): Unit = {
		worker.addExecutor(exec)
		worker.endpoint.send(LaunchExecutor(masterUrl, exec.application.id, exec.id, exec.application.desc, exec.cores, exec.memory, exec.resources))
		exec.application.driver.send(ExecutorAdded(exec.id, worker.id, worker.hostPort, exec.cores, exec.memory))
	}
  
}