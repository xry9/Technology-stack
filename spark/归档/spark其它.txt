spark 与hadoop MapReduce性能对比
5、reduce越多效率超高
====================================
persist()与checkpoint()
深入一点讨论，rdd.persist(StorageLevel.DISK_ONLY) 与 checkpoint 也有区别。前者虽然可以将 RDD 的 partition 持久化到磁盘，但该 partition 由 blockManager 管理。
一旦 driver program 执行结束，也就是 executor 所在进程 CoarseGrainedExecutorBackend stop，blockManager 也会 stop，被 cache 到磁盘上的 RDD 也会被清空
（整个 blockManager 使用的 local 文件夹被删除）。而 checkpoint 将 RDD 持久化到 HDFS 或本地文件夹，如果不被手动 remove 掉（ 话说怎么 remove checkpoint 过的 RDD？ ），
是一直存在的，也就是说可以被下一个 driver program 使用，而 cached RDD 不能被其他 dirver program 使用。
=======================================
----
分区处理（没有测试）
1)	parquet分区
通过DataFrame.write.partitionBy("列名").parquet("存储路径")
注意：分区功能适用于parquet格式的输出文件，在向hive输出数据时无法使用partitionBy
