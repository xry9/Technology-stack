2.3 原子操作的实现原理
	不用看了太底层

3.1.3 从源代码到指令序列的重排序	
表3-3 内存屏障类型表

3.2.4 重排序对多线程的影响
  --细品一下
class ReorderExample {
  int a = 0; boolean flag = false; 
  public void writer() { 
    a = 1; // 1 
	flag = true; // 2 
  }
  Public void reader() { 
    if (flag) { // 3 
	  int i = a * a; // 4 …… 
	}
  }
}
原来指令重排序问题这么大, 如果不知道指定重排序这个事就不会这个多线程程序有问题。1 2 之间没有依赖, 3 4 之间有依赖, 怎么解决? 
在 flag 上加 volatile 而不是在 a 上加吧

3.4.4 volatile 内存语义的实现
----
LoadLoad屏障：
对于这样的语句 Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
StoreStore屏障：
对于这样的语句 Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
  --但是我觉得最多是刷写自己变量的缓存到主存
LoadStore屏障：
对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被执行前，保证Load1要读取的数据被读取完毕。
StoreLoad屏障：
对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的(冲刷写缓冲器，
清空无效化队列)。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能。

内存屏障分类
按照可见性保障来划分
内存屏障可分为：加载屏障(Load Barrier)和存储屏障(Store Barrier)。
加载屏障：StoreLoad屏障可充当加载屏障，作用是使用load 原子操作，刷新处理器缓存，即清空无效化队列，使处理器在读取共享变量时，先从主内存或其他处理器的
  高速缓存中读取相应变量，更新到自己的缓存中
存储屏障：StoreLoad屏障可充当存储屏障，作用是使用 store 原子操作，冲刷处理器缓存，即将写缓冲器内容写入高速缓存中，使处理器对共享变量的更新写入高速缓存
  或者主内存中
这两个屏障一起保证了数据在多处理器之间是可见的。

按照有序性保障来划分
内存屏障分为：获取屏障(Acquire Barrier)和释放屏障(Release Barrier)。
获取屏障：相当于LoadLoad屏障与LoadStore屏障的组合。在读操作后插入，禁止该读操作与其后的任何读写操作发生重排序；
释放屏障：相当于LoadStore屏障与StoreStore屏障的组合。在一个写操作之前插入，禁止该写操作与其前面的任何读写操作发生重排序。
这两个屏障一起保证了临界区中的任何读写操作不可能被重排序到临界区之外。
--我觉得有个前提: 读读, 写写 重排序没有问题, 因为涉及不到与其它线程的交互, 不对呀 写写不行
----引处网络

以 ReorderExample 为例脑洞一下, flag 为 volatile
a. 在每个volatile写操作的前面插入一个StoreStore屏障 
  好理解, 我 flag 写之前, 我前面的操作一定要写完, 
b. 在每个volatile写操作的后面插入一个StoreLoad屏障
  这个更好理解了
c. 在每个volatile读操作的后面插入一个LoadLoad屏障
  保障我后面的读不要跑到我前面
d. 在每个volatile读操作的后面插入一个LoadStore屏障
  保障我后面的写不要跑到我前面
总结: cd 两条保障了我后面的不要跑到我前面, 我前面的会不会跑到我后面好像确实不需要关注
但是 3 操作前有一个 a 的读操作读到的是 a=0; 其实是有问题的

https://blog.csdn.net/ly262173911/article/details/106063924

Thread1:
	a = 1;
	flag = true;
Thread2:
    if (flag) {
	  int i = a * a;
	}
----
Thread1:
volatile a = k; // volatile 读不可以有下面的写上去
b=4;
Thread2:
k = b;
-- a b 在 Thread1 中没有依赖关系, 但是由于 Thread2 的存在, 其实他们是有依赖的
-- 因为读操作是其它线程影响到我, 写操作是我影响到其它线程, 写是主动行为读是被动行为
写写 重排序肯定是有问题的, 例子1
写读 重排也是有问题的, 例子2, 我写出的值可能通过其它线程影响到了我读的值
读写 重排序好像没问题, 同上, 本应先读后写变成先写后读就不可以了
读读与写写虽然在两个线程中相互对应, 但是只要保证写写顺序不乱, 你管我怎么读呢

我觉得内存屏障就是限制重排序, 写操作后就是要冲刷处理器缓存, 读操作要不要刷新处理器缓存, 与写操作后会不会强制无效化其它处理缓存有关了
而那四种内存屏障恰了遇到了上下文的那四种操作而已, 我觉得这样理解会简单好多, 但是仔细分析不对呀, 我说的是 storestore + loadstore + loadload + loadstore

分析一下 表3-5 volatile重排序规则
做个比喻 普通读写是本地变量, volatile 读写是全局变量
全局的读写之间完全不可以重排序, 我觉得过激了, 全局读读是可以重排序的
全局与普通变量之间我觉得是没有必要做任何限制的
当然我的刚才分析的前提是 "普通读写是本地变量", 但是如果前提不存在呢, 即普通读写被裹挟而被动刷新处理器或冲刷处理器了

如果模型是写冲刷处理器缓存并无效化其它处理缓存, 这种情况普通变量与 volatile 变量无异了, 因为冲刷和刷新影响的不只自身变量
如果模型是写只冲刷处理器缓存, 读自己去刷新处理器缓存:
对 volatile 变量来说与上一种模型无异
全局写与普通写, 之间的顺序有关于变通写能否影响到全局, 所以不能重排
普通读与全局读, 不行, 原因类似
全局写与普通读, 全局读与普通写之间怎么重排都无所谓吧

3.6 final域的内存语义

3.8.4 基于类初始化的解决方案
  JVM在类的初始化阶段(即在Class被加载后，且被线程使用之前)，会执行类的初始化。在执行类的初始化期间，JVM会去获取一个初始化锁。
  这个锁可以同步多个线程对同一个类的初始化(内部内方式的单例就是这个原理吧)
	讲了很多, 有精力可以细看一下
	
5.6 Condition接口
	有精力时可以研究一下, 把等待队列的细节讲了很多
