========================第一章========================

2、包括操作数据层( Operational Data Store, ODS) 、明细数据层( Data Warehouse Detail , DWD )、
汇总数据层( Data Warehouse Summary, DWS )和应用数据层( Application Data Store, ADS )。

操作数据层( Operational Data Store, ODS )
明细数据层( Data Warehouse Detail , DWD )
汇总数据层( Data Warehouse Summary, DWS )  / data warehouse service 服务数据层
应用数据层( Application Data Store, ADS )
还应该加上一个 DIM(dimension)
数据集市 data mart
----
GMV：Gross Merchandise Volume 是成交总额（一定时间段内）的意思。多用于电商行业，一般包含拍下未支付订单金额
SPU, Standard Product Unit 标准化产品单元
SKU, Stock Keeping Unit 库存量单位
我觉得 华为 P30 手机可以是一个 SPU, 红色的 * 可以是一个 SKU, 如果有两个/多个属性, 红色 64G 可以是一个 SKU

========================第二章========================
2.2.1 页面事件
  日志采集SDK对于不同事件的实现 大致是类似的：只是对于通用的用户行为, 抽象出来一些通用的接口方法。我们把常用的行为类别单独列出来, 作为单独的事件来处理, 
如本节要讲的页面事件(页面浏览行为)。每条页面事件日志记录三类信息 ①设备及用户的基本信息：②被访问页面的信息, 这里主要是一些业务参数(如商品详情页的商品
ID 、所属的店铺等) ; ③访问基本路径(如页面来源、来源的来源等), 用于还原用户完整的访问行为。
  对于页面事件, 不同的SDK有不同的实现, 有些采集 SD 选择在页面创建时即发送日志。结合业务分析, UT提供了页面事件的无痕埋点,  即无须开发者进行任何编码即可实现
UT 提供了两个接口, 分别在页面展现和页面退出时调用。以进入手机淘宝的某店铺详情页来举例, 当进入该店铺详情页时, 调用页面展现的接口, 该接口会记录页面进人时
的一些状态信息, 但此时不发送日志；当从该店铺详情页离开时(可能是在店铺详情页上点击某个商品到了对应的商品详情页, 也可能是退出了手机淘宝, 抑或是点击返回, 
返回到了之前的一个页面), 调用页面退出的接口, 该接口会发送 日志。。除了基础的两个接口外, 还提供了添加页面扩展信息的接口在页面离开前, 使用该接口提供的
方法给页面添加相关参数, 比如给店铺详情页添加店铺 ID 、店铺类别(天猫店铺或淘宝店铺) 等。
  除此之外, 为了平衡采集、计算和分析的成本, 在部分场景下我们选择采集更多的信息来减少计算及分析的成本。于是,  UT 提供了透传参数功能。所谓透传参数, 
即把当前页面的某些信息, 传递到下一个页面甚至下下一个页面的日志中
2.2.2 控件点击及其他事件
  和浏览器客户端的日志采集一样 , 交互日志的采集无法规定统一的采集内容, 交互类的行为呈现出高度自定义的业务特征。
  先来说说控件点击事件。控件点击事件比页面事件要简单得多, 首先, 它和页面事件一样, 记录了基本的设备信息、用户信息：其次, 它记录了控件所在页面名称、控件
名称、控件的业务参数等。由于控件点击事件的逻辑简单得多, 就是操作页面上的某个控件, 因此只需把相关基础信息告诉采集SDK即可。
  再来说说其他事件。所谓其他事件, 就是用户可以根据业务场景需求, 使用自定义事件来采集相关信息。从某种程度上说, 它几乎能满足用户的所有需求, 包括页面事件
和控件点击事件, 只是若采用通用的页面事件埋点方法, UT会帮助实现一些额外的功能(如上个页面的信息)。UT 提供了一个自定义埋点类, 其包括：①事件名称：
②事件时长 ③事件所携带的属性：④事件对应的页面。当然, 具体实现什么功能, 需要带哪些内容, 各个采集 SDK 可以自行决定。

2.2.3 特殊场景
  上述场景均为一个行为产生一条日志, 如一次浏览、一次点击等。如此用来处理普通的业务是足够的, 但对于阿里巴巴巨大的业务体量来说, 为了平衡日志大小, 减小流量
消耗、采集服务器压力、网络传输压力等, 采集 SDK 提供了聚合功能, 对某些场景如曝光或一些性能技术类日志 , 我们提倡在客户端对这类日志进行适当聚合, 以减少
对日志采集服务器端的请求 , 适当减小日志大小。总体思路就是每个曝光的元素般都属于一个页面, 利用页面的生命周期来实现适当的聚合及确定发送时机。拿曝光
日志来举例, 若 个商品的一次曝光就对应一条日志的话, 那么在搜索结果页的一次滚屏浏览过程中将产生几十条甚至上百条日志, 从下游使用及分析的角度来说, 其实
只是想知道哪些内容被曝光, 此时为了平衡业务需求及减少全链路资源消耗, 采集 SDK 提供了本地聚合功能, 在客户端对这类日志进行聚合, 上传聚合后的日志到采集服务器即可。

2.2.4 H5 & Native 日志统一
  简单来说,  APP 分为两种： 种是纯 Native APP; 种是既有 Native又有 H5 页面嵌入的 APP , 即 Hybrid APP 
  后续内容...
========================第三章========================
3.3.5 数据漂移的处理
  说的好乱啊, 本质应该是这样, 抽数据时不是扫库而是拉日志, 
  时间戳字段分为四类：
数据库表中用来标识数据记录更新时间的时间戳字段（假设这类字段叫 modified time ）。
数据库日志中用来标识数据记录更新时间的时间戳字段·（假设这类宇段叫 log_time
数据库表中用来记录具体业务过程发生时间的时间戳字段 （假设这类字段叫 proc_time
标识数据记录被抽取到时间的时间戳字段（假设这类字段extract time

理论上，这几个时间应该是 致的，但是在实际生产中，这几个时间往往会出现差异，可能的原因有以下几点
由于数据抽取是需要时间的， extract_ti me 往往会晚于前三个时间
·前台业务系统手工订正数据时未更新 modified_time
由于网络或者系统压力问题， log_time 或者 modified_time 会晚proc time
--至于说的漂移和解决方案好像挺扯的呀，不看了

  当update操作时，如果更新的数据没有实际变更,update_time是不会跟着变的
========================第五章========================
在"双门"的 24 小时中，支付峰值高达 12 万笔／秒，下单峰值达 17 .5 万笔／

5.3 流式数据模型
  实时建模跟离线建模非常类似, 数据模型整体上分为五层(ODS DWD DWS ADS DIM) 
  由于实时计算的局限性，每一层中并没有像离线做得那么宽，维度和指标也没有那么多
  
  DWD 层是在 ODS 层基础上，根据业务过程建模出来的实时事实明细层，对于访问日志这种数据（没有上下文关系，并且不需要等待过程的记录），会回流到离线
系统供下游使用，最大程度地保证实时和离线数据在 层和 DWD 层是一致的。例如 订单的支付明细表、退款明细表、用户的访问日志明细表
--我怎么觉得通常来说建模 DWD 都同 ODS 呢, 当然如果有分库分表, 他俩是不同的
DWS：
订阅明细层的数据后，会在实时任务中计算各个维度的汇总指标。如果维度是各个垂直业务线通用的，则会放在实时通用汇总层，作为通
用的数据模型使用。比如电商网站的卖家粒度，只要涉及交易过程，就会跟这个维度相关，所以卖家维度是各个垂直业务的通用维度，其中的汇
总指标也是各个业务线共用的。例如：电商数据的几大维度的汇总表家、商品、买家）。

 ADS
个性化维度汇总层，对于不是特别通用的统计维度数据会放在这一层中，这里计算只有自身业务才会关注的维度和指标，眼其他业务线一般没有 集，常用于 些垂直创新业务中。例如：手机淘宝下面的某个爱逛街、微淘等垂直业务。

DIM
实时维表层的数据基本上都是从离线维表层导出来的，抽取到在线
系统中供实时应用调用。这一层对实时应用来说是静态的，所有的 ETL
处理工作会在离线系统中完成。维表在实时应用的使用中跟离线稍有区
别，后面章节中会详细说明。例如：商品维表、卖家维表、买家维表、
类目维表。

DIM
  实时维表层的数据基本上都是从离线维表层导出来的，抽取到在线系统中供实时应用调用。这一层对实时应用来说是静态的，所有的 ETL处理工作会在离线系统中完成。
维表在实时应用的使用中跟离线稍有区别，后面章节中会详细说明。例如：商品维表、卖家维表、买家维表、类目维表。

下面通过简单的例子来说明每一层存储的数据。
ODS层：订单粒度的变更过程， 一笔订单有多条记录。
DWD层：订单粒度的支付记录，一笔订单只有一条记录。
DWS 卖家的实时成交金额，一个卖家只有一条记录，并且指标在实时刷新。
ADS 外卖地区的实时成交金额，只有外卖业务使用。
DIM 层：订单商品类目和行业的对应关系维表。

5.3.2 多流关联
  订单与支付会涉及到流关联呀
  
--流式数据可以不用去重, 所以同样要分 ods dwd dws, 至于 ads 应该就是在 dws 上的一些 join 操作吧, 所以流式处理也没问题, 但是数据存在哪呢 kafka 里? 

========================第八章========================
数据模型就是数据组织和存储方法，它强调从业务、数据存取和使用角度合理存储数据

8.3 从OLTP和OLAP 系统的区别看模型万法论的选择
  OLTP 系统通常面向的主要数据操作是随机读写, 主要采用满足3NF的实体关系模型存储数据, 从而在事务处理中解决数据的冗余和一致性问题：而 OLAP 系统面向的主要
数据操作是批量读写, 事务处理中的一致性不是 OLAP所关注的, 其主要关注数据的整合, 以及在一次性的复杂大数据查询和处理中的性能, 因此它需要采用一些不同的数据
建模方法

--总结起来说, OLTP/3NF 主要操作单条数据, 读写没有压力的情况不需要冗余, 而 OLAP 往往是单表/多表扫描操作, 冗余可以提高计算效率

8.4 典型的数据仓库建模方法论 (知道一下应付面试)

8.4.1 ER 模型:数据仓库之父 Bill lnmon 提出的建模方法是从全企业的高度设计3NF 模型, 用实体关系( Entity Relationship, ER )模型描述企业业务, 在范式理论
上符合3NF。数据仓库中的 3NF OLTP 系统中的 3NF的区别在于, 它是站在企业角度面向主题的抽象
  其建模步骤分为三个阶段: 
  高层模型：一个高度抽象的模型，描述主要的主题以及主题间的关系，用于描述企业的业务总体概况
  中层模型：在高层模型的基础上，细化主题的数据项
  物理模型（也叫底层模型）：在中层模型的基础上，考虑物理存储，同时基于性能和平台特点进行物理属性的设计，也可能做一些表的合并、分区的设计等
  ER 模型在实践中最典型的代表是 Teradata 公司基于金融业务发布的FS-LDM (Financial Services Logical Data Model ）
  
8.4.2 维度模型
  选择需要进行分析决策的业务过程。业务过程可以是单个业务事件, 比如交易的支付、退款等；也可以是某个事件的状态, 比如当前的账户余额等；还可以是一系列相关
业务事件组成的业务流程, 具体需要看我们分析的是某些事件发生情况, 还是当前状态, 或是事件流转效率。
  选择粒度。在事件分析中, 我们要预判所有分析需要细分的程度, 从而决定选择的粒度。粒度是维度的一个组合
    --既然他这么说了我只能揣测一下了, 事实粒度:粒度是与业务过程对应的, 维度粒度: 维度的一个组合, 即一张表
  识别维表。选择好粒度之后, 就需要基于此粒度设计维表, 包括维度属性, 用于分析时进行分组和筛选。
  选择事实。确定分析需要衡量的指标
8.4.3 Data Vault 模型
  Data Vault Dan Linstedt 发起创建的一种模型, 它是 ER 模型的衍生, 其设计的出发点也是为了实现数据的整合, 但不能直接用于数据分
析决策。它强调建立一个可审计的基础数据层, 也就是强调数据的历史性、可追溯性和原子性, 而不要求对数据进行过度的一致性处理和整合
8.4.4 Anchor 模型
  Anchor Data Vault 模型做了进一步规范化处理,  Lars. Ri:innback 的初衷是设计 个高度可扩展的模型, 其核心思想是所有的扩展只是添加而不是修改, 
因此将模型规范到 6NF, 基本变成了 k-v 结构化模型。们看 Anchor 模型的组成
========================第九章========================

图 9.1 及其下
图 9.2

9.2.1 名词术语
数据域:
  指面向业务分析, 将业务过程或者维度进行抽象的集合, 其中业务过程可以概括为一个个不可拆分的行为事件, 在业务过程之下可以定义指标, 维度是指度量的环境, 
如买家下单事件, 买家是维度, 为保障整个体系的生命力, 数据域是需要抽象提炼, 并且长期维护和更新的, 但不轻易变动
--我觉得数据域/主题, 应该是范围比较大的分析主体, 电商: 商品 仓储 用户 供应商, 不同主题之间表会有重合
    派生指标＝ 个原子指标＋多个修饰词（可选）＋时间周期 可以理解为对原子指标业务统计范罔的圈定 如原子指标 支付金额，最近 天海外买家支付金额则为派生指标（最近 天为时间周期 海外为修饰词 买家作为维度，而不作为修饰词）


维度: 维度是度量的环境, 用来反映业务的一类属性 这类属性的集合构成一个维度, 也可以称为实体对象(维度是被当做一张表看待的), 维度属于一个数据域, 
如地理维度(其中包括国家、地区、省以及城市等级别的内容)、时间维度(其中包括年、季、月、周、日等级别的内容)
--其实通常说的几十上百个维度, 跟这里的不是一回事, 这里是集合, 而他们说的是所有集合的所有元素, 不可能有几百个角度的
维度属性: 维度属性隶属于一个维度 如地理维度里面的国家名称、同家 ID 、省份名称等都属于维度属性

派生指标: 一个原子指标＋多个修饰词（可选）＋时间周期 可以理解为对原子指标业务统计范罔的圈定 如原子指标 支付金额，最近1天海外买家支付金额则为
派生指标（最近1天为时间周期 海外为修饰词 买家作为维度，而不作为修饰词）

修饰词:指除了统计维度以外指标的业务场景限定抽象 修饰词隶属于一种修饰类型，如在日志域的访问终端类型下 有修饰词 PC 端、无线端等
  --其实就是一个维度属性么



表 9.4, 9.5
图 9.4 业务过程命名示例

9.3.2 模型层次
CMD: Common Dimension Model 公共维度模型层
...
9.3.3 


========================第十章========================
10.1.1 维度的基本概念
  主键有两种：代理键和自然键, 它们都是用于标识某维度的具体值。但代理键是不具有业务含义的键, 一般用于处理缓慢变化维

缓慢变化维: 比如顾客的联系方式，手机号码等信息可能随着顾客的所在地的更改发生变化，比如商品的价格在不同时期有上涨和下降的变化
我觉得最好的办法就是维表做拉链吧, 事实表那只能叫表合并, 但是商品表这种如果做为事实也可以拉链的, 所以我觉得没有确定结束变化的表都可以拉链

10.1.2 维度的基本设计方法
  正如 kimball 所说数据仓库的能力直接与维度属性的质量和深度成正比
  数值型字段是作为事实还是维度属性, 可以参考字段的一般用途。如果通常用于查询约束条件或分组统计, 则是作为维度属性；如果通常
用于参与度量的计算, 则是作为事实。比如商品价格, 可以用于查询约束条件或统计价格区间的商品数量, 此时是作为维度属性使用的；也可
以用于统计某类目下商品的平均价格, 此时是作为事实使用的。
--其实我的困惑是比如商品表, 既做为事实又做为维度, 做为事实时是商品主题, 做为维度时可能是销售主题, 我觉得做法是单独清洗出一张维表

10.2 维度设计高级主题
  --我觉得可能是为了解决拓展性, 
10.2.1 维度整合
所以数据由面向应用的操作型环境进人数据仓库后, 需要进行数据成。将面向应用的数据转换为面向主题的数据仓库数据, 本身就是一种集成。具体体现在如下几个方面：
命名规范的统一。表名 字段名等统一。

10.2.2 水平拆分
  如果面试时被问到雪花模型时, 也可以聊一下子, 对于某个事业部来说用不到, 以机票为例不同产品维度基本相同啊. 但对于淘宝来说, 如淘宝的商品、天猫的商品
飞猪旅行的商品... , 航旅的商品除了有这些公共属性外, 还有酒店、景点、门票、旅行等自己独特的维度属性。
  如何设计维度？针对此问题, 主要有两种解决方案：方案 是将维的不同分类 例化为不同的维度, 同时在主维度中保存公共属性是维护单 维度, 包含所有可能的属性。
  定义一个主维度用于存放公共属性；同时定义多个子维度, 其中除了包含公共属性外, 还包含各自的特殊属性。比如在阿里巴巴数据仓库维度体系中, 依据此方法, 
构建了商品维度、航旅商品维度等。
  -- 这意思就是雪花模型呗
  第二个依据是业务的关联程度。两个相关性较低的业务, 稠合在起弊大于利, 对模型的稳定性和易用性影响较大。比如在阿里巴巴数据
仓库维度体系中, 对淘系商品和 1688 商品构建两个维度。虽然淘系和1688 在底层技术实现上是统 的, 但属于不同的 BU , 业务各自发展
在数据仓库层面, 淘系和 688 属于不同的数据集市,  般不会相互调用, 业务分析人员 般只针对本数据集市进行统计分析。如果设计成
个维度, 由于不同 业务各自发展,  1688 业务变更, 此维度需要变更, 淘宝业务变更亦然, 稳定性很差；在易用性方面, 会给数据使用方造成困扰。
  --看完这段我又迷糊了

10.2.3 垂直拆分
水平拆分就是拆成多表吧, 垂直拆分是一主多从表吧
但是这么一拆之后, 表的生命周期管理就麻烦了


10.3.1 缓慢变化维(说白了就是维表的更新)
  感觉说得一地鸡毛, 但是这确实是个很重要的事
  (我觉得应该有两种, 维度值变化和维度字段增加)
  美团小姐姐举的例子是: 城市所属辖区的变化, 还有的例子是人所属城市的变化, 商品价格、所属类目的变化
  代理键方式好像没有人用, 而且用的最多的就是快照方式吧, 即始终用最新数据
  我的思路是保留历史数据, 保留业务过程, 方式是增加 isnew, 和 starttime 两个字段, endtime 最好也加上, 因为没他用起来不方便, 但是我不确定这种表叫不叫拉链

10.3.2 快照维表
  "为什么不使用代理键"这个问题。第一个原因是, 阿里巴巴数据量庞大, 使用的是阿里巴巴自助知识产权的分布式计算平台
Max Compute 。对于分布式计算系统, 不存在事务的概念, 对于每个的记录生成稳定的全局唯 的代理键难度很大, 此处稳定指某条记录每次生成的代理键都相同。
第二个原因是, 使用代理键会大大增加 ETL的复杂性, 对 ETL 任务的开发和维护成本很高。
在阿里巴巴数据仓库实践中, 处理缓慢变化维的方法是采用快照方式

10.3.3 极限存储
  我想说一句英雄所见略同啊, 细看一下
  1 透明化:
    Select * from A where ds =20160101; --> Select * from A EXST where start dt <=20160101 and end dt >20 160101 ;
  2. 分月做历史拉链表
    对于部分变化频率频繁的宇段需要过滤。例如, 用户表中存在用户积分字段, 这种字段的值每天都在发生变化, 如果不过滤的话, 
极限存储就相当于每个分区存储一份全量数据, 起不到节约存储成本的效果
  
10.3.4 微型维度
  采用极限存储, 需要避免维度的过度增长。比如对于商品维表, 每20 多亿条数据, 如果在设计商品维度时, 将值变化频繁的属性加入到商品维度中, 极限情况是每天
所有商品数据都发生变化, 此时, 极限存储没有意义；反之, 每天所有商品数据都不发生变化, 此时, 只需要存储一天的数据即可
我感觉微型维度, 水平拆分, 垂直拆分 概念上有重合呀(不重合, 上面主要是合表, 这里是拆表)
----我觉得做历史拉链时可以拆分出来
后续内容...

10.4 特殊维度
10.4.1 递归层次
  维度的递归层次, 按照层级是否固定分为均衡层次结构和非均衡层次结构。比如类目, 有固定数量的级别, 分别是叶子类目、五级类 目、
四级类目、三级类目、二级类目、 级类曰：地区, 分别是乡镇／街道区县、城市、省份、国家。对于这种具有固定数量级别的递归层次, 称
为"均衡层次结构"。比如公司之间的关系, 每个公司可能存在 个母公司, 但可能没有固定的 级、 级等层级关系。对于这种数量级别不
固定的递归层次, 称为"非均衡层次结构"
  层次结构扁平化方式处理, 我觉得没有必要一说, 因为 区县、城市、省份、国家 肯定是同时出现的, 不可以搞出个雪花模型

10.4.2 行为维度
  其中卖家主营类目和主营品牌通过卖家的商品分布和交易分布情况, 采用算法计算得到；卖家常用地址通过最近 段时间内物流中卖家的发货地址和买家的收货地址
进行统计得到。类似的维度, 都和事实相关, 如交易、物流等, 称之为"行为维度", 或"事实衍生的维度"。
  --知道有这个提法就行了, 我觉得这些字段放在事实表里最好了
10.4.3 多值维度
a. 假设设计交易父订单事实表, 则对于此事实表的每一条记录, 在商品表中都有 到多条记录与之对应。处理方式是降低事实表的粒度。

b. 在房地产销售中, 每次合同订都可能存在多个买受方的情况, 如夫妻合买等。对于合同签订事实表, 每条记录可能对应多个买受方, 而合同已经是此事实中的最细粒度,
无法通过降低粒度的方式来解决。由于合同签订的买受人 般不会太多, 所以 般采用多字段方式。考虑到扩展性, 可以通过预留宇段的方式

10.4.4 多值属性
  -- 我觉得这个概念有点问题, 既然第个值都可以做为一个维度, 怎么又...
维表中的某个属性字段同时有多个值, 称之为"多值属性" 
每个商品均有一到多个 SKU一到多个属性和一到多个标签, 所以商品和 SKU 、属性、标签都是多对多的关系(不是一对多么?)。
第一种处理方式是保持维度主键不变, 将多值属性放在维度的一个属性字段中
第二种处理方式也是保持维度主键不变, 但将多值属性放在维度的多个属性字段中。如果多值属性字段具体值的数量不固定, 则可以采用预留字段的方式

10.4.5 杂项维度
  杂项维度是由操作型系统中的指示符或者标志宇段组合而成的, 一般不在一致性维度之列。比如淘宝交易订单的交易类型宇段, 包括话费充值、司法拍卖、航旅等类型 
支付状态、物流状态等, 它们在源系统中直接保存在交易表中。
  一个事实表中可能会存在多个类似的字段, 如果作为事实存放在事实表 中, 则会导致事实表占用空间过大 如果单独建立维表, 外键关联
到事实表, 则会出现维度过多的情况；如果将这些字段删除, 则会有人不同意。
  这时, 通常的解决方案就是建立杂项维度 , 将这些字段建立到维表中, 在事实表中只需保存一个外键 即可。多个字段的不同取值组成
一条记录, 生成代理键, 存人维表中, 并将该代理键保存到相应的事实表字段下。建议不要直接使用所有的组合生成完整 的杂项维表, 在抽取
遇到新的组合时生成相应的记录即可。杂项维度 ETL 过程比一般维度略微复杂些。
但在阿里巴巴的实践中, 杂项维度不仅包含上述指示符、状态或分类等枚举宇段, 还包含很多非枚举字段, 如交易留言、交易属性针对这些字段, 不可能生成所有的组合；
同时, 由于在分布式计算系统中生成代理键的复杂度, 一般在逻辑建模中 , 会使用实体的主键作为杂项维度的主键。只考虑杂项维度, 忽略其他维度, 
但子订单维度一般是逻辑模型, 物理实现时不进行物理化, 订单杂项维度和其他维度一起, 会将维度属性退化至事实表中(毁了前面所有铺垫), 详情在事实表中描述。
  --我差点以为这就是一个在阿里不用的呢, 看下图 10.11 我觉得还是与微型维度一回事么, 问题是外键怎么生成, 用主表 id 就行吧

========================第十一章========================
11.3 周期快照事实表
  前面章节对事务事实表进行了详细的阐述, 同时给出了淘宝交易事务事实表的设计过程。事务事实表可以很好地跟踪一个事件, 并对其进
行度量, 以提供丰富的分析能力。然而, 当需要一些状态度量时, 比如账户余额、买卖家星级 商品库存、卖家累积交易额等, 则需要聚集与
之相关的事务才能进行识别计 ；或者聚集事务无法识别 , 比如 温度等。对于这些状态度量, 事务事实表是无效率的, 而这些度量也和度量
事务本身一样是有用的 , 因此,  维度建模理论给出了第二种常见的事实表一一周期快照事实表, 简称"快照事实表"。快照事实表在确定的问
隔内对实体的度量进行抽样, 这样可以很容易地研究实体的度量值, 而不需要聚集长期 事务历史
  快照事实表的设计有一些区别于事务事实表设计的性质。事务事实表的粒度能以多 种方式表达, 但快照事实表的粒度通常以维度形式声
明$事务事实表是稀疏的, 但快照事实表是稠密的 事务事实表中的事实是完全可加的, 但快照模型将至少包含一个用来展示半可加性质的事实。

  淘宝活动运营小二或者卖家经常都需要看 些交易状态数据, 比如自然年至今或者历史至今的下单金额、支付金额、支付买家数、支付商品件数等状态度
量, 对于卖家而言 , 可能每天早上都想看 下截至昨天的成交情况；对于小二 , 可能在频繁的活动周期就需要查看 次成交情况
--我感觉周期快照事实表有点像报表呢

11.4 累积快照事实表
  针对淘宝交易, 设计了淘宝交易下单／支付／确认收货事务事实表, 用于统计下单／支付／确认收货的子订单数、GMV等。但仍然有很多需求, 
此事务事实表很难满足, 比如统计买家下单到支付的时长、买家支付到卖家发货的时长、买家从下单到确认收货的时长等。如果使用事务事实
表进行统计, 则逻辑复杂且性能很差。对于类似于研究事件之间时间间隔的需求, 采用累积快照事实表可以很好地解决。
--图 11.25

11.5 三种事实表的比较
  表 11.7
11.6 无事实的事实表
  比如用户的浏览日志, 某会员某时间点浏览了淘宝首页、某会员某时间点浏览了某卖家的店铺中的某商品详情页等对于每次点击, 其事实为 , 但 般不会保存此事实。
第二种是条件、范围或资格类的, 记录维度与维度多对多之 间的系。比如客户和销售人员的分配情况、产品的促销范围等
11.7 聚集型事实表
  知道有这个东西就行了






========================第十三章========================
13.2.1 Map 倾斜

  Map 端做聚合时, 由于某些 Map Instance 读取文件的某个值特别多而引起长尾, 主要是指 Count Distinct 操作
  文件块大的 Map 数据量比较大, 在与小表进行笛卡儿积操作时, 非常耗时, 造成 Map 端长尾, 我想说不要怀疑这个事, 安全说此 task 用时 40分钟, 如果说小表也很大
这种情况是存在的理论上, 上方案:
  select e.id,d.addr from db.emp_max e join db.dept_min d on e.id=d.id; -- map join
  select e.id,d.addr from (select id from db.emp_max distribute by rand()) e join db.dept_min d on e.id=d.id; -- 2 jobs
  如果是用 tez 引擎可能只一个 job
  可以这样做也恰是印证了是因为 mapjoin 引起的, 因为第一个 mr 执行没有多长时间, 甚至这个问题严格来说不能算数据倾斜, 是数据分部不均不是数本身不均。其实
道是未必是 mapjoin 引起, 只要 map 端比较耗时的操作, 比如正则、性能差的 udf(json)、都可以有这个问题呀
select * from (select id,age from tab1 where age>18)t1 left join (select id,age from tab1)t2 on t1.id=t2.id; 一个 job

13.2.2 Join 倾斜
  尤其是在"双 ll "等大型活动期间, 长尾程度比平时更严重。比如某些大型店铺的 PV 远远超过一般店铺的 PV , 当用浏览日志数据和卖家维表关联时, 会按照卖家 
ID 进行分发, 导致某些大卖家所在Instance 处理的数据量远远超过其他 Instance , 而整个任务会因为这个长尾的 Instance 迟迟无法结束。

Join 的某路输入比较小, 可以采用 MapJoin , 避免分发引起长尾。
• Join 的每路输入都较大, 且长尾是空值导致的, 可以将空值处理成随机值, 避免聚集。
• Join 的每路输入都较大, 且长尾是热点值导致的, 可以对热点值和非热点值分别进行处理, 再合并数据。
--先 count 出热点 key 到临时表, 当然量不大也不必到临时表了
  set odps.sql.skewjoin=true/false
  set odps.sql.skewinfo=skewed_src: (skewed_key) -- 这样做也是一种很有意义的探索了, 其实很难做的, 首先要设置表名来建行任务隔离, sql 解析引擎生成 job 
    时也要做很多修改

  中华石衫说的那种优化方案是我记错了还是他说错了? 仔细推敲 join 操作的扩容方案是不成立的, 因存一个小表的话用 mapjoin 就行了, 不存小表对其中一个表
  扩容另一个表加随机数, 不科学呀, 太有局限性了, 远不如先 count, 而且相比采样 count 也更好吧, 因为采样也不能保证一定采到热点 key 吧
  
  清洗出热点数据表(处理成集合方式简单不说了)后, 原表转成两个 job, 只说处理热点数据的 job, 变成 taba join hotkey, tabb join hotkey, 其实是三次 map join 
set hive.groupby.skewindata=true;

hive.optimize.skewjoin 参数：如果大表和大表进行join操作，则可采用skewjoin
set hive.skewjoin.key=100000;
skewjoin原理：
对于skewjoin.key，在执行job时，将它们存入临时的HDFS目录。其它数据正常执行
对倾斜数据开启map join操作，对非倾斜值采取普通join操作
将倾斜数据集和非倾斜数据及进行合并操作
https://blog.csdn.net/hellojoy/article/details/82931827


13.2.3 Reduce 倾斜
  因为 Distinct 操作, 数据无法在 Map 端的 Shuffle 阶段根据 Group By 先做一次聚合操作, 以减少传输的数据量, 而是将所有的数据都传输到Reduce 端, 
当 key 的数据分发不均匀时, 就会导致 Reduce 端长尾。
----
对同 个表按照维度对不同的列进行 Count Distinct 操作, 造成Map 端数据膨胀, 从而使得下游的 Join Reduce 出现链路上的长尾。
a. Map 端直接做聚合时出现 key 值分布不均匀, 造成 Reduce 端长尾
	--热点 key 单独处理再 union all
b. 动态分区数过多时可能造成小文件过多, 从而引起 Reduce 端长尾。
  set hive.merge.mapredfiles = true;
  set mapred.reduce.tasks=20;insert overwrite table tab2 select id, name, age from tab group by id, name, age; 产生 20个文件, 最后另起一个 job 合并  
  -- 上是非分区表操作
  20 分区 400 条 数据:
    set mapred.reduce.tasks=20;
	insert overwrite table tab1 partition(class) select id,name,age,class from tab2 group by id,name,age,class;
	结果每个分区 20 条, 然后 set hive.merge.mapredfiles = true; 结果是每个分区一个文件, 所以这个参数对动态分区也起作用
	记住 hive.exec.max.dynamic.partitions.pernode 默认是 100; 
c. 多个 Distinct 同时出现在 SQL 代码中时, 数据会被分发多次, 不仅会造成数据膨胀 N 倍, 还会把长尾现象放大 N 倍。
  --细看, 以及 Multi Distinct 的思考

========================第十四章========================
14.1 数据压缩 
底层数据超过一定的时间期限后使用的频率非常低, 但是又是属于不可恢复的重要数据, 对于这部分数据就可以考虑对历史数据的分区进行 archive 压缩, 
使用 RAID file(6,3) 来存储, 以此来节省存储空间
触发条件是 alter table A partition(ds= ’ 20130101 ’) archive ; 这是不是涉及一个跨集群传输, 或者一个集群中兼容两套副本策略


14.3 存储泊理顶优化
  阿里巴巴数据仓库在资源管理的过程中, 经过不断地实践, 慢慢摸索出一套适合大数据的存储优化方法, 在元数据的基础上, 诊断、加工
成多个存储治理优化项。目前已有的存储治理优化项有未管理表、 空表最近 62 天未访问表、数据无更新无任务表 、数据无更新有任务表、开
发库数据大于 lOOGB 且无访问表、长周期表等。通过对该优化项的数据诊断 形成治理项, 治理项通过流程的方式进行运转、管理, 最终推
动各个 TL 发人员进行操作, 优化存储管理, 并及时回收优化的存储效果。在这个体系下, 形成现状分析、 问题诊断、管理优化、效果反
馈的存储治理项优化的闭环。通过这个闭环, 可以有效地推进数据存储的优化, 降低存储管理的成本。
-- 这段话好像字字珠玑呀
14.4 生命周期管理
  生命周期管理的根本目的就是用最少的存储成本来满足最大的业务需求, 使数据价值最大化。
14.4.1 生命周期管理策略
1 .周期性删除策略
所存储的数据都有 定的有效期, 从数据创建开始到过时, 可以周期性删除X天前的数据。例如对于 MySQL 业务库同步到 MaxCompute 
的全量数据, 或者 ETL 过程产生的结果数据, 其中某些历史数据可能已经没有价值, 且占用存储成本, 那么针对无效的历史数据就可以进行定期清理

2. 彻底删除策略
无用表数据或者 ETL 过程产生的临时数据, 以及不需要保留的数据, 可以进行及时删除, 包括删除元数据。
3. 永久保留策略
重要且不可恢复的底层数据和应用数据需要永久保留。比如底层交易的增量数据, 出于存储成本与数据价值平衡的考虑, 需要永久保留, 用于历史数据的恢复与核查
4. 极限存储策略
极限存储可以超高压缩重复镜像数据, 通过平台化配置手段实现透明访问：缺点是对数据质量要求非常高, 配置与维护成本比较高, 建议一个
分区有超过 5G 的镜像数据(如商品维表、用户维表)就使用极限存储。
5. 冷数据管理策略
冷数据管理是永久保留策略的扩展。永久保留的数据需要迁移到冷数据中心进行永久保存, 同时将 MaxCompute 中对应的数据删除。一般
将重要且不可恢复的、占用存储空间大于 lOOTB , 且访问频次较低的数据进行冷备, 例如 年以上的日志数据。
6. 增量表 merge 表策略
对于某些特定的数据, 极限存储在使用性与存储成本方面的优势不是很明显, 需要改成增量同步与全量 erge 的方式, 对于对应的 delt
增量表的保留策略, 目前默认保留 93 天。例如, 交易增量数据, 使用订单创建日期或者订单结束日期作为分区, 同时将未完结订单放在最大
分区中, 对于存储, 一个订单在表里只保留一份；对于用户使用, 通过分区条件就能查询某一段时间的数据。
14.4.2 通用的生命周期管理矩阵
  随着业务的发展和不断的数据实践, 我们慢慢摸索出 套适合大数据生命周期管理的规范, 主要通过对历史数据的等级划分与对表类型的划分生成相应的生命周期管理矩阵。
书上...

========================第十五章========================
十四, 十五章可以说相当重要, 可以引发很多思考, 面试就问这个(美团数仓大哥问的是, 表生命周期管理和数据质量)

如何评估数据质量的好坏, 业界有不同的标准, 而阿里巴巴对数据仓库主要从四个方面进行评估, 即完整性、准确性、一致性和及时性

15.2 数据质量万法概述
数据生产加工各个环节卡点校验

在线系统数据加工过程卡点校验，主要是指在在线业务系统的数据生成过程中进行的卡点校验
-- 线上数据与数仓数据对比(横向校验), 以及同比的环比的纵向校验
自行感知表变化, 是否增加表了, 后续人工干预, 利用元数据系统每天检查两次, 




===================================
12.1.2 元数据价值
  在数据内容面为集团数据进行数据域、数据主题、业务属性等的提取和分析提供数据素材
12.2.1 Data Profile
业务标签：根据数据归属的主题域、产品线、业务类型为数据打上不同的标签。

14.4.2 通用的生命周期管理矩阵
  PO ：非常重要的主题域数据和非常重要的应用数据, 具有不可恢复性, 如交易、日志、集团 KPI 数据、 IPO 关联表。

https://blog.csdn.net/moon_yang_bj/article/details/19259671
4、我觉得去哪机票是个主题域
主题包括
航司(航段)
代理商
乘机人(就是客户啊, 出行分析) 
产品(机票 优惠券 保险, 细分的话可以分为这三个子主题么) 订单应该算产品里的吧, 其它几个主题中也包含订单
销售: 还是有必要有这个主题, 因为看看人家 https://www.cnblogs.com/HondaHsu/p/4313053.html
  还有算收益 base_income
去哪儿给我的感觉为什么没有分主题, 其实是只分析了一个销售主题

------------------------------------------------------------
https://baijiahao.baidu.com/s?id=1649349568939493055&wfr=spider&for=pc
