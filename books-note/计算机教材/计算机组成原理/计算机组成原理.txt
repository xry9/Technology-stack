=======================第一章=======================
1、高级语言 --> 汇编语言/其它中间语言 --> 机器语言
2、指令和数据放在存储器(内存)内
3、运算器完成算数运算和逻辑运算，并将中间结果存在运算器内；控制器我自己翻译成人话就是执行指令吧；运算器和控制器组成CPU
4、设某机的指令字长16位，操作码占6地址码占4，操作码包括：存数取数，加减乘除，停机打印等
5、主存中配置两个寄存器,MAR(memory Address Register),MAR(memory Data Register)其位数即【存储字长】,随着硬件的发展它俩会集成到CPU中
6、运算器至少包含三个寄存器：ALU(算数逻辑单元),ACC(Accumulator),MQ(Multiplier-Quotient),X(操作数寄存器)。运算器可以将运算结果从 ACC 送到存储器中的 MDR ，
  而存储器的操作数也可以从 MDR 送至运算器中的 ACC/MQ/X
7、控制器完成一条指令包括：取指（从存储器），分析，执行。由 PC(Program Counter)、IR(Instruction Register 指令寄存器) 以及控制单元 CU 组成。
8、机器字长：CPU一次能处理数据的位数，通常与CPU的寄存器位数有关
9、主存容量：存储单元个数 * 存储字长 --> MAR * MDR
10、运算速度相关因素：机器主频,执行的操作,主存本身速度(取指 取数)


=======================第二章=======================
1、基本电路元器件：电子管 --> 晶体管 --> 集成电路(integrated circuit IC 芯片)


=======================第三章=======================
1、系统总线：计算机五大部件之间连到一个公共的信息传输线上，称为总线连接
2、片内总线：芯片内部寄存器之间
3、按传输信息不同又可分为：数据总线、地址总线、控制总线
  数据总线：位数与机器字长存储字长有关，如数据总线宽度为8位，指令字长为16位，CPU在取指阶段必须两次访问主存
  地址总线：位数与存储单元的位数有关，如地址总线为20根，则对应存储单元个数为 2的20次方
  控制总线：发出各种控制信号的传输线
4、总线性能指标：
  总线宽度：即根数
  总线带宽：如总线工作频率为 33MHz，总线宽度为 32 位(4B), 则总线带宽为 33*4 MBps
  总线复用用：地址总线与数据总线共用一组线路，称为总线的多路复用
5、USB(Universal Serial Bus)通用串行总线
6、双总线结构：将速度较低的I/O设备从单总线上分离出来，形成主存总线和I/O总线
7、图 3.6中 主存总线用于 CPU 与主存之间的传输；I/O 总线供 CPU 与各类I/O 设备之间的传输;DMA 用于高速I/O 设备(磁盘)与主存之间交换信息。
  在三总线结构中任一时刻只能使用一种总线。主存总线与DMA总线不能同时对主存进行存取，I/O 总线只有在 CPU 执行 I/O 命令时用到
  
=======================第四章=======================
1、I/O 设备不断增多，如果他们与存储器交换信息都通过 CPU 这将大大降低 CPU 的工作效率。为此出现了存储器与 I/O 设备直接存取方式 DMA。某种意义上存储器的性能成为计算机的核心
2、存储器按介质分：
  半导体存储器：大规模集成电路制成的芯片，缺点是断电信息丢失
  磁表面存储器：金属或塑料基体涂一层磁性材料，磁头在磁层上读写操作
  光盘存储器：用激光在在介质上读写
3、按存取方式分：
  RAM(Random Access Memory 随机存储器) ROM(Read Only Memory) 串行访问存储器（如磁盘，对磁盘读写时，首先直接指出该存储器中的某个小区域（磁道）然后再顺序访问，直到找到位置，再串行访问） 
4、存储速度，由存取时间和存取周期来表示
  存取时间：又称存储器的访问时间(Memory Access Time)，是指一次存储器操作（读/写）到完成该操作所需的全部时间
  存取周期：是指存储器完成两次独立存取操作的时间间隔。通常存取周期大于存取时间
5、存储器带宽：如存取周期为 500ns ,每个存取周期可访问 16 位，则它的带宽为 32M 位/秒
  提高存储器带宽可以用以下措施：
    缩短存取周期 增加存储字长 增加存储体（这个放弃了解吧）
6、高速缓冲存储器：
  由于I/O 设备向主存请求的级别高于CPU访存，这就出现了CPU等待I/O设备访存的现象，致使CPU空等一段时间。为了避免CPU与I/O设备争抢访存，可以在CPU与主存之间加一级缓存
  从另一角度讲，主存速度的提高跟不上CPU的发展，例如 100MHz 的处理器每 10ns 就执行一条指令，而动态RAM的典型访问时间是 60~120ns,也希望通过高速缓存来解决主存与CPU速度不匹配问题
  一般 Cache 采用高速的 SRAM 制作，价格比主存贵，容量远小于主存
7、磁盘寻址时间：磁头寻找目标磁道的时间 + 磁头等待欲读写的区段旋转到磁头正方的时间
8、磁盘阵列 RAID(Redundant Array of Independent Disks):原理是将并行处理技术引入引入到磁盘系统。
9、假设磁盘存储器共6个盘片，最外层盘面不能记录，每面共204条磁道，每条磁道共12个扇段，每个扇段有512B,磁盘机以 7200rpm 速度旋转，平均定位时间为8ms 
  存储容量： 512B * 12 * 204 * 10 
  平均寻址时间：8ms + [60s/(7200rpm)]*0.5 = 8ms + 4.165ms 
  
=======================第五章=======================
1、接口模块和DMA阶段：
  采用接口技术可以使多台I/O设备分时占用总线，使多台I/O设备互相之间也可以实现并行工作方式。但是主机(主存？)与I/O设备交换信息时，CPU要中断现行程序，即CPU与I/O设备
  还做不到绝对并行工作。为进一步提高CPU工作效率，又出现了直接存储器存取(Direct Memory Access DMA )技术，其特点是I/O设备与主存之间有一条直接数据通道，I/O设备与主存
  直接交换信息，使CPU在I/O设备与主存交换信息时能继续完成自身工作（然而到底还有没有阻塞也没说明白），资源利用率进一步提高
2、通道结构阶段：
  大型计算机中I/O设备繁多，如果I/O设备都配置专用的DMA接口，不仅增加硬件成本，而且也有众多DMA接口同时访问主存的冲突问题
  CPU对众多DMA接口管理会占用CPU的工作时间，因此大型计算机中采用I/O通道的方式： CPU <--> 主存 <--> 通道|I/O设备。感觉原理类似吧，也需要CPU的参与
3、具有I/O处理机的阶段：I/O设备与CPU的并行性更高
4、I/O设备与主机信息传递的控制方式：
  程序查询方式：CPU通过程序不断查询I/O设备是否已经做好准备，从而控制I/O设备与主机交换信息。若查得I/O设备准备就绪，就将数据从I/O接口传送至CPU,再由CPU送至主存
  程序中断方式：倘若CPU在启动I/O设备后，不查询设备是否准备就绪，继续执行自身程序，只是I/O设备准备就绪并向CPU发出中断请求才予以响应，即CPU从I/O接口读一个字经CPU送至主存
  DMA方式：虽然程序中断方式消除了程序查询方式的“踏步”现象，但是为了完成I/O设备与主机的信息交换，还不得不占用CPU内部的一些寄存器，这同样是对CPU资源的消耗。如果I/O设备
  能直接与主存交换信息而不占用CPU,这就出现了直接存储器存取(DMA)方式。主存与I/O设备交换信息时无需调用中断服务程序，若出现DMA和CPU同时访问主存，CPU总是将总线占用权
  让给DMA的这种占有称为窃取或挪用，窃取的时间一般为一个存取周期，DMA窃取存取周期时CPU尚能做内部操作(如乘法运算)
5、 书中的5.6 DMA方式 有精力可以细看
=======================第六章=======================
有精力细看吧

=======================第七章=======================
1、指令是由操作码和地址码组成的，操作码指明要完成的操作，如加减、传送、转移、移位；地址码用来指出该指令的源操作数的地址、结果的地址、下个指令的地址，这里的地址
  可以是主存的地址也可以是寄存器的地址，甚至可以是I/O设备的地址
2、四指令地址格式：
  OP | A1 | A2 | A3 | A4 
  其中 OP 为操作码, A1 为第一操作数地址, A2 为第二操作数地址, A3 为结果地址, A4 为下个指令的地地址
  如果地址字段均指示主存地址则完成一条四地址指令共需访问四次存储器（取指令一次，取操作数据两次，存放结果一次）
  因为程序中大多数指令都是按顺序执行的，面程序计数器PC既能存放当前欲执行指令的地址又有计数功能，因此它能自动形成下一条指令地址，A4可省
  中间结果可以暂存在CPU的寄存器(如ACC)中，这样可以省去A3
  ... 最后可形成一指令地址，不研究了
3、操作数类型：地址、数字、字符、逻辑数据...
4、操作类型：数据传送、算术逻辑操作、移位、转移
  