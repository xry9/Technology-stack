2.2.1 程序计数器
  程序计数器 Program Count Register,它可以看作是当前线程所执行的字节码的行号指示器 Java 虚拟机的概念模型里,
【字节码解释器】工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令,它是程序流程控制的指示器,分支、循环 跳转、异常处理、
线程恢复等基础功能都需要依赖这个计数器来完成。每条线程都需要有一个独立的程序计数器
  如果线程正在执行的是一个 Java 方法,这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是本地 Native 方法,这个计数器值为空,
此内存区域是唯一一个在《 Java 虚拟机规范 》中没有规定任何 OutOtMemoryError 情况的区域

2.2.2 Java 虚拟机栈
  与程序计数器一样 Java 虚拟机栈Java Virtual Machine Stack 也是线程私有的,它的生命周期与线程相同,每个方法被执行的时候, Java 虚拟机都会
同步创建一个栈帧 Stack Frame 用于存储局部变量表、操作数栈、动态连接、方法出口等信息 每一个方法被调用直至执行完毕的过程,
就对应着一个栈帧在虚拟机核中入栈到出栈的过程
  栈通常就是指这里讲的虚拟机栈,或者更多的情况下只是指虚拟机栈中局部变量表部分
  局部变量表存放了编译期可知的各种 Java 虚拟机基本数据类型、对象引用和 returnAddress 类型
这些数据类型在局部变量表中的存储空间以局部变量槽(Slot 来表示,其 64 位长long double 类型的数据会占用两个变量槽,其余的数据类型只占用一个,
局部变量表所需的内存在编译期间完成分配,当进入一个方法时,这个方法需要在栈帧中分配大的局部变量空间是完全确定的,在方法运行期间不会改变局部
变量表的大小 请读者注意,这里版的 "大小"是指变量槽的数量,虚拟机真正使用多大的内存空间(譬如按照一个变量槽占用32个比特、64个比特或者更多)
来实现一个变量槽,这是完全由具体的虚拟机实现自行决定的事情.
  Java 虚拟机规范中,对这个内存区域规定了两类异常状况：如果线程请求的栈深度大于虚拟机所允许的深度,将抛出 StackOverflow Error 异常；如果 Java 虚拟机栈
  容量可以动态扩展,当栈扩展时无法申请到足够的内存会抛出 OutOfMemoryError 异常

2.2.3 本地方法栈
  本地方法找(Native Method Stacks)与虚拟机栈所发挥的作用是非常相似的,其区别是虚拟机栈为虚拟机执行 Java 方法(也就是字节码)服务,而本地方法找则是为虚拟机使
用到的本地(Native)方法服务. Java 虚拟机规范对本地方法找中方法使用的语言、使用方式与数据结构并没有任何强制规定,因此具体的虚拟机可以根据需要自由实现它,甚至有 
Java虚拟机(HotSpot虚拟机)直接就把本地方法栈和虚拟机栈合二为一与虚拟机栈一样,本地方法栈也会在校深度溢出或者栈扩展失败时分别抛出StackOverflowError OutOfMemoryError 异常

2.2.4 Java堆
  对于Java应用程序来说, JavaHeap是虚拟机所管理的内存中最大的一块,Java堆是被所有线程共享的一块内存区域. Java世界里几乎(栈上也可分配)所有的
对象实例都在这里分配内存

2.2.5 方法区
  方法区(Method Area)与 Java 堆一样,是各个线程共享的内存区域,它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码
缓存等数据。虽然 Java虚拟机规范中把方法区描述为堆的一个逻辑部分,但是它却有一个别名叫作"非堆", 目的是与Java堆区分开来

  说到方法区,不得不提一下"永久代"这个概念,尤其是在 JDK8 以前,许多 Java程序员都习惯在 HotSpot虚拟机上开发、部署程序,很多人都更愿意把方法区
称呼为"永久代"(Permanent Generation),或将两者混为一谈. 本质上这两者并不是等价的,因为仅仅是当时的 HotSpot 虚拟机设计团队选择把收集器的分代
设计扩展至方法区,或者说使用永久代来实现方法区而已. 这样使得 Hotspot 的垃圾收集器能够像管理 Java 堆一样管理这部分内存,省去专门为方法区编写
内存管理代码的工作

  但是对于其他虚拟机实现,是不存在永久代的概念的, 原则上如何实现方法区属于虚拟机实现细节,不受《Java 虚拟机规范》管束,并不要求统一. 
但现在回头来看,当年使用永久代来实现方法区的决定并不是一个好主意 ,这种设计导致了Java应用更容易遇到内存、溢出的问题(永久代有 XX:Ma PermSize 的上限,
即使不设置也有默认大小,而 19 JRockit 只要没有触碰到进程可用内存的上限 例如 32 位系统中的 4GB 限制,就不会出问题),而且有极少数方法(例如 String :: intern)
会因永久代的原因而导致不同虚拟机下有不同的表现。当Oracle 收购 EA 获得了 JRockit 的所有权后,准备把 JRockit 中的优秀功能,譬如Java Mission Control 
管理工具,移植到 HotSpot 虚拟机时,但因为两者对方法区实现异而面临诸多困难 考虑到 HotSpot 未来 发展,在 JDK 的时候 HotSpot 开发团队就有放弃永久代, 
逐步改为采用本地内存(Native Memory )来实现方法区的计划了 ,到了 JDK 7 Hotspot ,已经把原本放在永久代的字符串常、静态变量等移出,而到了 JDK8 ,终于完全废弃
了永久代的概念,改用与 JRockit 19 一样在本地内存中实现的元空间来代替,把 JDK 中永久代还剩余的内容(主要是类型信息)全部移到元空间中
--字符串常量池已经不在方法区了呗

2.2.6 运行时常量池
  运行时常量池(Runtime Constant Pool)是方法区的一部分 Class 文件中除了有类的版本、字段、方法 接口等描述信息外,还有一项信息是【常量池表】
(Constant Pool Table),用于存放【编译期生成的各种字面量(字符串)与符号引用】,这部分内容将在类加载后存放到方法区的运行时常量池中
  运行时常量池相对于Class 文件常量池的另外一个重要特征是具备动态性, Java 语言并不要求常量一定只有编译期才能产生,也就是说,
并非预置入 Class 文件中常量池的内容才能进入方法区运行时常量池,运行期间也可以将新的常量放入池中,这种特性被开发人员用得 较多的便是String类
的 intern()方法。
java8 方法区不在永久代而在 Meta-space 中
https://www.cnblogs.com/justcooooode/p/7603381.html
----
String str2 = new String("str")+new String("01");
str2.intern();
String str1 = "str01";
System.out.println(str1 == str2);
交换 2/3 行代码顺序, 这几行代码搞懂了应该就能理解常量池是怎么回事了

----
2.2.7 直接内存
  Direct Memory 并不是虚拟机运行时数据区的一部分,JDK 1.4 中新加入了NIO,引入了一种基于通道与缓冲区的I/O方式,它可以使用 Native 函数库直接
分配堆外内存,然后通过一个存储在 Java 堆里面的 DirectByteBuffer 对象作为这块内存的引用进行操作,这样能在【一些场景】中显著提高性能,因为避免了在 
Java 堆和 Native 堆中来回复制数据,显然,本机直接内存的分配不会受到 Java 堆大小的限制,但是,既然是内存,则肯定还是会受到本机总内存(包括物理
内存 SWAP 区或者分页文件)大小以及处理器寻址空间的限制,一般服务器管理员配置虚拟机参数时,会根据实际内存去设置－Xmx 等参数信息,但经常忽略掉
直接内存,使得各个内存区域总和大于物理内存限制(包括物理的和操作系统级的限制),从而导致动态扩展时出现 OutOFMemoryError 异常

2.3.1 对象的创建
  在类加载检查通过后,接下来虚拟机将为新生对象分配内存,对象所需内存的大小在类加载完成后便可完全确定(如何确定将在 2.3.2 节中介绍),
为对象分配空间的任务实际上便等同于把一块确定大小的内存块从 Java 堆中划分出来

  假设 Java 堆中内存是绝对规整的,所有被使用过的内存都被放在一边,空闲的内存被放在另一边,中间放着一个指针作为分界点的指示器,那所分配内存就仅仅是把那个
指针向空闲空间方向挪动一段与对象大小相等的距离,这种分配方式称为"指针碰撞" Bump The Pointer
  但如果 Java 堆中的内存并不是规整的,已被使用的内存和空闲的内存相互交错在一起,那就没有办法简单地进行指针碰撞了,虚拟机就必须维护一个列表,记录上哪些内存块是
可用的,在分配的时候从列表中找到一块足够大的空间划分给对象实例,并更新列表上的记录,这种分配方式称为"空闲列表" Free List 

  选择哪种分配方式由 Java 堆是否规整决定,而 Java 堆是否规整又由所采用的垃圾收集器是否带有空间压缩整理(Compact)的能力决定 因此,当使用Serial ParNew 
等带压缩整理过程的收集器时,系统采用的分配算法是指针碰撞,既简单又高效。而当使用CMS这种基于清除(Sweep)算法的收集器时,就只能采用空闲列表来分配内存


  除如何划分可用空间之外,还有另外一个需要考虑的问题：对象创建在虚拟机中是非常频繁的行为,即使仅仅修改一个指针所指向的位置,在并发情况下也并不是线程安全的
可能出现正在给对象A分配内存,指针还没来得及修改,对象B又同时使用了原来的指针来分配内存的情况.解决这个问题有两种可选方案:
  一种是对分配内存的动作进行同步处理,实际上虚拟机是采用CAS配上失败重试的方式保证更新操作的原子性；另外一种是把内存分配的动作按照线程划分在不同的空间
之中进行,即每个线程在 Java 堆中预先分配一小块内存,称为本地线程分配缓冲(Thread Local A llocation Buffer, TLAB),哪个线程配内存,就在哪个线程的本地缓冲区
中分配,只有本地缓冲区用完了,分配新的缓存区时才需要同步锁定,虚拟机是否使用 TLAB ,可以通过 -XX:+ -UseTLAB 来设定
  内存分配完成之后,虚拟机必须将分配到的内存空间(但不包括对象头)都初始化为零值,接下来,Java虚拟机还要对对象进行必要的设置,例如这个对象是哪个类的实例,
如何才能找到类的元数据信息,对象的哈希码(实际上对象的哈希码会延后到真正调用Object: :hashCode()方法时才计算),对象的GC分代年龄信息这些信息存放在对象的对
象头(Object Header)之中,根据虚拟机当前运行状态的不同,如是否启用偏向锁等,对象头会有不同的设置方式 关于对象头的具体内容,稍后会详细介绍
  在上面作都完成之后,从虚拟机的视角来看一个新的对象经产生了,但是从Java 程序的视角来看,对象创建才刚刚开始一一一构造函数,即 Class 文件中的 init>()方法
还没有执行,所有的字段都为默认的零值,对象需要的其他资源和状态信息也还没有按照预定的意图构造好

2.3.2 对象的内存布局
  在Hotspot虚拟机里 对象在堆内存中的存储布局可以划分为三个部分 对象Header、实例数据(Instance Data)和对齐填充 Padding
  HotSPot 虚拟机对象的对象头部分包括两类信息,【第一类是用于存储自身的运行时数据,如哈希码、GC分代年龄、锁状态标志 、线程持有的锁、偏向线程ID、偏向
时间戳等对象头的另外一部分是类型指针,即对象指向它的类型元数据的指针】, Java 虚拟机通过这个指针来确定该对象 哪个类的实例, 并不是所有的虚拟机实现都
必须在对象数据上保留类型指针,换句话说,查找对象的元数据信息并不一定要经过对象本身,这点我们会在下一节具体讨论. 此外如果对象是一个 Java 数组,那在对象头
中还必须有一块用于记录数组长度的数据,因为虚拟机可以通过普通Java对象的元数据信息确定 Java 对象的大小,但 如果数组的长度是不确定的 将无法通过元数据中的
信息推断出数组的大小
  接下来实倒数据部分是对象真正存储的有效信息,即我们在程序代码里面所定义的各种类型的字段内容,无论是从父类继承下来的还是在子类中定义的字段都必须记录起来
这部分的存储顺序会受到虚拟机分配策略参数(XX:FieldsAllocationStyle 参数)和字段在Java 源码中定义顺序的影响. 
  HotSpot 虚拟机默认的分配顺序为 longs/double ints shorts/chars bytes/booleans oops ( OrdinaryObject Pointers,OOPs),从以上默认的分配策略中可以看
到,相同宽度的字段总被分配到一起存放,在满足这个前提条件的情况下,在父类中定义的变量会出现在子类之前
  对象的第三部分是对齐填充,这并不是必然存在的,也没有特别的含义,它仅仅起着占位符的作用,由于Hotspot虚拟机的自动内存管理系统要求对象起始地址必须是8字节
整数倍,换句话说就是任何对象的大小都必须是【8字节】的整数倍

2.3.3 对象的访问定位 
  创建对象自然是为了后续使用该对象,我们的 Java 程序会通过栈上的reference数据来操作堆上的具体对象,由于 reference 类型在《Java虚拟机规范》里面只规定了
它是一个指向对象的引用,并没有定义这个引用应该通过什么方式去定位 访问到堆中对象的具体位置, 所以对象访问方式也是由虚拟机实现而定的, 主流的访问方式主要
有使用句柄和直接指针两种(图2-2 ,2-3)

【指针指向系统中物理内存的地址,而句柄是windows在内存中维护的一个对象内存物理地址列表的整数索引,句柄是一种指向指针的指针】

2.4.1 Java 堆溢出
  图2-5 显示了使用 Eclipse Memory Anayzer 打开的堆转储快照文件
2.4.2 虚拟机栈和本地方法栈溢出
  由于HotSpot虚拟机中并不区分虚拟机栈和本地方法栈,因此对于Hotspot来说,-Xoss参数(设置本地方法校大小)虽然存在,但实际上是没有任何效果的,栈容量只能由-Xss 
  参数来设定,关于虚拟机栈和本地方法栈,在《 Java 虚拟机规范》中描述了两种异常：
	1)如果线程请求的战深度大于虚拟机所允许的最大深度 将抛出 StackOverflowError 异常
	2)如果虚拟机的战内存允许动态扩展,当扩展核容量无法申请到足够的内存时,将抛OutOtMemory Error 异常
	Java 虚拟机规范 明确允许 Java 虚拟机实现自行选择是否支持栈的动态扩展,而Hotspot 虚拟机的选择是不支持扩展,所以除非在创建线程申请内存时就因无法获得
	足够内存而出现 OutOfMemorγError 异常,否则在线程运行时是不会因为扩展而导致内存溢出的,只会因为栈容量无法容纳新的战帧而导致 StackOverflowError 异常
	... 后续实验
	https://www.runoob.com/w3cnote/cglibcode-generation-library-intro.html
	
2.4.3 方法区和运行时常量池溢出
	书再看一下, 要记住自JDK7起,原本存放在永久代的串常量池被移至 Java 堆之中, 但是怎么放的放在哪块了也没说明白呀, 仔细看书说的也挺明白的
	JDK 以后，永久代便完全退出了历史舞台，元 间作为其 代者 在默认设下，前面列举的那些正常的动态创建新类型 的测试用例已 很难再迫使虚拟机产生方法区的溢出异常了
	-- 其实字符串常量池这种东西感觉上就应该放在堆中, 以前放在方法区/永久代就是偷懒的做法吧, 引入元空间的第二个好处说了上面说的, 减少创建新类型引起的异常吧
	
2.4.4 本机直接内存溢出
	设置 -XX:MaxDirectMemorySize=10M 不生效啊,从1.6到1.8, 生效了, 以前说没生效应该是 DirectByteBuffer 的引用释放了
3.2.2 可达性分析算法
  Java 技术体系里面,固定可作为 GC Roots 的对象包括以下几种：
	在虚拟机栈(栈帧中的本地变量表) 中引用的对象,譬如各个线程被调用的方法堆栈中使用到的参数、局部变量、临时变量等
	在方法区中类静态属性引用的对象,譬如 Java类的引用类型静态变量,【方法区号称存静态变量,但经我测试,静态变量如果是引用则对象存在堆中(static byte[] bytes)】
	在方法区中常量引用的对象, 譬如字符串常量池(String Table)里的引用
	在本地方法栈中 JNI (即通常所说的 Native 方法)引用的对象
	Java 虚拟机内部的引用,如基本数据类型对应的 Class 对象, 一些常驻的异常对象(比如 NullPointExcepiton OutOfMemoryError)等,还有系统类加载器
	所有被同步锁(synchronized 关键字)持有的对象
    反映 Java 虚拟机内部情况的 JMXBean JVMTI 中注册的回调、本地代码缓存等
除了这些固定的 GC Roots 集合以外,根据用户所选用的垃圾收集器以及当前回收的内存区域不同,还可以有其他对象"临时性"地加入,共同构成完整 GC Roots 集合.
譬如后文将会提到的分代收集和局部回收(Partial GC),如果只针对 Java 堆中某一块区域发起垃圾收集时(如最典型的只针对新生代的垃圾收集),必须考虑到内存
区域是虚拟机自己的实现细节(在用户视角里任何内存区域都是不可见的),更不是孤立封闭的,所以某个区域里的对象完全有可能被位于堆中其他区域的对象所引用,
这时候就需要将这些关联区域的对象也一并加入 GC Roots 集合中去,才能保证可达性分析的正确性 目前最新的几款垃圾收集器 无一例外都具备了局部回收的特征,为了避免 
GC Roots含过多对象而过度膨胀,它们在实现上也做出了各种优化处理 关于这些概念、优化技巧以及各种不同收集器实现等内容,都将在本章后续内容中一一介绍


3.2.3 再谈引用 
  Soft Reference: 软引用是用来描述一些还有用,但非必须的对象 只被软引用关联着的对象,在系统将要发生内存溢出异常前,会把这些对象列进回收范围之中进行第二次回收,
如果这次回收还没有足够的内存,才会抛出内存溢出异常
  Weak Reference: 弱引用也是用来描述那些非必须对象,但是它的强度比软引用更弱一些,被弱引用关联的对象只能生存到下一次垃圾收集发生为 当垃圾收集器开始工作,无论当前
内存是否足够,都会回收掉只被弱引用关联的对象
  Phantom Reference: 虚引用也称为"幽灵引用"或者"幻影引用",它是最弱的一种引用关系一个对是否有虚引用的存在,完全不会对其生存时间构成影响,
也无法通过虚引用来取得一个对象实例 为一个对象设置虚引用关联的唯一目的只是为了能在这个对象被收集器回收时收到一个系统通知

3.2.4 生存还是死亡
  即使在可达性分析算法 中判定为不可达的对象,也不是"非死不可"的,这时候它们暂时还处于"缓刑"阶段 要真正宣告一个对象死亡,【至少要经历两次标记过程】(这么说不合适吧)： 
如果对象在进行可达性分析后发现没有与 GC Roots 连接的引用链,那它将会被第一次标记 ,随后进行一次筛选,筛选的条件是此对象是否有必要执行 finalize() 
假如对象没有覆盖finalize(),或者 finalize()方法已经被虚拟机调用过,那么虚拟机将这两种情况都视为"没有必要执行"

  如果这个对象被判定为确有必要执行 finalize(),那么该对象将会被放置在一个名为 F-Queue 的队列之中,并在稍后由 一条 由虚拟机自动建立的、
低调度优先级的 Fina lizer线程去执行它们的 finalize()这里所说的 "执行"是指虚拟机会触发这个方法开始运行,但并不承诺一定会等待它运行结束 样做的原因
是,如果某个对象的 finalize()执行缓慢,或者更极端地发生了死循环,将很可能导致 F-Queue 队列中的其他对象永久处于等待,甚至导致整个内存回收子系统的崩溃。
finalize()是对象逃脱死亡命运的最后一次机会,稍后收集器将对 -Qu 中的对象进行第 次小规模的标记,如果对象要在finalize()中成功拯救自己一一只要重新
与引用链上的任何 个对象建立关联即可, 如把自己( this 关键字)赋值给某个类变量或者对象的成员变量,那在第二次标记时它将被移出"即将回收"的集合；
如果对象这时候还没有逃脱,那基本上它就真的要被回收了 从代码清单 3-2 中我们可以看到一个对象的 finalize()被执行,但是它仍然可以存活
finalize 只被执行一次一定是哪里记住状态了, 我觉得最可能的是在对象头中吧

3.2.5 回收方法区
  Java 虚拟机规范中提到过可以不要求虚拟机在方法区中实现垃圾收集,事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在(如 JDK 11 时期的 ZGC 收集器
就不支持类卸载),方法区垃圾收集的"性价比"通常也是比较低的
  方法区的垃圾收集主要回收两部分内容：废弃的常量和不再使用的类型 回收废弃常量与 回收 Java 堆中的对象非常类似 举个常量池中字面量回收的例子,
假如一个字符串"java"曾经进入常量池中,但是当前系统又没有任何一个字符串对象的值是"java",换句话说,已经没有任何字符串对象引用常量池中的"java"常量,
且虚拟机中也没有其他地方引用这个字面量. 如果在这时发生内存回收,而且垃圾收集器判断确有必要的话,这个java"常量就将会被系统清理出常量池,常量池中其他类
(接口)、方法、字段的符号引用也与此类似
  判定一个常量是否"废弃"还是相对简单,而要判定 个类型是否属于"不再被使用的类"的条件就比较苛刻了.需要同时满足下面三个条件:
  1. 该类所有的实例都已经被回收,也就是 Java 堆中不存在该类及其任何派生子类的实例
  2. 加载该类的类加载器已经被回收,这个条件除非是经过精心设计的可替换类加载器的场景,如 OSGi JSP 的重加载等,否则通常是很难达成的
  3. 该类对应的 java.lang.Class对象没有在任何地方被引用,无法在任何地方通过反射访问该类的方法
  在大量使用反射、动态代理 CGLib 等字节码框架,动态生成 JSP 以及 OSGi 这类频繁自定义类加载器的场景中,通常都需要Java 虚拟机具备类型卸载的能力,
以保证不会对方法区造成过大的内存压力

3.3 垃坡收集算法
  推荐阅读 Richard Jones 撰写的 垃圾回收算法手册 ＠的第2~4章的相关内容
3.3.1 分代收集理论
  当前商业虚拟机的垃圾收集器,大多数都遵循了"分代收集"(Generational Collection)③的理论进行设计,分代收集名为理论,实质是一套符合大多数程序运行实际情况
的经验法则,它建立在两个分代假说之上：
	1)弱分代假说(Weak Generational Hypothesis)：绝大多数对象都是朝生夕灭的
	2)强分代假说(Strong Generational Hypothesis)：熬过越多次垃圾收集过程的对象就越难以消亡

  其实我们只要仔细思考一下,也很容易发现分代收集并非只是简单划分一下内存区域那么容易,它至少存在一个明显的困难：对象不是孤立的,对象之间会存在跨代引用
假如要现在进行一次只局限于新生代区域内的收集(Minor GC),但新生代中的对象是完全有可能被老年代所引用的,为了找出该区域中的存活对象,不得不在固定的 GC Roots
之外,再额外遍历整个老年代中所有对象来确保可达性分析结果的正确性,反过来也是一样＠ 遍历整个老年代所有对象的方案虽然理论上可行,但无疑会为内存回收带来很大的性
能负担 为了解决这个问题,就需要对分代收集理论添加第三条经验法则：跨代引用假说(Intergenerational Reference Hypothesis)：跨代引用相对于同代引用来说仅占极少数

部分收集( Partial GC )：指目标不是完整收集整个 Java 堆的垃圾收集,其中又分为
	新生代收集(Minor GC/Young GC )：指目标只是新生代的垃圾收集
	老年代收集( Major GC/Old GC )：指目标只是老年代的垃圾收集 目前只有CMS 收集器会有单独收集老年代的行为 另外请注意" Major GC "这个说
		法现在有点混淆,在不同资料上常有不同所才旨,读者需按上下文区分到底是指老年代的收集还是整堆收集
	混合收集( Mixed GC )：指目标是收集整个新生代以及部分老年代的垃圾收目前只有 Gl 收集器会有这种行为
整堆收集( Full GC )：收集整个 Java 堆和方法区的垃圾收集

3.3.4 标记－整理算法
  针对老年代对象的存亡特征, 提出了另外一种有针对性的"标记－整理"( Mark-Compact )算法,其中的标记过程仍然与"标记 清除"算法一样,但后续步骤不是直接
对可回收对象进行清理,而是让所有存活的对象都向内存空间一端移动,然后直接清理掉边界以外的内存

  标记－清除算法与标记 整理算法的本质差异在于前者是一种非移动式的回收算法,而后者是移动式的 是否移动回收后的存活对象是一项优缺点并存的风险决策：如果
移动存活对象 ,尤其是在老年代这种每次 回收都有大量对象存活区域 移动存活对象并更新所有引用这些对象的地方将会是一种极为负重的操作,而且这种对象移动操作
必须全程暂停用户应用程序才能进行。这就更加让使用者不得不小心翼翼地权衡其弊端了,像这样的停顿被最初的虚拟机设计者形象地描述为" Stop The World"

  HotSpot 虚拟机里面关注吞 Parallel Scavenge 集器是基于标记－整理算法的,而关注延迟的 CMS 收集器则是基于标记－清除算法的,这也从侧面印证这点
  还有一 "和稀泥式"解决方案可以不在 存分配和访问上 加太大额外负担,做法是让虚拟机平时多数时间都采用标记 清除算法,暂时容忍内存碎片的存在,直到内存空间
的碎片化程度已经大到影响对象分配时,再采用标记－整理算法收集一次,以获得规整的内存空间。前面提到的基于标记－清除算法的 CMS 收集器面临空间碎片过多时采用
的就是这种处理办法

3.4.1 根节点枚举
  所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的,因此毫无疑问根节点枚举与之前提及的整理内存碎片一样会面临相似的 "Stop The World" 的困扰
现在可达性分析算法耗时最长的查找引用链的过程已经可以做到与用户线程一起并发(具体见3.4.6 节),但根节点枚举始终还是必须在一个能保障一致性的快照中才得以
进行,所以当用户线程停顿下来之后,其实并不需要一个不漏地检查完所有执行上下文和全局的引用位置,虚拟机应当是有办法直接得到哪些地方存放着对象引用的。
在HotSpot 的解决方案里,是使用一组称为 OopMap 的数据结构来达到这个目的。一旦类加载动作完成的时候, HotSpot 就会把对象内什么偏移量上是什么类型的数据
计算出来,在即时编译(见第11章)过程中,也会在特定的位置记录下楼里和寄存器里哪些位置是引用 这样收集器在扫描时就可以直接得知这些信息了,并不需要
真正一个不漏地从方法区等 GC Roots 开始查找。...可以再看下接下来的代码清单3-3例子

3.4.2 安全点
  在OopMap的协助下,Hotspot 可以快速准确地完成GC Roots 枚举,但一个很现实的问题随之而来：可能导致引用关系变化,或者说导致 OopMap内容变化的指令非常多,
如果为每一条指令都生成对应的 OopMap ,那将会需要大量的额外存储空间,这样垃圾收集伴随而来的空间成本就会变得元法忍受的高昂
  实际上 HotSpot 也的确没有为每条指令都生成 OopMap ,前面已经提到,只是在"特定的位置"记录了这些信息,这些位置被称为安全点(Safepoint) 有了安全点的设定,也就
决定了用户程序执行时并非在代码指令流的任意位置都能够停顿下来开始垃圾收集,而是强制要求必须执行到达安全点后才能够暂停。安全点位置的选取基本上是以
"是否具有让程序长时间执行的特征"为标准进行选定的

3.4.3 安全区域
  使用安全点的设计似乎已经完美解决如何停顿用户线程,让虚拟机进入垃圾回收状态的问题了,但实际情况却并不一定安全点机制保证了程序执行时,在不太长的时间
内就会遇到可进入垃圾收集过程的安全点 但是,程序 不执行"的时候呢？所谓的程序不执行就是没有分配处理器时间,典型的场景便是用户线程处于Sleep 状态或者 
Blocked 状态,这时候线程无法响应虚拟机的中断请求,不能再走到安全的地方去中断挂起自己,虚拟机也显然不可能持续等待线程重新被激活分配处理器时间 对于这种
情况,就必须引人安全区域( Safe Region )来解决

3.4.4 记忆集与卡表
  解决跨代引用问题, 知道这个就行了

3.4.5 写屏障

3.4.6 并发的可达性分析

3.5.1 Serial 收集器
  它的"单线程"的意义并不仅仅是说明它只会使用一个处理器或一条收集线程去完成垃圾收集工作,更重要的是强调在它进行垃圾收集时,必须暂停其他所有工作线程,
直到它收集结束

3.5.2 ParNew 收集器
  Par New 收集器实质上是 Serial 收集器的多线程并行版本
  ParNew 对于垃圾收集时系统资源的高效利用远是很有好处的 它默认开启的收集线程数与处理器核心数量相同

3.5.3 Parallel Scavenge 收集器
  Parallel Scavenge收集器也是一款新生代收集器,它同样是基于标记 复制算法实现的收集器,也是能够并行收集的多线程收集器……Parallel Scavenge 的诸多特性
从表面上看和ParNew 非常相似,那它有什么特别之处呢？

  Parallel Scavenge 收集器的特点是它的关注点与其他收集器不同, CMS 等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间,而 Parallel Scavenge 
收集器的目标则是达到一个可控制的吞吐量(Throughput)

  Parallel Scavenge 收集器提供了两个参数用于精确控制吞吐量,分别是控制最大垃圾收集
停顿时间的 XX:MaxGCPauseMillis 参数以及直接设置吞吐量大小的 XX:GCTimeRatio 参数
  Parallel Scavenge 收集器还有一个参数 -XX:+UseAdaptiveSizePolicy值得我们关注 这是一个开关参数,当这个参数被激活之后,就不需要人工指定新生代的
大小 Eden与Survivor 区的比例  晋升老年代对象大小(－XXPretenureSizeThreshold )等细节参数了, 虚拟机会根据当前系统的运行情况收集性能监控信
息,动态调整这些参数以提供最合适的停顿时间或者最大的吞吐 这种调节方式称为垃圾收集的自适应的调节策略

3.5.4 Serial Old 收集器
  Serial Old 是 serial 收集器的老年代版本,它同样是一个单线程收集器,使用标记--整理算法

3.5.5 Parallel Old 收集器
  Parallel Old是Parallel Scavenge收集器的老年代版本, 支持多线程并发收集,基于标记-整理算法实现

3.5.6 CMS收集器
  CMS ( Concurrent Mark Sweep 收集器是一种以获取最短回收停顿时间为 目标的收集器
  从名字(包含" Mark Sweep ")上就可以看出 CMS 收集器是基于标记－清除算法实现的,整个过程分为四个步骤,包括：
  1)初始标记( CMS initial mark )
  2)并发标记( CMS concurrent mark )
  3)重新标记( MS remark )
  4)并发清除( CMS concurrent sweep) 
  其中初始标记、重新标记这两个步 然需要" Stop The World 
  初始标记仅仅只是
  标记一下 GC Roots能直接关联到的对象,速度很快 并发标记阶段就是从 GC Roots的直接关联对象开始遍历整个对象图的过程,这个过程耗时较长但是不需要停顿
用户线程,可以与垃圾收集线程一起并发运行 ；而重新标记阶段则是为了修正并发标记期间,因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。
最后是并发清除阶段 ,清理删除掉标记阶段判断的已经死亡的对象, 由于不需要移动存活对象,所以这个阶段也是可以与用户线程同时并发的
  由于在整个过程中耗时最长的并发标记和并发清除阶段中,垃圾收集器线程都可以与用户线程一起工作所以从总体上来说, CMS收集器的内存回收过程是与用户线程
一起并发执行的。至少有以下三个明显的缺点：
  首先, CMS 收集器对处理器资源非常敏感,在并发阶段,它虽然不会导致用户线程停顿,但却会因为占用了－部分线程(或者说处理器的计算能力)而导致应用程序变慢,降低总吞吐量
然后,由于 CMS 收集器无法处理"浮动垃圾"(Floating Garbage ),有可能出现" Concurrent Mode Failur巳"失败进而导致另一次完全"Stop The World"的 Full GC 
的产生。在CMS 的并发标记和并发清理阶段,用户线程是还在继续运行的,程序在运行自然就还会伴随有新的垃圾对象不断产生,但这一部分垃圾对象是出现在标记过程
结束以后,CMS 无法在当次收集中处理掉它们,只好留待下一次垃圾收集时再清理掉。这一部分垃圾就称为"浮动垃圾"。同样也是由于在垃圾 集阶段用户线程还需要持续
运行 ,那就还需要预留足够内存空间提供给用户线程使用,因此 CMS 收集器不能像其他收集器那样等待到老年代几乎完全被填满了再进行收集,必须预留一部分空间
供并发收集时的程序运作使用。到了 JDK1.6 时, CMS 收集器的启动阔值就已经默认提升至 92%但这又会更容易面临另一种风险 要是 CMS 运行期间预留的内存无法满足
程序分配新对象的需要,就会出现一次"并发失败"( Concurrent Mode Failure ),这时候虚拟机将不得不启动后备预案 冻结用户线程的执行,临时启用 Serial Old 
收集器来重新进行老年代的垃圾收集,但这样停顿时间就很长了
  还有最后一个缺点,在本节的开头曾提到, CMS 是一款基于"标记 清除"算法实现的收集器,如果读者对前面这部分介绍还有印象的话,就可能想到这意味着收集结束时会
有大量空间碎片产生。空间碎片过多时,将会给大对象分配带来很大麻烦 ,往往会出现老年代还有很多剩余空间,但就是无法找到足够大的连续空间来分配当前对象,
而不得不提前触发一次 Full GC 的情况。为了解决这个问题, CMS 收集器提供了一个 XX :+UseCMSCompactAtFullCollection 开关参数(默认是开启 的,此参数从 JDK9 开始废弃),用于在
CMS 收集器不得不进行 Full GC 时开启内存碎片的合并整理过程,由于这个内存整理必须移动存活对象,(在 Shenandoah ZGC 出现前)是无法并发的 这样空间碎片问题是解决了,
但停顿时间又会变长,因此虚拟机设计者们还提供了另外 个参数－XX: CMSFullGCsBeforeCompaction (此参数从 JDK9 开始废弃),这个参数的作用是要求 CMS 收集器在执行过若
干次(数量由 参数值决定)不整理空间的 Full GC 之后,下 次进入 Full GC 前会先进行碎片整理(默认值为 ,表示每次进入 Full GC 时都进行碎片整理)


3.5.7 Garbage First 收集器
  GI 开创的基于 Region 的堆内存布局是它能够实现这个目标的关键 虽然G1也仍是遵循分代收集理论设计的,但其堆内存的布局与其他收集器有非常明显的差异 Gl 
不再坚持固定大小以及固定数 的分代区域划分,而是把连续的 Java 堆划分为多个大小相等的独立区域( Region ), 每一个 Region 都可以根据需要 ,扮演新生代
的 Eden空间 Survivor空间或者老年代空间。收集器能够对扮演不同角色的 Region 采用不同的策略去处理,这样无论是新创建的对象还是已经存活了一段时间、熬过多次
收集的旧对象都能获取很好的收集效果
  Region 中还有一类特殊的 Humongous 区域,专 门用 来存储大对象 GI 认为只要大小超过了一个 Region 容量一半的对象即可判定为大对象 每个 Region的大小可以
通过参-XX :G IHeapRegionSize 设定,取值范围为 lMB~32MB ,且应为2的N次幂。而对于那些超过了整个 Region 量的超级大对象, 将会被存放在 个连续的 
Humongous Region之中, GI 的大多数行为都把 Humongous Region 作为老年代的 部分来进行看待
后续内容...

3.6.1 Shenandoah 收集器
3.6.2 ZGC 收集器

3.7 选择合适的垃坡收集器
  看下 表3-4 垃圾收集相关的常用参数
  
3.8.2 大对象直接进入老年代
	HotSpot 提供了 XX:PretenureSizeThreshold 参数,指定大于该设置值的对象直接在老年代分配,这样做的目的就是避免在Eden区及两个Survivor区之间来回复制
只对 Serial 和 ParNew 有效

3.8.3 长期存活的对象将进入老年代
  对象晋升老年代的年龄阈值可通过 -XX:MaxTenuringThreshold 设置

3.8.4 动态对象年龄判定
  为了能更好地适应不同程序的内存状况, HotSpot 虚拟机并不是永远要求对象的年龄必
须达到 XX:MaxTenuringThreshold 才能晋升老年代,如果在 Survivor空间中相同年龄所有
对象大小的总和大于 Survivor 空间的一半 ,年龄大于或等于 亥年龄的对象就可以直接进入
老年代,无须等到 XX:MaxTenuringThreshold 中要求的年龄

3.8.5 空间分配担保
  在发生 Minor GC 之前,虚拟机必须先检查老年代最大可用的连续空间是否大于新生代所有对象总空间,如果这个条件成立,那这一次Minor GC 可以确保是安全的 
如果不成立,则虚拟机会先查看-XX:Hand ePromotionFailure 参数 的设置值是否允许担保失败(Handle Promotion Failure )；如果允许,那会继续检查老年代最大可用
的连续空间是否大于历次晋升到老年代对象的平均大小,如果大于,将尝试进行一次Minor GC ,尽管这次Minor GC 是有风险的；如果小于,
或者 -XX:HandlePromotionFailure 设置不允许冒险,那这时就要改为进行一次 Full GC
  取历史平均值来比较其实仍然是一种赌概率的解决办法,也就是说假如某次 Minor GC
存活后的对象突增,远远高于历史平均值的话,依然会导致担保失败 如果出现了担保
失败,那就只好老老实实地重新发起一次 Full GC 这样停顿时间就很长了。虽然担保失败时
绕的圈子是最大的,但通常情况下都还是会将 XX:HandlePrornotionFailure 开关打开,避免
Full GC 过于频繁
  JDK 6 Update 24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小,就会进行MinorGC,否则将进行Full GC


第4章
4.2.1 jps ：虚拟机进程状况工具
及其后章节
java -cp ${JAVA_HOME}/lib/sa-jdi.jar sun.jvm.hotspot.HSDB

第5章

5.2.1 大内存硬件上的程序部署策略
  回收12GB的Java 堆,一次 Full GC 的停顿时间就高达 14s 由于程序设计的原因,访问文档时会把文档从磁盘提取到内存中,导致内存中出现很多由文档序列化产生
的大对象,这些大对象大多在分配时就直接进入了老年代,没有在 Minor GC 中被清理掉 这种情况下即使有12GB 的堆,内存也很快会被消耗殆尽,由此导致每隔几分钟
出现十几秒的停顿
  经调查,更早之前的硬件使用的 32 位操作
系统,给 Hotspot 虚拟机只分配了 l.SGB 的堆内存,当时用户确实感觉到使用网站比较缓
慢,但还不至于发生长达十几秒的明显停顿,后来将硬件升级到 64 位系统、 16 GB 内存希望
能提升程序效能,却反而出现了停顿问题,尝试过将 Java 堆分配的内存重新缩小到 1.SGB
或者 2GB 这样的确可以避免长时间停顿
  对于用户交互性强 对停顿时间敏感、内存又较大的系统,并不是一定要使用 Shenandoah ZGC 这些明确以控制延迟为目标的垃圾收集器才能解决问题(当然不可否认,
如果情况允许的话,这是最值得考虑的方案),使用Parallel Scavenge Old 收集器,并且给 Java 虚拟机分配较大的堆内存也是有很多运行得很成功的案例的,但前提
是必须把应用的 Full GC频率控制得足够低,至少要低到不会在用户使用过程中发生,譬如十几个小时乃至一整天都不出现一次 Full GC ,这样可以通过在深夜执行定时
任务的方式触发 Full GC 甚至是自动重启应用服务器来保持内存可用空间在一个稳定的水平
  控制 Full GC频率的关键是老年代的相对稳定,这主要取决于应用中绝大多数对象能否
符合"朝生夕灭"的原则,即大多数对象的生存时间不应当太长,尤其是不能有成批量的、
长生存时间的大对象产生,这样才能保障老年代空间的稳定
后续内容...

5.2.2 集群间同步导致的内存溢出
5.2.3 堆外内存导致的溢出错误
5.2.4 外部命令导致系统缓慢
5.2.5 服务器虚拟机进程崩溃
5.2.6 不怡当数据结构导致内存占用过大
5.2.7 Windows 虚拟内存导致的长时间停顿
5.2.8 由安全点导致长时间停顿
5.3 实战： Eclipse 运行速度调优

6.2 无关性的基石
  各种不同平台的 Java 虚拟机,以及所有平台都统一支持的程序存储格式一－字节码( Byte Code)是构成平台无关性的基石
  实现语言无关性的基础仍然是虚拟机和字节码存储格式 Java 虚拟机不与包括 Java言在内的任何程序语言绑定,它只与"Class 文件"这种特定的二进制文件格式所关联,
Class 文件中包含了 Java 虚拟机指令集 、符号表以及若干其他辅助信息
第6章

7.1 
  在Java里类型的加载,连接和初始化过程都是在程序运行期间完成的。这种策略会让类加载时稍微增加一些性能开销,但是却为 Java 应用提供了极高的扩展性和灵
活性, Java天生可以动态扩展的语言特性就是依赖运行期动态加载和动态连接这个特点实现的

7.2 类加载的时机
  加载 、验证、准备、初始化和卸载这五个阶段的顺序是确定的,类型的加载过程必须按照这种顺序按部就班地开始,解析阶段不一定：它在某些情况下可以在初始化
阶段之后再开始,这是为了支持 Java语言的运行时绑定特性(也称为动态绑定或晚期绑定)

关于在什么情况下需要开始类加载过程的第一个阶段"加载",《 Java 拟机规范》并没有进行强制约束,这点可以交给虚拟机的具体实现来自由把握 但是对于初始化阶段,
Java 虚拟机规范 是严格规定了有且只有六种情况必须立即对 进行 "初始化"(而加载、验证、准备自然需要在 之前开始)
-- 所以类加载有可能通过下列初始化行为反向触发或是主动行为吧
1) 遇到 new getstatic putstatic invokestatic 这四条字节码指令时,如果类型没有进行过初始化,则需要先触发其初始化阶段,能够生成这四条指的典型 Java 代码场景有
	a. 使用 new 关键字例化对象的时候
	b. 读取或设置一个类型的静态字段(被 final 修饰 己在编译期把结果放入常量池的静态字段除外)的时候
	c. 调用一个类型的静态方法的时候
2)使用 java.lang retlect 包的方法对类型进行反射调用的时候,如果类型没有进行过初始化,则需要先触发其初始化
3)当初始化类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化
--举例
public class SingleTon{
	private SingleTon(){}
	private static class SingleTonHoler{ private static SingleTon INSTANCE = new SingleTon();}
	public static SingleTon getInstance(){ return SingleTonHoler.INSTANCE; }
}

... 后面从略

7.3.1 加载
	"加载"(Loading)阶段是整个"类加载"(class Loading)过程中的一个阶段,希望读者没有混淆这两个看起来很相似的名同。在加载阶段,Java虚拟机需要完成以下
	三件事情：
		1 )通过一个类的全限定名来获取定义此类的二进制字节流
		2 )将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构
		3 )在内存中生成一个代表这个类的 java. lang.Class 对象,作为方法区这个类的各种数据的访问人口
	加载阶段与连接阶段的部分动作(如一部分字节码文件格式验证动作)是交叉进行的
7.3.2 验证
	验证是连接阶段的第一步,这一阶段的目的是确保 lass 文件的字节流中包含的信息符合《 Java 虚拟机规范 》的全部约束要求,保证这些信息被当作代码运行
后不会危害虚拟机自身的安全
	验证阶段大致上会完成下面四个阶段的检验动作：文件格式验证、元数据验证、字节码验证和符号引用验证
7.3.3 准备
	准备阶段是正式为类中定义的变量(即静态变量,被static 修饰的变量)分配内存并设置类变量初始值的阶段,从概念上讲,这些变量所使用的内存都应当在
方法区中进行分配. 而在 JDK8及之后,类变量则会随着Class对象一起存放在 Java 堆中,这时候"类变量在方法区"就完全是一种对逻辑概念的表述了,关于这部分
内容,笔者已在 4.3.1 节介绍并且验证过
	假设一个类变量的定义为 public static int value = 123 ; 那变量 value 在准备阶段过后的初始值为 而不是 123 ,因为这时尚未开始执行任Java 方法,
而 value 赋值为 123 putstatic 指令是程序被编译后,存放于类构造器clinit()方法之中,所以把 value 赋值为 123 的动作要到类的初始化阶段才会被执行
	如果类字段的字段属性表中存在 ConstantValu 属性, 那在准备阶段变量值就会被初始化为ConstantValue 属性所指定的初始值,假设上面类变量 value 的
定义修改为：public static final int value = 123; 编译时 Javac 将会为 va lue 生成 ConstantValue 属性,在准备阶段虚拟机就会根据 ConstantValue 的设置
将 value 赋值为 123
7.3.4 解析
  解析阶段是 Java 虚拟机将常量池内的符号引用替换为直接引用的过程
  符号引用(Symbolic References)：符号引用以一组符号来描述所引用的目标,符号可以是任何形式的字面量 ,只要使用时能无歧义地定位到目标即可 符号引用与虚拟机
实现的内存布局无关,引用的目标并不一定是已经加载到虚拟机内存当中的内容。各种虚拟机实现的内存布局可以各不相同,但是它们能接受的符号引用必须都是一致的,
因为符号引用的宇面量形式明确定义在《Java虚拟机规范》的Class文件格式中
	直接引用(Direct References): 直接引用是可以直接指向目标的指针、相对偏移量或者是一个能间接定位到目标的句柄 直接引用是和虚拟机实现的内存布局直接相关
的,同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用 ,那引用的目标必定已经在虚拟机的内存中存在
及其后...
	亲测通过 sa-jdi.jar 工具发现代码中 ClassA 只做没有执行到, 就不会加载该类	

7.3.5 初始化
初始化阶段就是执行类构造器<clinit> ()方法的过程
<clinit>()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块(static{}块)中的语句合并产生的,编译器收集的顺序是由语句在源、文件中出现的顺序
决定的<clinit>()方法与类的构造函数(即在虚拟机视角中的实例构造器< ni ()方法)不它不需要显式地调用父类构造器, Java 虚拟机会保证在子类的<clinit()方法执前, 
父类 clinit>()方法已经执行完毕 Java 拟机中第 个被执行的clinit() 方法的类型肯定是 java.lang.Object
<clinit>()方法对于类或接口来说并不是必需的,如果一个类中没有静态语句块, 也没有对变量的赋值操作, 那么编译器可以不为这个类生成<clinit>()方法
接口中不能使用静态语句块,但仍然有变量初始化的赋值操作,因此接口与类一样都都会生成<clinit> ()方法
Java 虚拟机必须保证一个类的<clinit>()方法在多线程环境中被正确地加锁同步, 如果多线程同时去初始化一个类, 那么只会有其中一个线程去执行这个类的 clinit()
方线程都需要塞等待,直到活动线程执行完毕 clinit()方法, 在一个 clinit() 方法中有耗时很可能造成多个进程阻塞
-- init是instance实例构造器,对非静态变量解析初始化,而clinit是class类构造器对静态变量,静态代码块进行初始化

7.4 类加载器

7.5 Java 模块化系统
  可配置的封装隔离机制首先要解决 JDK9之前基于类路径(ClassPath)来查找依赖的可靠性问题. 此前,如果类路径中缺失了运行时依赖的类型 ,那就只能等程序运行到
发生该类型的加载、链接时才会报出运行的异常 而在 JDK9以后,如果启用了模块化进行封装,模块就可以声明对其他模块的显式依赖,这样 Java 虚拟机就能够在启动
时验证应用程序开发阶段设定好的依赖关系在运行期是否完备,如有缺失那就直接启动失败,从而避免了很大一部分 由于类型依赖而引发的运行时异常

7.5.1 模块的兼容性
  JDK9提出了与"类路径"(ClassPath)相对应的"模块路径"( ModulePath)的概念,简单来说,就是某个类库到底是模块还是传统的 JAR 包,只取决于它存放在哪种路径上 
只要是放在类路径上的 JAR文件,无论其中是否包含模块化信息(是否包含了 module info.class 文件),它都会被当作传统的 JAR 包来对待；相应地,只要放在模块
路径上的 JAR 文件,即使没有使用 JMOD后缀,甚至说其中并不包含 module-info class 文件,它也仍然会被当作一个模块来对待
及其后。。。
7.5.2 模块化下的类加载器


8.2 运行时钱帧结构
  在编译 Java 程序源码的时候,战 帧中需要多大的局部变量表,需要多深的操作数钱就已经被分析计算出来,并且写入到方法表的 Code 属性之中。换言之,一个枝帧
需要分配多少内存,并不会受到程序运行期变量数据的影响,而仅仅取决于程序源码和具体的虚拟机实现的枝内存布局形式

8.2.1 局部变量表
  局部变量表( Local Variables Table )是一组变量值的存储空间,用于存放方法参数和方法内部定义的局部变量,在Java 程序被编译为 Class 文件时,就在方法的
Code 属性的max locals 数据项中确定了该方法所需分配的局部变量表的最大容量
  局部变量表的容量以变量槽( Variable Slot )为最小单位,变量槽应占空间允许变量槽的长度可以随着处理器、操作系统或虚拟机实现的不同而发生变化,保证了
即使在 64 位虚拟机中使用了 64位的物理内存空间去实现一个变量槽
  为了尽可能节省检帧耗用的内存空间,局部变量表中的变量槽是可以重用的,方法体中定义的变量,其作用域并不一定会覆盖整个方法体,如果 当前字节码 PC计数器
的值已经超出了某个变量的作用域,那这个变量对应的变量槽就可以交给其他变量来重用 

	public static void main(String[] args) {
        {
            byte[] placeholder = new byte[1024*1024*64];
        }
        int a = 0;
        System.gc();
	}
	placeholder 能否被回收的根本原因就是：局部变量表中的变量槽是否还存有关于 placeholder 数组对象的引用。第一次修改中,代码虽然已经离开了 placeholder 
的作用域,但在此之后,再没有发生过任何对局部变量表的读写操作,placeholder 原本所占用的变量槽还没有被其他变量所复用 ,所以作为 GC Roots 一部分的局部
变量表仍然保持着对它的关联 这种关联没有被及时打断,绝大部分情况下影响都很轻微 但如果遇到一个方法,其后面的代码有一些耗时很长的操作,而前面又定义了
占用了大 内存但实际上已 经不会再使用的变量,手动将其设置为 null 值(用来代替那句 int a=O ,把变 对应的局部变量槽清空)便不见得是一个绝对元意义的操作
  
  在实际情况中,即时编译才是虚拟机执行代码的主要方式,null 值的操作在经过即时编译优化后几乎是一定会被当作无效操作消除掉的,这时候将变量设置为 null 
就是毫无意义的行为 字节码被即时编译为本地代码后,对 GC Roots的枚举也与解释执行时期有显著差别,以前面的例子来看 经过第一次修改 的代码清单在经过即时
编译后, System.gc ()执行时就可以正确地回收内存,根本无须 成代码清8-3 的样子(这段提到对即时编译,确实理解不深)
  
8.2.2 操作数栈
  同局部变量表一样,操作数枝的最大深度也在编译的时候被写入到 Code 属性的max stacks 数据项之中 操作数校的每一个元素都可以是包括 long和double 在内的任意
Java 数据类型 32 位数据类型所占的钱容量为 l, 64 位数据类型所占的核容量为2。Javac编译器的数据流分析工作保证了在方法执行的任何时候,操作数榜的深度都不会
超过在max stacks 数据项中设定的最大值
  譬如在做术运算的时候是通过将运算涉及的操作数桔压入校顶后调用运算指令来进行的,又譬如在调用其他方法的时候是通过操作数找来进行方法参数的传递
  两个不同枝帧作为不同方法的虚拟机拢的元素,是完全相互独立但是在大多虚拟机的实现里都会进行一些优化处理, 令两个梳帧出现一部分重叠。让下面找帧的部分操作
数楼与上面钱帧的部分局部变量表重叠在一起,这样做不仅节约了一些空间,更重要的是在进行方法调用时就可以直接共用一部分数据,无须进行额外的参数复制传递了

8.2.3 动态连接

8.2.4 方法返回地址
  方法退出的过程实际上等同于把当前枝帧出拢,因此退出时可能执行的操作有：恢复
上层方法的局部变 表和操作数枝,把返回值(如果有的话)压入调用者技帧的操作数校
中,调整PC 计数器的值以指向方法调用指令后面的一条指令等

8.3 方法调用
  第7章中已经讲过, Class 文件的编译过程中不包含传统程序语言编译的连接步骤,一切方法调用在 Class 文件里面存储的都只是符号引用,而不是方法在实际运行时
内存布局中的入口地址(也就是之前说的直接引用) 这个特性给 Java 带来了更强大的动态扩展能力,但也使得 Java 方法调用过程变得相对复杂,某些调用需要在类
加载期间,甚至到运行期间才能确定目标方法的直接引用

8.3.1 解析
  承接前面关于方法调用的话题,所有方法调用的目标方法在 Class 文件里面都是一个常量池中的符号引用,在类加载的解析阶段,会将其中的一部分符号引用转化为
直接引用,这种解析能够成立的前提是：方法在程序真正运行之前就有一个可确定的调用版本,并且这个方法的调用版本在运行期是不可改变的 换句话说,调用目标在
程序代码写好、编译器进行编译那一刻就已经确定下来。这类方法的调用被称为解析( Resolution)
  在Java 语言中符合"编译期可知,运行期不可变"这个要求的方法,主要有静态方法和私有方法两大类,前者与类型直接关联,后者在外部不可被访问,这两种方法各自
的特点决定了它们都不可能通过继承或别的方式重写出其他版本,因此它们都适合在类加载阶段进行解析
  虚方法,非虚方法
  解析调用一定是个静态的过程,在编译期 间就完全确定,在类加载的解析阶段就会把
涉及的符号引用全部转变为明确的直接引用,不必延迟到运行期再去完成 而另一种主要
的方法调用形式：分派( Dispatch )调用则要复杂许多,它可能是静态的也可能是动态的,
按照分派依据的宗量数可分为单分派和多分派

8.3.2 分派
1. 静态分派
  Javac 编译器就根据参数 的静态类型决定了会使用哪个重载版本,因此选择了 sayHello(Human )作为调用目标,井把这个方法的符号引用写到 main()方法里的两条
invokevirtual指令的参数中
  所有依赖静态类型来决定方法执行版本的分派动作,都称为静态分派 静态分派的最典型应用表现就是方法重载 静态分派发生在编译阶段,因此确定静态分派的动作实际
上不是由虚拟机来执行的,这点也是为何一些资料选择把它归入"解析"而不是"分派"的原因
  另外还有一点读者可能比较容易混淆 ：笔者讲述的解析与分派这两者之间的关系并不是二选一的排他关系,它们是在不同层次上去筛选 、确定 目标方法的过程 例如
前面说过静态方法会在编译期确定、在类加载期就进行解析,而静态方法显然也是可以拥有重载版本的,选择重载版本的过程也是通过静态分派完成的
2. 动态分派
  invokevirtual 指令的运行时解析过程 大致分为以下几步：
	1) 找到操作数枝顶的第一个元素所指向的对象的实际类型,记作C
	2) 按照继承关系从下往上依次对C的各个父类进行第二步的搜索和验证过程
  正是因为 invokevirtual指令执行的第一步就是在运行期确定接收者的实际类型,所以两次调用中 invokevirtual 指令并不是把常量池中方法的符号引用解析到直接
引用上就结束了,还会根据方法接收者的实际类型来选择方法版本,这个过程就是 Java 中方法重本质
  按照目前 Java 语言的发展趋势,它并没有直接变为动态语言的迹象,而是通过内置动态语言(如 JavaScript )执行引擎、 加强与其他Java 虚拟机上动态语言交互
能力的方式来间接地满足动态性的需求。但是作为多种语言共同执行平台的 Java 虚拟机层面上则不是如此,早在 JDK 中实现的 JSR-292 ＠里面就已经开始提供对动态
语言的方法调用支持了, JDK 7中新增的 invokedynamic 指令也成为最复杂的一条方法调用的字节码指令,稍后笔者将在本章中专门开一节来讲解这个与 Java 调用
动态语言密切相关的特性
4. 虚拟机动态分派的实现

8.4 动态类型语言支持
8.4.1 动态类型语言
  动态类型语言的关键特征是它的类型检查的主体过程是在运行期而不是编译期进行的,满足这个特征的语言有很多,常用的包括：Clojure Groovy JavaScript Python...
相对地,在编译期就进行类型检查过程的语言,譬如 C++和 Java 等就是最常用的静态类型语言
后面再看看...

8.4.2 Java 与动态类型
  而目前确实已经有许多动态类型语言运行于 Java 虚拟机之上了,如 Clojure Groovy Jython JRuby 等,能够在同一个虚拟机之上可以实现静态类型语言的严谨与动态
类型语言的灵活,这的确是一件很美妙的事情
及其后...

8.4.3 java.lang.invoke包
8.4.4 invokedynamic 指令
8.4.5 实战：掌控方法分派规则

8.5 基于梭的字节码解释执行引擎
  概述中曾提到过,许多 Java虚拟机的执行引擎在执行 Java 代码的时候都有解释执行(通过解释器执行)和编译执行(通过即时编译器产生本地代码执行)两种选择
8.5.1 解释执行
  Java 语言经常被人们定位为"解释执行"的语言,在 Java 初生的 JDK 1.0 时代,这种定义还算是比较准确的,但当主流的虚拟机中都包含了即时编译器后,Class 文件
中的代码到底会被解释执行还是编译执行,就成了只有虚拟机自己才能准确判断的事

8.5.3 基于榜的解释器执行过程

9.2.1 Tomcat 正统的类加载器架构
  主流的 Java 服务器,如 Tomcat... 都实现了自己定义的类加载器,而且一般还都不止一个 因为一个功能健全Web 服务器,都要解决如下的这些问题：
	a. 部署在同一个服务器上的两个 Web 应用程序所使用的 Java 类库可以实现相互隔离这是最基本的需求,两个不同的应用程序可能会依赖同一个第三方类库的不同版本,
不能要求每个类库在一个服务器中只能有一份,服务器应当能够保证两个独立应用程序的类库可以互相独立使用
    b. 部署在同一个服务器上的两个 Web 应用程序所使用的 Java 类库可以互相共享。这个需求与前面一点正好相反,但是也很常见,例如用户可能有 10 个使用 Spring组织的应用程序部署在同 台服务器上,如果把 10份 Spring 分别存放在各个应用程序
的隔离目录中,将会是很大的资源浪费一一这主要倒不是浪费磁盘空 间的问题,而是指类库在使用时都要被加载到服务器内存,如果类库不能共享,虚拟机的方法区就会很容易出现过度膨胀的风险
    c. 服务器需要尽可能地保证自身的安全不受部署的 Web 应用程序影响 目前,有许多主流的 Java Web 服务器自身也是使用 Java 语言来实现的 因此服务器本身也有类
库依赖的问题, 般来说,基于安全考虑,服务器所使用的类库应该与应用程序的类库互相独立
  
  由于存在上述问题,在部署 Web 应用时,单独的一个ClassPath 就不能满足需求了,所以各种 Web 服务器都不约而同地提供了好几个有着不同含义的 ClassPath 
路径供用户存放第三方类库。被放置到不同路径中的类库具备不同的访问范围和服务对象,通常每一个目录都会有一个相应的自定义类加载器去加载放置在里面的 Java 类库
  tomcat把Java 类库放置在这4组目录中,每一组都有独立的含义,分别是：
	放置在／common 目录中 类库可被Tomcat 和所有的 Web 应用程序共同使用
	放置在／server 目录中 类库可被 Tomcat 使用
	放置在／shared 目录中 类库可被所有的 Web 应用程序共同使用,但对 Tomcat 自己不可见
	放置在 /WebApp/Web-INF 目录中 类库仅仅可以被该 Web 应用程序使用,对 Tomcat 和其它Web 应用程序都不可见
  我觉得用多个子加载器是为了解决隔离问题,而子加载器要把类委托给父加载器不行再自己加载,目的是解决共享问题
  如果有 10 个Web 应用程序都是用 Spring 来进行组织和管理的话,可 以把 Spring 放到 Common或Shared 目录下让这些程序共享 Spring 要对用户程序的类进行管理,
自然要能访问到用户 程序的类,而用户的程序显然是放在／WebApp WEB-INF 目录中的

9.2.2 OSGi ：灵活的类加载器架构
  实在有时间时可以看一下
9.2.3 字节码生成技术与动态代理的实现
  在Java世界里面除了 Javac,使用到字节码 成的例子比比皆是,如 Web 务器中的 JSP 编译器,编译时织入的 AOP 框架,汪有很常用的动态代理技术
  Spring 内部都是通过动态代理的方式来对 Bean 进行增强的
9.2.4 Backport 工具： Java 的时光机器
	知道才不会的就行了
9.3 实战：自己动手实现远程执行功能
	有精力再看吧

10.1 概述
  在Java 技术下谈"编译期"而没有具体上下文语境的话,其实是一句很含糊的表述,
因为它可能是指一个前端编译器(叫"编译器的前端"更准确一些)把*.java 文件转变成
*.class 文件的过程；也可能是指 Java 虚拟机的即时编译器(常称 JIT 编译器, just In Time
Compiler )运行期把字节码转变成本地机器码的过程；还可能是指使用静态的提前编译器
(常称 AOT 编译器, Ahead Of Time Compiler )直接把程序编译成与目标机器指令集相关的
二进制代码的过程 下面笔者列举了这3类编译过程里一些比较有代表性的编译器产品：
	a. 前端编译器 JDK的Javac Eclipse JDT 中的增量式编译器( ECJ )
	b. 即时编译器 Hotspot 虚拟机的 C1 C2 编译器, Graal 编译器
	c. 提前编译器： JDK Jaotc GNU Compiler for the Java ( GCJ) ＠、 Excelsior JET
  因为 Java 虚拟机设计团队选择把对性能的优化全部集中到运行期的即时编译器中,这样可以让那些不是由 Javac 产生的Class文件(如 JRuby Groovy 等语言的Class 
文件)也同样能享受到编译器优化措施所带来的性能红利

10.2 Javac 编译器
	有精力再看
10.3 Java 语法糖的味道
	有精力再看
10.4 实战：插人式注解处理器
	有精力再看
	
11.1 概述
11.2 即时编译器
	目前主流的两款商用 Java 虚拟机( HotSpot OpenJ9 )里, Java 程序最初都是通过解释
器( Interpreter )进行解释执行的,当虚拟机发现某个方法或代码块的运行特别频繁,就会
把这些代码认定为"热点代码"(Hot Spot Code ),为了提高热点代码的执行效率,在运行时,
虚拟机将会把这些代码编译成本地机器码,并以各种手段尽可能地进行代码优化,运行时
完成这个任务的后端编译器被称为即时编译器 本节我们将会了解 HotSpot 虚拟机内的即
时编译器的运作过程,此外,我们还将解决以下几个问题：
	为何 HoSpot 虚拟机要使用解释器与即时编译器并存的架构？
	口为何 HoSpot 虚拟机要实现两个(或三个)不同的即时编译器？
	程序何时使用解释器执行？何时使用编译器执行？
	口哪些程序代码会被编译为本地代码？如何编译本地代码？
	口如何从外部观察到即时编译器的编译过程和编译结果？
11.2.1 解释器与编译器
  尽管并不是所有的 Java 虚拟机都采用解释器与编译器并存的运行架构,但目前主流的商用 Java 虚拟机,譬如 Hotspot OpenJ9 等,内部都同时包含解释器与编译器,
解释器与编译器两者各有优势 当程序需要迅速启动和执行的时候,解释器可以首先发挥作用,省去编译的时间,立即运行 当程序启动后,随着时间的推移,编译器逐渐
发挥作用,把越来越多的代码编译成本地代码,这样可以减少解释器的中间损耗,获得更高的执行效率。当程序运行环境中内存资源限制较大,可以使用解释执行节约内存
(如部分嵌入式系统中和大部分的 JavaCard 应用中就只有解释器的存在),反之可以使用编译执行来提升效率
  HotSpot 虚拟机中内置了两个(或三个)即时编译器,其中有两个编译器存在已久,分别被称为"客户端编译器"(Client Compiler)和"服务端编译器"(Server Compiler),
或者简称为C1编译器和 C2 编译器(部分资料和 JDK 源码中 C2 也叫 Opto 编译器),第三个是在JDK10时才出现的、长期目标是代替 C2的Graal 编译器
  在分层编译( Tiered Compilation )的工作模式出现以前, Hotspot 虚拟机通常是采用解释器与其中一个编译器直接搭配的方式工作,程序使用哪个编译器,只取决
于虚拟机运行的模式, HotSpot 虚拟机会根据自身版本与宿主机器的硬件性能自动选择运行模式,用户也可以使用"-client",或"-server" 指定模式
  元论采用的编译器是客户端编译器还是服务端编译器,解释器与编译器搭配使用的方式在虚拟机中被称为"混合模式"( Mixed Mode ),用户也可以使用参数"-Xint "
强制虚拟机运行于"解释模式"( Interpreted Mode ),这时候编译器完全不介入工作,全部代码都使用解释方式执行 另外,也可以使用参数"－Xcomp "强制虚拟机运行
于"编译模式"( Compiled Mode ),这时候将优先采用编译方式执行程序,但是解释器仍然要在编译无法进行的情况下介入执行过程 可以通过虚拟机的 "-version",
命令的输出结果显示出这三种模式 java -version, java -Xcomp -version, java -Xint -version
  由于即时编译器编译本地代码需要占用程序运行时间,通常要编译出优化程度越高的代码,所花费的时间便会越长；而且想要编译出优化程度更高的代码,解释器可能
还要替编译器收集性能监控信息,这对解释执行阶段的速度也有所影响为了在程序启动响应速度与运行效率之间达到最佳平衡, HotSpot 虚拟机在编译子系统中加入了
分层编译的功能
	第0层：程序纯解释执行,并且解释器不开启性能监控功能(Profiling
	第1层：使用客户端编译器将 节码编译为本地代码来运行, 进行简单可 的稳优化,不开启性能监控功
	第2层：仍然使用客户端编译器执行 仅开启方法及 回边次数统计等有限的性能监控功能
	第2层：仍然使用客户端编译器执行,开启全部性能监控,除了第 层的统计信息外,还会收集如分支跳转、虚方法调用版本等全部的统计信息
	第4层：使用服务端编译器将字节码编译为 地代码,相比起客户端编译器,服务端编译器会启用更多编译耗时更长的优化,还会根据性能监控信息进行一些不可靠进优化
11.2.2 编译对象与触发条件
  在本章概述中提到了在运行过程中会被即时编译器编译的目标是"热点代码",这里所指的热点代码主要有两类, 包括：1.被多次调用的方法；2.被多次执行的循环体
  对于这两种情况,编译的目标对象都是整个方法体,而不会是单独的循环体
  要知道某段代码是不是热点代码,是不是需要触发即时编译,这个行为称为"热点探测"(Hot Spot Code Detection),其实进行热点探测并不一定要知道方法具体被调用
了多少次,目前主流的热点探测判定方式有两种
	a. 基于采样的热点探测( Sample Based Hot Spot Code Detectio 采用这种方法的虚拟机会周期性地检 各个线程的调用楼顶,如果发现某个(或某些)方法经常出现在校顶,那这个方法就是"热点方法"
    b.基于计数器的热点探测( Counter Based Hot Spot Code Det ction 采用这种方法的虚拟机会为每个方法(甚至是代码块)建立计数器,统计方法的执行次数,如果执行次数超过一定的阔值就认为它是"热点方法"
  HotSpot 虚拟机中使用的是第二种基于计数器的热点探测方法,为了实现热点计数,HotSpot 为每个方法准备了两类计数器 方法调用计数器( Invocaton Counter )和
回边计数器( Back Edge ounter ,"回边"的意思就是指在循环边界往回跳转)。当虚拟机运行参数确定的前提下,这两个计数器都有 个明确的阔值,计数器阔值 旦溢出,
就会触发时编译
  我们首先来看看方法调用计数器 顾名思义,这个计数器就是用于统计方法被调用的次数,它的默认 现值在客户端模式下是 1500 次,在服务端模式下是 10000 次,
这个阔值可以通过虚拟机参数 XX:CompieThreshold 来人为设定。当一个方法被调用时, 虚拟机会先检查该方法是否存在被即时编译过的版本,如果存在,则优先使用编译
后的本地代码来执如果不存在已被编译过的版本,则将该方法的调用计数器值加一,然后判断方法调用计数器与回边计数器值之和是否超过方法调用计数器的阔值 一旦
已超过阁值的话,将会向即时编译器提交一个该方法的代码编译请求
  如果没有做过任何设置, 执行引擎默认不会同步等待编译请求完成,而是继续进入解释器按照解释方式执行字节码,直到提交的请求被即时编译器编译完成 当编译工作
完成后,这个方法的调用入口地址就会被系统自动改写成新值,下一次调用该方法时就会使用己编译的版本了
  现在我们再来看看另外一个计数器--回边计数器,它的作用是统计一个方法中循环体代码执行的次数。在字节码中遇到控制流向后跳转的指令就称为"回边(Back Edge)",
很显然建立 回边计数器统计的目的是为 了触发枝上的替换编译
  当解释器遇到一条回边指令时,会先查找将要执行的代码片段是否有 已经编译好的版本,如果有的话,它将会优先执行己编译的代码,否则就把回边计数器的值加一,
然后判断方法调用计数器与回边计数器值之和是否超过回边计数器的阔值 当超过阁值的时候,将会提交一个枝上替换编译请求,并且把回边计数器的值稍微降低一些,
以便继续在解释器中执行循环
11.2.3 编译过
  在默认条件下,无论是方法调用产生的标准编译请求,还是椅上替换编译请求,虚拟机在编译器还未完成编译之前 都仍然将按照解释方式继续执行代码,而编译动作
则在后台的编译线程中进行
其后内容有精力再看
11.2.4 实战：查看及分析即时编译结果
  一般来说, Java 虚拟机的即时编译过程对用户和程序都是完全透明的,虚拟机是通过解释来执行代码还是通过编译来执行代码,对于用户来说并没有什么影响
(对执行结果没有影响,速度上会有显著差别),大多数情况下用户也没有必要知道。但是 HotSpot 虚拟机还是提供了一些参数用来输出 即时编译和某些优化措施的运行
状况,以满足调试和调优的需要。本节将通过实战说明如何从外部观 Java 虚拟机的即时编译行为
其后内容有精力再看...
11.3 提前编译器
  但是提前编译很快又在 Java 世界里沉寂了下来,因为当时 Java 的一个核心优势是平台中立’性,其宣传口号是"一次编译,到处运行",这与平台相关的提前编译在
理念上就是直接冲突的
  尽管 Android 并不能直接等同于 Java ,但两者毕竟有着深厚渊源,提前编译在 Android上的革命与崛起也震撼到了 Java 世界 在某些领域 、某些人眼里,只要能
获得更好的执行性能,什么平台中立性、字节膨胀②、动态扩展＠, 叨皆可舍弃,唯一的问题就只有"提前编译真的会是获得更高性能的银弹吗？
11.3.1 提前编译的优劣得失
  现在提前编译产品和对其的研究有着两条明显的分支,一条分支是做与传统C C++编译器类似的,在程序运行之前把程序代码编译成机器码的静态翻译工作;另外一条分支是
把原本即时编译器在运行时要做的编译工作提前做好并保存下来,下次运行到这些代码(譬如公共库代码在被同一台机器其他 Java 进程使用)时直接把它加载进来使用
  我们先来说第一条,这是传统的提前编译应用形式,它在 Java 中存在的价值直指即时编译的最大弱点 即时编译要占用程序运行时间和运算资源。无论如何,即时编译
消耗的时间都是原本可用于程序运行的时间,消耗的运算资源都是原本可用于程序运行的资源,这个约束从未减弱更不会消失,始终是悬在即时编译头顶的达摩克利斯之剑
  关于提前编译的第二条路径,本质是给即时编译器做缓存加速,去改善 Java 程序的启动时间,以及需要一段时间预热后才能到达最高性能的问题
  我们还要思考一个问题 提前编译的代码输出质量,一定会比即时编译更高吗？提前编译因为没有执行时间和资源限制的压力,能够毫无顾忌地使用重负载的优化手段,
这当然是一个极大的优势,但即时编译难道就没有能与其竞争的强项了吗？当然是有的,尽管即时编译在时间和运算资源方面的劣势是无法忽视的,但其依然有自己的优势
  首先,是性能分析制导优化, 上一节介绍 HotSpot的即时编译器时就多次提及在解释器或者客户端编译器运行过程中,会不断收集性能监控信息,譬如某个程序点抽象
类通常会是什么实际类型、条件判断通常会走哪条分支、方法调用通常会选择哪个版本、循环通常会进行多少次等,这些数据一般在静态分析时是无法得到的。但在动态
运行时却能看出它们具有非常明显的偏好性 如果一个条件分支的某一条路径执行特别频繁, 而其他路径鲜有问津,那就可 以把热的代码集中放到一起, 集中优化和分配
更好的资源(分支预测、寄存器、缓存等)给它
  其次 ,是激进预测性优化Aggressive Speculative Optimization ), 这也已经成为很多即时编译优化措施的基础静态优化无论如何都必须保证优化后所有的程序外部
可见影响(不仅仅是执行结果)与优化前是等效的,不然优 之后会导致程序报错或者结果不对,若出现这种情况,则速度再快也是没有价值的 然而,相对于提前编译来说,
即时编译的策略就可以不必这样保守,如果性能监控信息能够支持它做出一些正确的可能性很大但无法保证绝对正确 的预测判断 ,就已经可以大胆地按照高概率的假设
进行优化,万一真的走到罕见分支上,大不了退回到低级编译器甚至解释器上去执行,并不会出现无法挽救的后果
  最后 ,是链接时优化 Link-Time Optimization, LTO ), Java 语言天生就是动态链接的,
一个个 Class 文件在运行期被加载到虚拟机内存当中,然后在 即时编译器里产生优化后的
本地代码,这类事情在 Java 程序员眼里看起来毫无违和之处 但如果类似的场景出现在使
用提前编译的语言和程序上,譬如C C++的程序要调用某个动态链接库 的某个方法,就
会出现很明显的边界隔阂,还难以优
11.3.2 实战： Jaotc 的提前编译
  有精力再看...
11.4.1 优化技术概览
  有精力再看...
11.4.2 方法内联
  我们多次提到方法内联 ,说它是编译器最重要的优化手段, 甚至都可以不加上"之一"。内联被业内戏称为优化之母,因为除了消除方法调用的成本之外,它
更重要的意义是为其他优化手段建 良好的基础
其后内容有精力再看...
11.4.3 逃逸分析
  逃逸分析的基本原理是：分析对象动态作用域,当一个对象在方法里面被定义后,它可能被外部方法所引用,例如作为调用参数传递到其他方法中,这种称为方法逃逸；
甚至还有可能被外部线程访问到譬如赋值给可以在其它线程中访问的实例变量,这种称为线程逃逸；从不逃逸 方法逃逸到线程逃逸,称为对象由低到高的不同逃逸程度

栈上分配 Stack Allocations )：虚拟机的垃圾收集子系统会回收堆中不再使用的对象, 但回收动作无论是标记筛选出可回收对象,还是回收和整理内存,都需要
耗费大量资源 如果确定一个对象不会逃逸出线程之外,那让这个对象在枝上分配内存将会是 个很不错的主意, 对象所占用的内存空间就可以随钱帧出枝而销毁枝上分配
可以支持方法逃逸 但不能支持线程逃逸

标量替换( Scalar Replacement )：看书...
同步消除( Synchronization Elimination ):逃逸分析能够确定一个变量不会逃逸出线程,无法被其他线程访问,那么这个变量的读写肯定就不会有竞争,对这个变量实施的同步措施也就可以安全地消除掉
后面的例子也看一下

11.4.4 公共子表达式消除
  感觉好简单
11.4.5 数组边界检查消除
	有精力再看
11.5 实战：深人理解 Graal 编译器
	有精力再看
	
12.2 基于高速缓存的存储交互很好地解决了处理器与内存速度之间的矛盾,但是也为计算机系统带来更高的复杂度,它引入了一个新的问题：缓存一致性( Cache Coherence)
  My viewpoint: 线程数据一致性问题不仅是 缓存一致性问题,就像 volatile 可以解决缓存一致性问题但并不能保证线程安全。从物理机层面解释是因为每个线程的
  寄存器要把数据从主存中读过来,造成了数据不一致
  
  物理机层面：除了增加高速缓存之外,为了使处理器内部的运算单元能尽量被充分利用,处理器可能会对输入代码进行乱序执行( Out-Of-Order Execution )优化。
  与处理器的乱序执行优类似, Java虚拟机的即时编译器中也有指令重排序( Inst ruction Reorder )优化  
  
  Java内存模型规定了所有变量都存储在主内存( Main Memory )中(此处的主内存与
介绍物理硬件时提到的主内存名字一样,两者也可以类比。每条线程还有自己的工作内存( Working Memory ,可与前面讲的处理器高速缓存类比)

12.3.2 内存间交 操作
  含义很深啊
12.3.3 对于 volatile 型变 的特殊规则
12.3.4 针对 long double 型变量的特殊规则
12.3.5 原子性、可见性与有序性
  细读也有很多深意呢, 举例: int a=1; int b=2; 两个都是原子操作吧, 但是我觉得可能不是有序的(不仅指令重排序), 我觉得应该是 store store write write 这个顺序
  
12.4.1.1
	内核线程( Kernel Level Thread, KLT)就是直接由操作系统内核( Kerne ,下称内核)支持的线程

  轻量级进程也具有它的局限性：
  首先, 由于是基于内核线程实现的,所以各种线程操作,如创建、析构及同步,都需要进行系统调用 而系统调用的代价相对较高,需要在用户态(Use Mo 和内核态 Kerne Mode )
中来回切换 其次,每个轻量级进程都需要有一个内核线程的支持,因此轻量级进程要消耗一定的内核资源 如内核线程的栈空间),因此一个系统支持轻量级进程的数量是有限的
12.4.1.2
  用户线程的建立、同步 、销毁和调度完全在用户态 中完成,不需要内核的帮助 如果程序实现得当,这种线程不需要切换到内核态,因此操作可以是非常快
速且低消耗的,也能够支持规模更大的线程数量, 部分高性能数据库中的多线程就是由用户线程实现的
  近年来许多新 的、以高并发为卖点的编程语言又普遍支持了用户线程,譬如 Go Jang Erlang 等,使得用户线程的使用率有所回升
12.4.2 Java 线程调度
  如果使用协同式调度的多线程系统,线程的执行时间由线程本身来控制,线程把自己的工作执行完了之后, 主动通知系统切换到另外 个线程上去 协同式多线程的最大好
处是实现简单,而且由于线程要把自己的事情干完后才会进行线程切换,切换操作对线程自己是可知的,所以一般没有什么线程同步的问题。它的坏处也很明显：线程执行时间不可控制, 甚至如果一个线程的代码编写有问题,
一直不告知系统进行线程切换 ,那么程序就会一直阻塞在那里

12.4.3 状态转换

	无限期等待( Waiting) 处于这种状态的线程不会被分配处理器执行时间,它们要等
	待被其他线程显式唤醒 以下方法会让线程陷入无限期的等待状态
	没有设置Timeout 参数的 Object::wait()
	没有设置 Timeout 参数 Thread: :join()
	LockSupport::park()

	阻塞(Blocked)： 线程被阻塞了,"阻塞状态"与"等待状态"的区别是"阻塞状态" 在等待着获取到一个排它锁,这个事件将在另外一个线程放弃这个锁的时候发生；
	而"等待状态"则是在等待一段时间,或者唤醒动作的发生 在程序等待进入同步区域的时候,线程将进入这种状态

12.5.2 协程的复苏
	假设发生了这样一次线程切换: 线程A --〉系统中断 --〉线程B
	处理器要去执行线程A的程序代码时,并不是仅有代码程序就能跑得起来,程序是数据与代码的组合体,代码执行时还必须要有上下文数据的支撑
	而这里说的"上下文",以程序员的角度来看,是方法调用过程中的各种局部的变量与资源 以线程的角度来看,是方法的调用找中存储的各类信息 
	而以操作系统和硬件的角度来看, 则是存储在内存、缓存和寄存器中的一个个具体数值
	物理硬件的各种存储设备和寄存器是被操作系统内所有线程共享的资源,当中断发生,从线程A切换到线程B去执行之前,操作系统首先要把线程A的上下文数据妥善
	保管好,然后把寄存器 内存分页等恢复到线程B挂起时候的状态,这样线程B被重新激活后才能仿佛从来没有被挂起过,这种保护和恢复现场的工作,免不了涉及一系列
	数据在各种寄存器 缓存中的来回拷贝,当然不可能是一种轻量级的操作
	
	由于最初多数的用户线程是被设计成协同式调度( Cooperative Scheduling )的,所以它有了一个别名--"协程"
	协程的主要优势是轻量, 无论是有钱协程还是无技协程,都要比传统内核线程要轻量得多。如果进行量化的话,那么如果不显式设置 -Xss 或 
	-XX: Thread StackSize,则在64位Linux HotSpot 线程栈容量默认是 lMB ,此外内 核数据结构( Kernel Data Structures)还会额外消耗 16KB 内存。
	与之相对的 ,一个协程的战通常在几百个字节到几 KB 之间,所以Java 虚拟机里线程池容量达到两百就已经不算小了,而很多支持协程的应用中,同时并
    存的协程数量可数以十万
	
13.2.2 线程安全的实现方法

13.3.1 自旋锁与自适应自旋
	参数：-XX:+UseSpinning  -XX:+PreBlockSpin
  如果物理机器有一个以上的处理器或者处理器核心,能让两个或以上的线程同时并行执行,我们就可以让后面请求锁的那个线程稍等一会,但不放弃处理器的执行时间,
看看持有锁的线程是否很快就会释放锁。为了让线程等待,我们只须让线程执行一个忙循环(自旋),这项技术就是所谓的自旋锁
  如果锁被占用的时间很短,自旋等待的效果就会非常好,反之如果锁被占用的时间很长,那么自旋的线程只会白白消耗处理器资源,而不会做任何有价值的工作,
这就会带来性能的浪费。因此自旋等待的时间必须有一定的限度 如果自旋超过了限定的次数仍然没有成功获得锁,就应当使用传统的方式去【挂起】线程 自旋次数的
默认值是十次
	
  在 JDK 6 中对自旋锁的优化,引人了自适应的自旋 自适应意味着自旋的时间不再是固定的了,而是由前一次在同 个锁上的自旋时间及锁的拥有者的状态来决定的。
如果在同一个锁对象上,自旋等待刚刚成功获得过锁,并且持有锁的线程正在运行中,那么虚拟机就会认为这次自旋也很有可能再次成功,进而允许自旋等待持续相对
更长的时间,比如持续 100 次忙循环. 另一方面,如果对于某个锁,自旋很少成功获得过锁,那在以后要获取这个锁时将有可能直接省略掉自旋过程,以避免浪费处理器资源

13.3.2 锁消除 
	锁消除是指虚拟机即时编译器在运行时,对一些代码要求同步,但是对被检测到不可能存在共享数据竞争的锁进行消除,锁消除的主要判定依据来源于逃逸分析的数据
支持(第11章已经讲解过逃逸分析技术),如果判断到一段代码中,在堆上的所有数据都不会逃逸出去被其他线程访问到 ,那就可以把它们当作栈上数据对待,认为它们
是线程私有的,同步加锁自然就无须再进行

13.3.3 锁粗化
  原则上,我们在编写代码的时候,总是推荐将同步块的作用范围限制得尽量小--在共享数据的实际作用域中才进行同步,这样是为了使得需要同步的操作数量尽可能变少,
即使存在锁竞争,等待锁的线程也能尽可能快地拿到锁大多数情况下,上面的原则都是正确的 但是如果一系列的连续操作都对同一个对象反复加锁和解锁,甚至加锁操作
是出现在循环体之中的,那即使没有线程竞争,频繁地进行互斥同步操作也会导致不必要的性能损耗
  如果虚拟机探测到有这样一串零碎的操作都对同一个对象加锁,将会把加锁同步的范围扩展(粗化)到整个操作序列的外部

13.3.4 轻量级锁
  它名字中的"轻量级"是相对于使用操作系统互斥量来实现的传统锁而言的,因此传统的锁机制就被称为"重量级"锁
13.3.5 偏向锁

